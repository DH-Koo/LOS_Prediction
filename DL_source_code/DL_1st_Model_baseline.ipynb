{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V08e05Ftqyv",
        "outputId": "b2ccbb1b-7815-4319-ea03-a47a5ddd6b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(424803, 17)\n",
            "Index(['subject_id', 'hadm_id', 'admittime', 'dischtime', 'race', 'los_hours',\n",
            "       'gender', 'anchor_age', 'curr_service', 'hcpcs_cd_list',\n",
            "       'diagnoses_icd_code_list', 'procedures_icd_code_list', 'drg_code',\n",
            "       'drg_severity', 'drg_mortality', 'medication_list', 'order_type_list'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Data Loading\n",
        "df = pd.read_parquet(\"los_dataset_24h.parquet\")\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrTAv2ht3aZ"
      },
      "outputs": [],
      "source": [
        "def build_label_encoder(series):\n",
        "    classes = sorted(series.unique())\n",
        "    stoi = {c: i for i, c in enumerate(classes)}\n",
        "    return stoi\n",
        "\n",
        "\n",
        "def build_vocab_from_list_column(df, col, min_freq=1, add_unk=True):\n",
        "    counter = Counter()\n",
        "    for lst in df[col]:\n",
        "        counter.update(lst)\n",
        "\n",
        "    stoi = {}\n",
        "    idx = 0\n",
        "    if add_unk:\n",
        "        stoi[\"<UNK>\"] = idx\n",
        "        idx += 1\n",
        "\n",
        "    for token, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            if token not in stoi:\n",
        "                stoi[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "    return stoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LpjEFBuIUx",
        "outputId": "01f1d61c-b639-49e8-e5ab-713ddcc2c499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_genders: 2\n",
            "num_races: 33\n",
            "num_services: 21\n",
            "num_drg_codes: 301\n"
          ]
        }
      ],
      "source": [
        "# Encoders for gender, race, curr_service, drg_code\n",
        "gender_stoi = build_label_encoder(df[\"gender\"])\n",
        "race_stoi = build_label_encoder(df[\"race\"])\n",
        "service_stoi = build_label_encoder(df[\"curr_service\"])\n",
        "\n",
        "# drg_code is already an int, but treat it as a \"category\" and map it to an index again\n",
        "drg_code_stoi = build_label_encoder(df[\"drg_code\"].astype(int))\n",
        "\n",
        "print(\"num_genders:\", len(gender_stoi))\n",
        "print(\"num_races:\", len(race_stoi))\n",
        "print(\"num_services:\", len(service_stoi))\n",
        "print(\"num_drg_codes:\", len(drg_code_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jysvDQ6KuKI3",
        "outputId": "fb441cbb-f095-4213-b450-40cb7f260a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diag vocab size: 27701\n",
            "proc vocab size: 12184\n",
            "hcpcs vocab size: 1925\n",
            "med vocab size: 3358\n",
            "order vocab size: 17\n"
          ]
        }
      ],
      "source": [
        "list_cols = [\n",
        "    \"diagnoses_icd_code_list\",\n",
        "    \"procedures_icd_code_list\",\n",
        "    \"hcpcs_cd_list\",\n",
        "    \"medication_list\",\n",
        "    \"order_type_list\",\n",
        "]\n",
        "\n",
        "diag_stoi = build_vocab_from_list_column(df, \"diagnoses_icd_code_list\", min_freq=1)\n",
        "proc_stoi = build_vocab_from_list_column(df, \"procedures_icd_code_list\", min_freq=1)\n",
        "hcpcs_stoi = build_vocab_from_list_column(df, \"hcpcs_cd_list\", min_freq=1)\n",
        "med_stoi = build_vocab_from_list_column(df, \"medication_list\", min_freq=1)\n",
        "order_stoi = build_vocab_from_list_column(df, \"order_type_list\", min_freq=1)\n",
        "\n",
        "print(\"diag vocab size:\", len(diag_stoi))\n",
        "print(\"proc vocab size:\", len(proc_stoi))\n",
        "print(\"hcpcs vocab size:\", len(hcpcs_stoi))\n",
        "print(\"med vocab size:\", len(med_stoi))\n",
        "print(\"order vocab size:\", len(order_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prFr0KUjuNiy",
        "outputId": "87cc0a64-20ec-41cc-a008-668d6d8c52d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "combined proc vocab size: 14108\n"
          ]
        }
      ],
      "source": [
        "# Combine proc_stoi and hcpcs_stoi into a single unified vocab\n",
        "proc_all_stoi = {}\n",
        "idx = 0\n",
        "\n",
        "# Only one UNK\n",
        "proc_all_stoi[\"<UNK>\"] = idx\n",
        "idx += 1\n",
        "\n",
        "# Procedures first\n",
        "for k in proc_stoi.keys():\n",
        "    if k == \"<UNK>\":\n",
        "        continue\n",
        "    proc_all_stoi[\"PROC_\" + k] = idx\n",
        "    idx += 1\n",
        "\n",
        "# HCPCS next\n",
        "for k in hcpcs_stoi.keys():\n",
        "    if k == \"<UNK>\":\n",
        "        continue\n",
        "    key = \"HCPCS_\" + k\n",
        "    if key not in proc_all_stoi:\n",
        "        proc_all_stoi[key] = idx\n",
        "        idx += 1\n",
        "\n",
        "print(\"combined proc vocab size:\", len(proc_all_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vqz1gkzjuQpZ"
      },
      "outputs": [],
      "source": [
        "UNK_DIAG = diag_stoi[\"<UNK>\"]\n",
        "UNK_PROC = proc_all_stoi[\"<UNK>\"]\n",
        "UNK_MED = med_stoi[\"<UNK>\"]\n",
        "UNK_ORDER = order_stoi[\"<UNK>\"]\n",
        "\n",
        "def map_list_to_ids(lst, stoi, unk_token=\"<UNK>\"):\n",
        "    unk_idx = stoi.get(unk_token, None)\n",
        "    out = []\n",
        "    for x in lst:\n",
        "        idx = stoi.get(x)\n",
        "        if idx is None:\n",
        "            if unk_idx is not None:\n",
        "                out.append(unk_idx)\n",
        "        else:\n",
        "            out.append(idx)\n",
        "    return out\n",
        "\n",
        "# Diagnosis codes\n",
        "df[\"diag_ids\"] = df[\"diagnoses_icd_code_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, diag_stoi)\n",
        ")\n",
        "\n",
        "# Combined procedure + hcpcs ids\n",
        "def build_proc_ids(row):\n",
        "    ids = []\n",
        "    for code in row[\"procedures_icd_code_list\"]:\n",
        "        tok = \"PROC_\" + code\n",
        "        ids.append(proc_all_stoi.get(tok, UNK_PROC))\n",
        "    for code in row[\"hcpcs_cd_list\"]:\n",
        "        tok = \"HCPCS_\" + code\n",
        "        ids.append(proc_all_stoi.get(tok, UNK_PROC))\n",
        "    return ids\n",
        "\n",
        "df[\"proc_ids\"] = df.apply(build_proc_ids, axis=1)\n",
        "\n",
        "# Medication\n",
        "df[\"med_ids\"] = df[\"medication_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, med_stoi)\n",
        ")\n",
        "\n",
        "# Order type\n",
        "df[\"order_ids\"] = df[\"order_type_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, order_stoi)\n",
        ")\n",
        "\n",
        "# Single categorical -> id\n",
        "df[\"gender_id\"] = df[\"gender\"].map(gender_stoi)\n",
        "df[\"race_id\"] = df[\"race\"].map(race_stoi)\n",
        "df[\"service_id\"] = df[\"curr_service\"].map(service_stoi)\n",
        "df[\"drg_code_id\"] = df[\"drg_code\"].astype(int).map(drg_code_stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTxymZbB-_YY",
        "outputId": "6763a139-e55e-4edc-fa59-1baf37b1e79e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================ SAMPLE DATA (after encoding) ================\n",
            "\n",
            "--- Row 0 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 279\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 135\n",
            "diagnoses_icd_code_list   : ['07071' '78959' '2875' '2761' '496' '5715' 'V08' '3051']\n",
            "diag_ids                  : [1, 2, 3, 4, 5, 6, 7, 8]\n",
            "procedures_icd_code_list  : ['5491']\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : [1]\n",
            "medication_list           : ['Raltegravir' 'Rifaximin' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Calcium Carbonate' 'Rifaximin' 'Raltegravir'\n",
            " 'Emtricitabine-Tenofovir (Truvada)' 'Sulfameth/Trimethoprim DS'\n",
            " 'Furosemide' 'Tiotropium Bromide' 'Albuterol Inhaler' 'Lactulose'\n",
            " 'Heparin' 'Sodium Chloride 0.9%  Flush' 'Acetaminophen' 'Heparin'\n",
            " 'Lactulose' 'Albumin 25% (12.5g / 50mL)' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Albumin 25% (12.5g / 50mL)' 'Albumin 25% (12.5g / 50mL)']\n",
            "med_ids                   : [1, 2, 3, 4, 2, 1, 5, 6, 7, 8, '...(+11 more)']\n",
            "order_type_list           : ['Medications' 'General Care' 'Nutrition' 'Blood Bank' 'Lab' 'Respiratory'\n",
            " 'Medications' 'Medications' 'ADT orders' 'Lab' 'Lab' 'Medications'\n",
            " 'ADT orders' 'ADT orders' 'ADT orders' 'ADT orders' 'Lab' 'ADT orders'\n",
            " 'Lab' 'General Care' 'Nutrition' 'Medications' 'ADT orders' 'Lab'\n",
            " 'IV therapy' 'Medications' 'General Care' 'General Care' 'Nutrition'\n",
            " 'Medications' 'Nutrition' 'Lab' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications']\n",
            "order_ids                 : [1, 2, 3, 4, 5, 6, 1, 1, 7, 5, '...(+32 more)']\n",
            "\n",
            "\n",
            "--- Row 1 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 283\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 139\n",
            "diagnoses_icd_code_list   : ['07054' '78959' 'V462' '5715' '2767' '2761' '496' 'V08' '3051' '78791']\n",
            "diag_ids                  : [9, 2, 10, 6, 11, 4, 5, 7, 8, 12]\n",
            "procedures_icd_code_list  : ['5491']\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : [1]\n",
            "medication_list           : ['Heparin' 'Raltegravir' 'Rifaximin' 'Emtricitabine-Tenofovir (Truvada)'\n",
            " 'Lactulose' 'Fluticasone Propionate 110mcg' 'Tiotropium Bromide'\n",
            " 'Albuterol Inhaler' 'Calcium Gluconate' 'Dextrose 50%'\n",
            " 'Insulin (Regular) for Hyperkalemia' 'Sodium Polystyrene Sulfonate'\n",
            " 'TraMADOL (Ultram)' 'Lactulose' 'Heparin' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Lactulose' 'Albuterol Inhaler' 'Insulin (Regular) for Hyperkalemia'\n",
            " 'Sodium Polystyrene Sulfonate' 'Calcium Gluconate' 'Dextrose 50%'\n",
            " 'Furosemide' 'Albumin 25% (12.5g / 50mL)' 'Calcium Carbonate'\n",
            " 'Raltegravir' 'Rifaximin' 'Zolpidem Tartrate'\n",
            " 'Fluticasone Propionate 110mcg' 'Albuterol Inhaler' 'Heparin'\n",
            " 'Sodium Chloride 0.9%  Flush' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Calcium Carbonate']\n",
            "med_ids                   : [11, 1, 2, 5, 10, 14, 8, 9, 15, 16, '...(+24 more)']\n",
            "order_type_list           : ['Lab' 'ADT orders' 'Lab' 'General Care' 'General Care' 'Nutrition'\n",
            " 'Medications' 'ADT orders' 'Lab' 'IV therapy' 'Medications'\n",
            " 'General Care' 'General Care' 'General Care' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Radiology' 'Nutrition' 'Nutrition' 'ADT orders' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Cardiology' 'Lab'\n",
            " 'Medications' 'Consults' 'Consults' 'General Care' 'Medications' 'Lab'\n",
            " 'Medications' 'Lab' 'Lab' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'General Care' 'General Care' 'Medications' 'Medications'\n",
            " 'Lab']\n",
            "order_ids                 : [5, 7, 5, 2, 2, 3, 1, 7, 5, 8, '...(+45 more)']\n",
            "\n",
            "\n",
            "--- Row 2 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 207\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 103\n",
            "diagnoses_icd_code_list   : ['45829' '07044' '7994' '2761' '78959' '2767' '3051' 'V08' 'V4986' 'V462'\n",
            " '496' '29680' '5715']\n",
            "diag_ids                  : [13, 14, 15, 4, 2, 11, 8, 7, 16, 10, '...(+3 more)']\n",
            "procedures_icd_code_list  : []\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : []\n",
            "medication_list           : ['Lactulose' 'TraMADOL (Ultram)' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Albumin 25% (12.5g / 50mL)' 'Bisacodyl' 'Calcium Carbonate'\n",
            " 'Docusate Sodium (Liquid)' 'Emtricitabine-Tenofovir (Truvada)'\n",
            " 'Fluticasone Propionate 110mcg' 'Heparin' 'Lactulose' 'Raltegravir'\n",
            " 'Rifaximin' 'Tiotropium Bromide']\n",
            "med_ids                   : [10, 19, 3, 13, 21, 4, 22, 5, 14, 11, '...(+4 more)']\n",
            "order_type_list           : ['Lab' 'ADT orders' 'Lab' 'General Care' 'General Care' 'General Care'\n",
            " 'Nutrition' 'Medications' 'ADT orders' 'Lab' 'General Care'\n",
            " 'General Care' 'General Care' 'Nutrition' 'Medications' 'Medications'\n",
            " 'Medications' 'General Care' 'Medications' 'Respiratory' 'General Care'\n",
            " 'Lab' 'Medications' 'Lab' 'Nutrition' 'Medications' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Lab' 'ADT orders' 'Lab' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Nutrition' 'Nutrition' 'IV therapy' 'Medications' 'General Care'\n",
            " 'General Care' 'General Care' 'Lab' 'General Care' 'Medications'\n",
            " 'Medications' 'Lab' 'General Care' 'ADT orders' 'Lab' 'Medications'\n",
            " 'Consults' 'Consults' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications']\n",
            "order_ids                 : [5, 7, 5, 2, 2, 2, 3, 1, 7, 5, '...(+61 more)']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def summarize_list(lst, max_len=10):\n",
        "    if lst is None:\n",
        "        return None\n",
        "    if len(lst) <= max_len:\n",
        "        return lst\n",
        "    return lst[:max_len] + [\"...(+{} more)\".format(len(lst) - max_len)]\n",
        "\n",
        "\n",
        "# Print 3 samples\n",
        "cols_to_show = [\n",
        "    \"gender\", \"race\", \"curr_service\", \"drg_code\",\n",
        "    \"gender_id\", \"race_id\", \"service_id\", \"drg_code_id\",\n",
        "    \"diagnoses_icd_code_list\", \"diag_ids\",\n",
        "    \"procedures_icd_code_list\", \"hcpcs_cd_list\", \"proc_ids\",\n",
        "    \"medication_list\", \"med_ids\",\n",
        "    \"order_type_list\", \"order_ids\",\n",
        "]\n",
        "\n",
        "print(\"\\n================ SAMPLE DATA (after encoding) ==============\\n\")\n",
        "\n",
        "for i in range(3):\n",
        "    row = df.iloc[i]\n",
        "    print(f\"--- Row {i} ---\")\n",
        "\n",
        "    for c in cols_to_show:\n",
        "        val = row[c]\n",
        "\n",
        "        # Summarize list\n",
        "        if isinstance(val, list):\n",
        "            val = summarize_list(val)\n",
        "\n",
        "        print(f\"{c:25} : {val}\")\n",
        "\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D0LX9ClZuTkx"
      },
      "outputs": [],
      "source": [
        "class LOSDataset(Dataset):\n",
        "    def __init__(self, df, use_log_target=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.use_log_target = use_log_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        sample = {\n",
        "            # tabular\n",
        "            \"age\": float(row[\"anchor_age\"]),\n",
        "            \"gender_id\": int(row[\"gender_id\"]),\n",
        "            \"race_id\": int(row[\"race_id\"]),\n",
        "            \"service_id\": int(row[\"service_id\"]),\n",
        "            \"drg_code_id\": int(row[\"drg_code_id\"]),\n",
        "            \"drg_severity\": float(row[\"drg_severity\"]),\n",
        "            \"drg_mortality\": float(row[\"drg_mortality\"]),\n",
        "\n",
        "            # List-type IDs\n",
        "            \"diag_ids\": row[\"diag_ids\"],\n",
        "            \"proc_ids\": row[\"proc_ids\"],\n",
        "            \"med_ids\": row[\"med_ids\"],\n",
        "            \"order_ids\": row[\"order_ids\"],\n",
        "        }\n",
        "\n",
        "        # target\n",
        "        los = float(row[\"los_hours\"])\n",
        "        if self.use_log_target:\n",
        "            sample[\"target\"] = np.log1p(los)\n",
        "        else:\n",
        "            sample[\"target\"] = los\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZBngU2IuZuA"
      },
      "outputs": [],
      "source": [
        "def los_collate_fn(batch):\n",
        "    B = len(batch)\n",
        "\n",
        "    # ----- Tabular stack -----\n",
        "    age = torch.tensor([b[\"age\"] for b in batch], dtype=torch.float32)\n",
        "    gender_id = torch.tensor([b[\"gender_id\"] for b in batch], dtype=torch.long)\n",
        "    race_id = torch.tensor([b[\"race_id\"] for b in batch], dtype=torch.long)\n",
        "    service_id = torch.tensor([b[\"service_id\"] for b in batch], dtype=torch.long)\n",
        "    drg_code_id = torch.tensor([b[\"drg_code_id\"] for b in batch], dtype=torch.long)\n",
        "    drg_severity = torch.tensor([b[\"drg_severity\"] for b in batch], dtype=torch.float32)\n",
        "    drg_mortality = torch.tensor([b[\"drg_mortality\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    target = torch.tensor([b[\"target\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    # ----- List-type: diag / proc / med / order -----\n",
        "    def build_bag_inputs(key):\n",
        "        codes_all = []\n",
        "        offsets = [0]\n",
        "        for b in batch:\n",
        "            ids = b[key]\n",
        "            codes_all.extend(ids)\n",
        "            offsets.append(len(codes_all))\n",
        "        if len(codes_all) == 0:\n",
        "            codes_tensor = torch.empty(0, dtype=torch.long)\n",
        "        else:\n",
        "            codes_tensor = torch.tensor(codes_all, dtype=torch.long)\n",
        "        offsets_tensor = torch.tensor(offsets, dtype=torch.long)\n",
        "        return codes_tensor, offsets_tensor\n",
        "\n",
        "    diag_codes, diag_offsets = build_bag_inputs(\"diag_ids\")\n",
        "    proc_codes, proc_offsets = build_bag_inputs(\"proc_ids\")\n",
        "    med_codes, med_offsets = build_bag_inputs(\"med_ids\")\n",
        "    order_codes, order_offsets = build_bag_inputs(\"order_ids\")\n",
        "\n",
        "    batch_out = {\n",
        "        \"age\": age,\n",
        "        \"gender_id\": gender_id,\n",
        "        \"race_id\": race_id,\n",
        "        \"service_id\": service_id,\n",
        "        \"drg_code_id\": drg_code_id,\n",
        "        \"drg_severity\": drg_severity,\n",
        "        \"drg_mortality\": drg_mortality,\n",
        "        \"diag_codes\": diag_codes,\n",
        "        \"diag_offsets\": diag_offsets,\n",
        "        \"proc_codes\": proc_codes,\n",
        "        \"proc_offsets\": proc_offsets,\n",
        "        \"med_codes\": med_codes,\n",
        "        \"med_offsets\": med_offsets,\n",
        "        \"order_codes\": order_codes,\n",
        "        \"order_offsets\": order_offsets,\n",
        "        \"target\": target,\n",
        "    }\n",
        "\n",
        "    return batch_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmEgyvbPuaOO",
        "outputId": "e044b6fc-dae7-4f9d-cf72-0cae71fac937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#train: 297362, #val: 63720, #test: 63721\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "import torch\n",
        "\n",
        "# Create Dataset\n",
        "dataset = LOSDataset(df, use_log_target=False)\n",
        "\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * 0.7)\n",
        "n_val = int(n_total * 0.15)\n",
        "n_test = n_total - n_train - n_val   # Remaining\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test], generator=g)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "print(f\"#train: {len(train_ds)}, #val: {len(val_ds)}, #test: {len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoKFkMU2udG8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    # ----- Tabular categorical vocab sizes -----\n",
        "    num_genders: int          # e.g. {\"M\", \"F\"} -> 2\n",
        "    num_races: int            # unique race categories\n",
        "    num_services: int         # curr_service (MED, ORTHO, ...)\n",
        "    num_drg_codes: int        # drg_code vocab size\n",
        "\n",
        "    # ----- Code vocab sizes -----\n",
        "    diag_vocab_size: int      # diagnoses_icd_code_list vocab\n",
        "    proc_vocab_size: int      # procedures_icd_code_list + hcpcs_cd_list combined vocab\n",
        "    med_vocab_size: int       # medication_list vocab\n",
        "    order_vocab_size: int     # order_type_list vocab\n",
        "\n",
        "    # ----- Embedding dimensions -----\n",
        "    emb_dim_gender: int = 4\n",
        "    emb_dim_race: int = 8\n",
        "    emb_dim_service: int = 8\n",
        "    emb_dim_drg: int = 16\n",
        "\n",
        "    emb_dim_diag: int = 32\n",
        "    emb_dim_proc: int = 32\n",
        "    emb_dim_med: int = 32\n",
        "    emb_dim_order: int = 16\n",
        "\n",
        "    # ----- Hidden dimension for the single MLP -----\n",
        "    hidden_dim: int = 128 # This will be the hidden dimension for the combined MLP\n",
        "    dropout: float = 0.2\n",
        "\n",
        "\n",
        "class MultiModalLOSModel(nn.Module):\n",
        "    def __init__(self, cfg: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        # ------------- Embeddings for all categorical and list features -------------\n",
        "        self.gender_emb = nn.Embedding(cfg.num_genders, cfg.emb_dim_gender)\n",
        "        self.race_emb = nn.Embedding(cfg.num_races, cfg.emb_dim_race)\n",
        "        self.service_emb = nn.Embedding(cfg.num_services, cfg.emb_dim_service)\n",
        "        self.drg_emb = nn.Embedding(cfg.num_drg_codes, cfg.emb_dim_drg)\n",
        "\n",
        "        self.diag_emb = nn.EmbeddingBag(\n",
        "            cfg.diag_vocab_size, cfg.emb_dim_diag,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.proc_emb = nn.EmbeddingBag(\n",
        "            cfg.proc_vocab_size, cfg.emb_dim_proc,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.med_emb = nn.EmbeddingBag(\n",
        "            cfg.med_vocab_size, cfg.emb_dim_med,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.order_emb = nn.EmbeddingBag(\n",
        "            cfg.order_vocab_size, cfg.emb_dim_order,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "\n",
        "        # Calculate total input dimension for the single MLP\n",
        "        total_in_dim = (\n",
        "            3 # for age, drg_severity, drg_mortality\n",
        "            + cfg.emb_dim_gender\n",
        "            + cfg.emb_dim_race\n",
        "            + cfg.emb_dim_service\n",
        "            + cfg.emb_dim_drg\n",
        "            + cfg.emb_dim_diag\n",
        "            + cfg.emb_dim_proc\n",
        "            + cfg.emb_dim_med\n",
        "            + cfg.emb_dim_order\n",
        "        )\n",
        "\n",
        "        # Single MLP for all combined features\n",
        "        self.main_mlp = nn.Sequential(\n",
        "            nn.Linear(total_in_dim, cfg.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.Linear(cfg.hidden_dim, cfg.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "        )\n",
        "\n",
        "        # Final regression output layer (LOS prediction)\n",
        "        self.out = nn.Linear(cfg.hidden_dim, 1)\n",
        "\n",
        "    # Forward\n",
        "    def forward(\n",
        "        self,\n",
        "        # ----- Tabular -----\n",
        "        age,               # (B,) float tensor (anchor_age or normalized)\n",
        "        gender_idx,        # (B,) long tensor\n",
        "        race_idx,          # (B,) long tensor\n",
        "        service_idx,       # (B,) long tensor (curr_service)\n",
        "        drg_code_idx,      # (B,) long tensor\n",
        "        drg_severity,      # (B,) float or long (recommend normalizing to float first)\n",
        "        drg_mortality,     # (B,) float or long\n",
        "\n",
        "        # ----- Diagnoses (EmbeddingBag) -----\n",
        "        diag_codes,        # (N_diag_codes,) long tensor (flattened)\n",
        "        diag_offsets,      # (B+1,) long tensor, offset for EmbeddingBag\n",
        "\n",
        "        # ----- Procedures (EmbeddingBag) -----\n",
        "        proc_codes,        # (N_proc_codes,) long tensor\n",
        "        proc_offsets,      # (B+1,) long tensor\n",
        "\n",
        "        # ----- Medications (EmbeddingBag) -----\n",
        "        med_codes,         # (N_med_codes,) long tensor\n",
        "        med_offsets,       # (B+1,) long tensor\n",
        "\n",
        "        # ----- Order types (EmbeddingBag) -----\n",
        "        order_codes,       # (N_order_codes,) long tensor\n",
        "        order_offsets,     # (B+1,) long tensor\n",
        "    ):\n",
        "        # Embeddings for categorical features\n",
        "        g_emb = self.gender_emb(gender_idx)   # (B, emb_dim_gender)\n",
        "        r_emb = self.race_emb(race_idx)       # (B, emb_dim_race)\n",
        "        s_emb = self.service_emb(service_idx) # (B, emb_dim_service)\n",
        "        d_emb = self.drg_emb(drg_code_idx)    # (B, emb_dim_drg)\n",
        "\n",
        "        # EmbeddingBag for list features\n",
        "        diag_bag = self.diag_emb(diag_codes, diag_offsets)  # (B, emb_dim_diag)\n",
        "        proc_bag = self.proc_emb(proc_codes, proc_offsets)  # (B, emb_dim_proc)\n",
        "        med_bag = self.med_emb(med_codes, med_offsets)      # (B, emb_dim_med)\n",
        "        order_bag = self.order_emb(order_codes, order_offsets) # (B, emb_dim_order)\n",
        "\n",
        "        # Continuous features (unsqueeze for concatenation)\n",
        "        age = age.float().unsqueeze(-1)                 # (B, 1)\n",
        "        sev = drg_severity.float().unsqueeze(-1)        # (B, 1)\n",
        "        mort = drg_mortality.float().unsqueeze(-1)      # (B, 1)\n",
        "\n",
        "        # Concatenate all features into a single tensor\n",
        "        all_features = torch.cat(\n",
        "            [\n",
        "                age, sev, mort,\n",
        "                g_emb, r_emb, s_emb, d_emb,\n",
        "                diag_bag, proc_bag, med_bag, order_bag\n",
        "            ],\n",
        "            dim=-1\n",
        "        )\n",
        "\n",
        "        # Pass the combined features through the main MLP\n",
        "        h = self.main_mlp(all_features)\n",
        "        out = self.out(h).squeeze(-1)  # (B,)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZm2f-aivdkb",
        "outputId": "b8c729ff-fa6d-412b-9550-06cb59d30367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "========== Epoch 1/20 ==========\n",
            "  [Epoch 1 | Step 0/1162] AvgTrainLoss=45002.0859\n",
            "  [Epoch 1 | Step 100/1162] AvgTrainLoss=38802.9024\n",
            "  [Epoch 1 | Step 200/1162] AvgTrainLoss=33965.8014\n",
            "  [Epoch 1 | Step 300/1162] AvgTrainLoss=32617.4853\n",
            "  [Epoch 1 | Step 400/1162] AvgTrainLoss=30746.0077\n",
            "  [Epoch 1 | Step 500/1162] AvgTrainLoss=29548.1408\n",
            "  [Epoch 1 | Step 600/1162] AvgTrainLoss=29496.5476\n",
            "  [Epoch 1 | Step 700/1162] AvgTrainLoss=28647.0902\n",
            "  [Epoch 1 | Step 800/1162] AvgTrainLoss=28036.7451\n",
            "  [Epoch 1 | Step 900/1162] AvgTrainLoss=27113.4442\n",
            "  [Epoch 1 | Step 1000/1162] AvgTrainLoss=26588.8289\n",
            "  [Epoch 1 | Step 1100/1162] AvgTrainLoss=26351.3900\n",
            "[Epoch 001] train_loss(MSE)=26120.7227 | val_loss(MSE)=20636.9439 | val_MAE(hours)=69.41\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 2/20 ==========\n",
            "  [Epoch 2 | Step 0/1162] AvgTrainLoss=18095.1328\n",
            "  [Epoch 2 | Step 100/1162] AvgTrainLoss=26929.4045\n",
            "  [Epoch 2 | Step 200/1162] AvgTrainLoss=23555.4764\n",
            "  [Epoch 2 | Step 300/1162] AvgTrainLoss=21696.8348\n",
            "  [Epoch 2 | Step 400/1162] AvgTrainLoss=20832.5180\n",
            "  [Epoch 2 | Step 500/1162] AvgTrainLoss=20476.3754\n",
            "  [Epoch 2 | Step 600/1162] AvgTrainLoss=20558.0759\n",
            "  [Epoch 2 | Step 700/1162] AvgTrainLoss=20509.1327\n",
            "  [Epoch 2 | Step 800/1162] AvgTrainLoss=20336.4574\n",
            "  [Epoch 2 | Step 900/1162] AvgTrainLoss=20231.6021\n",
            "  [Epoch 2 | Step 1000/1162] AvgTrainLoss=20265.4106\n",
            "  [Epoch 2 | Step 1100/1162] AvgTrainLoss=20287.0035\n",
            "[Epoch 002] train_loss(MSE)=20315.2287 | val_loss(MSE)=19414.6172 | val_MAE(hours)=72.65\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 3/20 ==========\n",
            "  [Epoch 3 | Step 0/1162] AvgTrainLoss=13873.1045\n",
            "  [Epoch 3 | Step 100/1162] AvgTrainLoss=19349.9488\n",
            "  [Epoch 3 | Step 200/1162] AvgTrainLoss=21734.4473\n",
            "  [Epoch 3 | Step 300/1162] AvgTrainLoss=20864.4567\n",
            "  [Epoch 3 | Step 400/1162] AvgTrainLoss=19753.8344\n",
            "  [Epoch 3 | Step 500/1162] AvgTrainLoss=19184.4881\n",
            "  [Epoch 3 | Step 600/1162] AvgTrainLoss=19521.4252\n",
            "  [Epoch 3 | Step 700/1162] AvgTrainLoss=19332.8659\n",
            "  [Epoch 3 | Step 800/1162] AvgTrainLoss=19375.2074\n",
            "  [Epoch 3 | Step 900/1162] AvgTrainLoss=19391.0477\n",
            "  [Epoch 3 | Step 1000/1162] AvgTrainLoss=18965.4189\n",
            "  [Epoch 3 | Step 1100/1162] AvgTrainLoss=19041.7791\n",
            "[Epoch 003] train_loss(MSE)=18905.6513 | val_loss(MSE)=18633.5970 | val_MAE(hours)=64.88\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 4/20 ==========\n",
            "  [Epoch 4 | Step 0/1162] AvgTrainLoss=17095.2852\n",
            "  [Epoch 4 | Step 100/1162] AvgTrainLoss=19083.0063\n",
            "  [Epoch 4 | Step 200/1162] AvgTrainLoss=18610.8807\n",
            "  [Epoch 4 | Step 300/1162] AvgTrainLoss=17971.7895\n",
            "  [Epoch 4 | Step 400/1162] AvgTrainLoss=18444.1753\n",
            "  [Epoch 4 | Step 500/1162] AvgTrainLoss=18290.1961\n",
            "  [Epoch 4 | Step 600/1162] AvgTrainLoss=17849.7902\n",
            "  [Epoch 4 | Step 700/1162] AvgTrainLoss=18092.4540\n",
            "  [Epoch 4 | Step 800/1162] AvgTrainLoss=17846.0445\n",
            "  [Epoch 4 | Step 900/1162] AvgTrainLoss=18422.7207\n",
            "  [Epoch 4 | Step 1000/1162] AvgTrainLoss=18265.8469\n",
            "  [Epoch 4 | Step 1100/1162] AvgTrainLoss=18182.8260\n",
            "[Epoch 004] train_loss(MSE)=18052.4104 | val_loss(MSE)=18309.0266 | val_MAE(hours)=64.91\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 5/20 ==========\n",
            "  [Epoch 5 | Step 0/1162] AvgTrainLoss=82338.7656\n",
            "  [Epoch 5 | Step 100/1162] AvgTrainLoss=20572.9731\n",
            "  [Epoch 5 | Step 200/1162] AvgTrainLoss=17809.6221\n",
            "  [Epoch 5 | Step 300/1162] AvgTrainLoss=17517.8712\n",
            "  [Epoch 5 | Step 400/1162] AvgTrainLoss=17246.6983\n",
            "  [Epoch 5 | Step 500/1162] AvgTrainLoss=17712.5428\n",
            "  [Epoch 5 | Step 600/1162] AvgTrainLoss=17426.2723\n",
            "  [Epoch 5 | Step 700/1162] AvgTrainLoss=17510.5835\n",
            "  [Epoch 5 | Step 800/1162] AvgTrainLoss=17617.7729\n",
            "  [Epoch 5 | Step 900/1162] AvgTrainLoss=17535.9567\n",
            "  [Epoch 5 | Step 1000/1162] AvgTrainLoss=17570.6160\n",
            "  [Epoch 5 | Step 1100/1162] AvgTrainLoss=17321.2111\n",
            "[Epoch 005] train_loss(MSE)=17279.4955 | val_loss(MSE)=18250.0272 | val_MAE(hours)=64.51\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 6/20 ==========\n",
            "  [Epoch 6 | Step 0/1162] AvgTrainLoss=8062.8276\n",
            "  [Epoch 6 | Step 100/1162] AvgTrainLoss=20669.7539\n",
            "  [Epoch 6 | Step 200/1162] AvgTrainLoss=18992.0005\n",
            "  [Epoch 6 | Step 300/1162] AvgTrainLoss=17978.6706\n",
            "  [Epoch 6 | Step 400/1162] AvgTrainLoss=16867.5872\n",
            "  [Epoch 6 | Step 500/1162] AvgTrainLoss=16782.9121\n",
            "  [Epoch 6 | Step 600/1162] AvgTrainLoss=16966.0179\n",
            "  [Epoch 6 | Step 700/1162] AvgTrainLoss=16790.3462\n",
            "  [Epoch 6 | Step 800/1162] AvgTrainLoss=16570.7063\n",
            "  [Epoch 6 | Step 900/1162] AvgTrainLoss=16368.6825\n",
            "  [Epoch 6 | Step 1000/1162] AvgTrainLoss=16067.5223\n",
            "  [Epoch 6 | Step 1100/1162] AvgTrainLoss=16286.9993\n",
            "[Epoch 006] train_loss(MSE)=16612.8779 | val_loss(MSE)=18622.2150 | val_MAE(hours)=67.09\n",
            "\n",
            "========== Epoch 7/20 ==========\n",
            "  [Epoch 7 | Step 0/1162] AvgTrainLoss=25119.3301\n",
            "  [Epoch 7 | Step 100/1162] AvgTrainLoss=14500.0364\n",
            "  [Epoch 7 | Step 200/1162] AvgTrainLoss=15564.9202\n",
            "  [Epoch 7 | Step 300/1162] AvgTrainLoss=15173.7094\n",
            "  [Epoch 7 | Step 400/1162] AvgTrainLoss=15769.2228\n",
            "  [Epoch 7 | Step 500/1162] AvgTrainLoss=15587.6219\n",
            "  [Epoch 7 | Step 600/1162] AvgTrainLoss=16435.4915\n",
            "  [Epoch 7 | Step 700/1162] AvgTrainLoss=16421.4466\n",
            "  [Epoch 7 | Step 800/1162] AvgTrainLoss=16367.2770\n",
            "  [Epoch 7 | Step 900/1162] AvgTrainLoss=16260.4028\n",
            "  [Epoch 7 | Step 1000/1162] AvgTrainLoss=16092.9361\n",
            "  [Epoch 7 | Step 1100/1162] AvgTrainLoss=16006.2488\n",
            "[Epoch 007] train_loss(MSE)=16059.3918 | val_loss(MSE)=18632.2128 | val_MAE(hours)=67.14\n",
            "\n",
            "========== Epoch 8/20 ==========\n",
            "  [Epoch 8 | Step 0/1162] AvgTrainLoss=24361.5273\n",
            "  [Epoch 8 | Step 100/1162] AvgTrainLoss=14049.5077\n",
            "  [Epoch 8 | Step 200/1162] AvgTrainLoss=14854.9529\n",
            "  [Epoch 8 | Step 300/1162] AvgTrainLoss=15027.9257\n",
            "  [Epoch 8 | Step 400/1162] AvgTrainLoss=14745.8532\n",
            "  [Epoch 8 | Step 500/1162] AvgTrainLoss=15623.7458\n",
            "  [Epoch 8 | Step 600/1162] AvgTrainLoss=15574.1942\n",
            "  [Epoch 8 | Step 700/1162] AvgTrainLoss=15651.4873\n",
            "  [Epoch 8 | Step 800/1162] AvgTrainLoss=15540.3320\n",
            "  [Epoch 8 | Step 900/1162] AvgTrainLoss=15446.6463\n",
            "  [Epoch 8 | Step 1000/1162] AvgTrainLoss=15522.1219\n",
            "  [Epoch 8 | Step 1100/1162] AvgTrainLoss=15538.5831\n",
            "[Epoch 008] train_loss(MSE)=15445.2015 | val_loss(MSE)=19025.5805 | val_MAE(hours)=63.90\n",
            "\n",
            "========== Epoch 9/20 ==========\n",
            "  [Epoch 9 | Step 0/1162] AvgTrainLoss=6154.8228\n",
            "  [Epoch 9 | Step 100/1162] AvgTrainLoss=14788.9330\n",
            "  [Epoch 9 | Step 200/1162] AvgTrainLoss=15384.1840\n",
            "  [Epoch 9 | Step 300/1162] AvgTrainLoss=15068.9984\n",
            "  [Epoch 9 | Step 400/1162] AvgTrainLoss=14653.4411\n",
            "  [Epoch 9 | Step 500/1162] AvgTrainLoss=15673.6987\n",
            "  [Epoch 9 | Step 600/1162] AvgTrainLoss=15421.3980\n",
            "  [Epoch 9 | Step 700/1162] AvgTrainLoss=15189.0106\n",
            "  [Epoch 9 | Step 800/1162] AvgTrainLoss=15020.8117\n",
            "  [Epoch 9 | Step 900/1162] AvgTrainLoss=14891.6190\n",
            "  [Epoch 9 | Step 1000/1162] AvgTrainLoss=14916.1161\n",
            "  [Epoch 9 | Step 1100/1162] AvgTrainLoss=14775.9334\n",
            "[Epoch 009] train_loss(MSE)=14871.1460 | val_loss(MSE)=20453.9883 | val_MAE(hours)=67.42\n",
            "\n",
            "========== Epoch 10/20 ==========\n",
            "  [Epoch 10 | Step 0/1162] AvgTrainLoss=10813.9512\n",
            "  [Epoch 10 | Step 100/1162] AvgTrainLoss=14442.7344\n",
            "  [Epoch 10 | Step 200/1162] AvgTrainLoss=13419.6741\n",
            "  [Epoch 10 | Step 300/1162] AvgTrainLoss=13691.3398\n",
            "  [Epoch 10 | Step 400/1162] AvgTrainLoss=13710.5778\n",
            "  [Epoch 10 | Step 500/1162] AvgTrainLoss=13685.8074\n",
            "  [Epoch 10 | Step 600/1162] AvgTrainLoss=13779.1074\n",
            "  [Epoch 10 | Step 700/1162] AvgTrainLoss=13823.5617\n",
            "  [Epoch 10 | Step 800/1162] AvgTrainLoss=14587.2954\n",
            "  [Epoch 10 | Step 900/1162] AvgTrainLoss=14490.0137\n",
            "  [Epoch 10 | Step 1000/1162] AvgTrainLoss=14354.6674\n",
            "  [Epoch 10 | Step 1100/1162] AvgTrainLoss=14307.1331\n",
            "[Epoch 010] train_loss(MSE)=14287.1829 | val_loss(MSE)=20014.5152 | val_MAE(hours)=66.43\n",
            "\n",
            "========== Epoch 11/20 ==========\n",
            "  [Epoch 11 | Step 0/1162] AvgTrainLoss=9470.2568\n",
            "  [Epoch 11 | Step 100/1162] AvgTrainLoss=13377.3487\n",
            "  [Epoch 11 | Step 200/1162] AvgTrainLoss=13010.3977\n",
            "  [Epoch 11 | Step 300/1162] AvgTrainLoss=13235.9596\n",
            "  [Epoch 11 | Step 400/1162] AvgTrainLoss=13327.7226\n",
            "  [Epoch 11 | Step 500/1162] AvgTrainLoss=13096.5755\n",
            "  [Epoch 11 | Step 600/1162] AvgTrainLoss=13175.8371\n",
            "  [Epoch 11 | Step 700/1162] AvgTrainLoss=14005.6776\n",
            "  [Epoch 11 | Step 800/1162] AvgTrainLoss=14115.8490\n",
            "  [Epoch 11 | Step 900/1162] AvgTrainLoss=13998.0217\n",
            "  [Epoch 11 | Step 1000/1162] AvgTrainLoss=13879.1784\n",
            "  [Epoch 11 | Step 1100/1162] AvgTrainLoss=13748.0932\n",
            "[Epoch 011] train_loss(MSE)=13750.9205 | val_loss(MSE)=20254.7574 | val_MAE(hours)=66.24\n",
            "\n",
            "========== Epoch 12/20 ==========\n",
            "  [Epoch 12 | Step 0/1162] AvgTrainLoss=12620.2588\n",
            "  [Epoch 12 | Step 100/1162] AvgTrainLoss=17528.8962\n",
            "  [Epoch 12 | Step 200/1162] AvgTrainLoss=15928.4297\n",
            "  [Epoch 12 | Step 300/1162] AvgTrainLoss=15194.0558\n",
            "  [Epoch 12 | Step 400/1162] AvgTrainLoss=14460.6736\n",
            "  [Epoch 12 | Step 500/1162] AvgTrainLoss=13932.8661\n",
            "  [Epoch 12 | Step 600/1162] AvgTrainLoss=13843.8925\n",
            "  [Epoch 12 | Step 700/1162] AvgTrainLoss=13767.6047\n",
            "  [Epoch 12 | Step 800/1162] AvgTrainLoss=13447.9899\n",
            "  [Epoch 12 | Step 900/1162] AvgTrainLoss=13411.5501\n",
            "  [Epoch 12 | Step 1000/1162] AvgTrainLoss=13374.1557\n",
            "  [Epoch 12 | Step 1100/1162] AvgTrainLoss=13343.5603\n",
            "[Epoch 012] train_loss(MSE)=13347.5609 | val_loss(MSE)=21258.6714 | val_MAE(hours)=66.78\n",
            "\n",
            "========== Epoch 13/20 ==========\n",
            "  [Epoch 13 | Step 0/1162] AvgTrainLoss=6585.3027\n",
            "  [Epoch 13 | Step 100/1162] AvgTrainLoss=11248.6216\n",
            "  [Epoch 13 | Step 200/1162] AvgTrainLoss=11487.8204\n",
            "  [Epoch 13 | Step 300/1162] AvgTrainLoss=11793.6013\n",
            "  [Epoch 13 | Step 400/1162] AvgTrainLoss=12190.4580\n",
            "  [Epoch 13 | Step 500/1162] AvgTrainLoss=12213.6133\n",
            "  [Epoch 13 | Step 600/1162] AvgTrainLoss=12246.0461\n",
            "  [Epoch 13 | Step 700/1162] AvgTrainLoss=12487.8740\n",
            "  [Epoch 13 | Step 800/1162] AvgTrainLoss=12486.2695\n",
            "  [Epoch 13 | Step 900/1162] AvgTrainLoss=12536.8994\n",
            "  [Epoch 13 | Step 1000/1162] AvgTrainLoss=12544.0466\n",
            "  [Epoch 13 | Step 1100/1162] AvgTrainLoss=12608.6932\n",
            "[Epoch 013] train_loss(MSE)=12777.7460 | val_loss(MSE)=23539.6191 | val_MAE(hours)=73.55\n",
            "\n",
            "========== Epoch 14/20 ==========\n",
            "  [Epoch 14 | Step 0/1162] AvgTrainLoss=10780.5000\n",
            "  [Epoch 14 | Step 100/1162] AvgTrainLoss=10717.0660\n",
            "  [Epoch 14 | Step 200/1162] AvgTrainLoss=11289.4430\n",
            "  [Epoch 14 | Step 300/1162] AvgTrainLoss=12086.1864\n",
            "  [Epoch 14 | Step 400/1162] AvgTrainLoss=12289.6336\n",
            "  [Epoch 14 | Step 500/1162] AvgTrainLoss=12531.3596\n",
            "  [Epoch 14 | Step 600/1162] AvgTrainLoss=12524.4543\n",
            "  [Epoch 14 | Step 700/1162] AvgTrainLoss=12486.6077\n",
            "  [Epoch 14 | Step 800/1162] AvgTrainLoss=12398.7820\n",
            "  [Epoch 14 | Step 900/1162] AvgTrainLoss=12330.7021\n",
            "  [Epoch 14 | Step 1000/1162] AvgTrainLoss=12223.2208\n",
            "  [Epoch 14 | Step 1100/1162] AvgTrainLoss=12485.6898\n",
            "[Epoch 014] train_loss(MSE)=12484.6711 | val_loss(MSE)=24121.5836 | val_MAE(hours)=68.15\n",
            "\n",
            "========== Epoch 15/20 ==========\n",
            "  [Epoch 15 | Step 0/1162] AvgTrainLoss=6655.4463\n",
            "  [Epoch 15 | Step 100/1162] AvgTrainLoss=11285.7346\n",
            "  [Epoch 15 | Step 200/1162] AvgTrainLoss=11563.7737\n",
            "  [Epoch 15 | Step 300/1162] AvgTrainLoss=11680.4936\n",
            "  [Epoch 15 | Step 400/1162] AvgTrainLoss=11792.0769\n",
            "  [Epoch 15 | Step 500/1162] AvgTrainLoss=11825.9828\n",
            "  [Epoch 15 | Step 600/1162] AvgTrainLoss=11974.0575\n",
            "  [Epoch 15 | Step 700/1162] AvgTrainLoss=12079.6534\n",
            "  [Epoch 15 | Step 800/1162] AvgTrainLoss=11946.9315\n",
            "  [Epoch 15 | Step 900/1162] AvgTrainLoss=11880.6600\n",
            "  [Epoch 15 | Step 1000/1162] AvgTrainLoss=12096.3488\n",
            "  [Epoch 15 | Step 1100/1162] AvgTrainLoss=11969.6175\n",
            "[Epoch 015] train_loss(MSE)=12010.1591 | val_loss(MSE)=24954.6669 | val_MAE(hours)=70.23\n",
            "\n",
            "========== Epoch 16/20 ==========\n",
            "  [Epoch 16 | Step 0/1162] AvgTrainLoss=9750.7539\n",
            "  [Epoch 16 | Step 100/1162] AvgTrainLoss=11435.9852\n",
            "  [Epoch 16 | Step 200/1162] AvgTrainLoss=11394.4408\n",
            "  [Epoch 16 | Step 300/1162] AvgTrainLoss=11491.9651\n",
            "  [Epoch 16 | Step 400/1162] AvgTrainLoss=11503.9567\n",
            "  [Epoch 16 | Step 500/1162] AvgTrainLoss=11554.0423\n",
            "  [Epoch 16 | Step 600/1162] AvgTrainLoss=11596.1992\n",
            "  [Epoch 16 | Step 700/1162] AvgTrainLoss=11472.1821\n",
            "  [Epoch 16 | Step 800/1162] AvgTrainLoss=11572.7700\n",
            "  [Epoch 16 | Step 900/1162] AvgTrainLoss=11534.6368\n",
            "  [Epoch 16 | Step 1000/1162] AvgTrainLoss=11517.4508\n",
            "  [Epoch 16 | Step 1100/1162] AvgTrainLoss=11501.4496\n",
            "[Epoch 016] train_loss(MSE)=11655.6664 | val_loss(MSE)=30170.8295 | val_MAE(hours)=71.00\n",
            "\n",
            "========== Epoch 17/20 ==========\n",
            "  [Epoch 17 | Step 0/1162] AvgTrainLoss=7225.3721\n",
            "  [Epoch 17 | Step 100/1162] AvgTrainLoss=10669.9300\n",
            "  [Epoch 17 | Step 200/1162] AvgTrainLoss=10948.0294\n",
            "  [Epoch 17 | Step 300/1162] AvgTrainLoss=11309.5660\n",
            "  [Epoch 17 | Step 400/1162] AvgTrainLoss=11300.9029\n",
            "  [Epoch 17 | Step 500/1162] AvgTrainLoss=11274.5473\n",
            "  [Epoch 17 | Step 600/1162] AvgTrainLoss=11335.5005\n",
            "  [Epoch 17 | Step 700/1162] AvgTrainLoss=11287.2043\n",
            "  [Epoch 17 | Step 800/1162] AvgTrainLoss=11257.5907\n",
            "  [Epoch 17 | Step 900/1162] AvgTrainLoss=11211.7424\n",
            "  [Epoch 17 | Step 1000/1162] AvgTrainLoss=11251.7280\n",
            "  [Epoch 17 | Step 1100/1162] AvgTrainLoss=11305.4646\n",
            "[Epoch 017] train_loss(MSE)=11275.7640 | val_loss(MSE)=28851.3703 | val_MAE(hours)=68.36\n",
            "\n",
            "========== Epoch 18/20 ==========\n",
            "  [Epoch 18 | Step 0/1162] AvgTrainLoss=8099.2969\n",
            "  [Epoch 18 | Step 100/1162] AvgTrainLoss=10833.7158\n",
            "  [Epoch 18 | Step 200/1162] AvgTrainLoss=11311.3877\n",
            "  [Epoch 18 | Step 300/1162] AvgTrainLoss=11320.1818\n",
            "  [Epoch 18 | Step 400/1162] AvgTrainLoss=11045.7244\n",
            "  [Epoch 18 | Step 500/1162] AvgTrainLoss=11142.6831\n",
            "  [Epoch 18 | Step 600/1162] AvgTrainLoss=10991.3795\n",
            "  [Epoch 18 | Step 700/1162] AvgTrainLoss=10963.1943\n",
            "  [Epoch 18 | Step 800/1162] AvgTrainLoss=10951.7333\n",
            "  [Epoch 18 | Step 900/1162] AvgTrainLoss=11023.9501\n",
            "  [Epoch 18 | Step 1000/1162] AvgTrainLoss=10930.4353\n",
            "  [Epoch 18 | Step 1100/1162] AvgTrainLoss=10993.2075\n",
            "[Epoch 018] train_loss(MSE)=11083.1389 | val_loss(MSE)=33997.3681 | val_MAE(hours)=69.77\n",
            "\n",
            "========== Epoch 19/20 ==========\n",
            "  [Epoch 19 | Step 0/1162] AvgTrainLoss=7244.7363\n",
            "  [Epoch 19 | Step 100/1162] AvgTrainLoss=10223.0403\n",
            "  [Epoch 19 | Step 200/1162] AvgTrainLoss=10412.8404\n",
            "  [Epoch 19 | Step 300/1162] AvgTrainLoss=10706.8048\n",
            "  [Epoch 19 | Step 400/1162] AvgTrainLoss=10971.1861\n",
            "  [Epoch 19 | Step 500/1162] AvgTrainLoss=10844.3072\n",
            "  [Epoch 19 | Step 600/1162] AvgTrainLoss=10800.2727\n",
            "  [Epoch 19 | Step 700/1162] AvgTrainLoss=10850.0831\n",
            "  [Epoch 19 | Step 800/1162] AvgTrainLoss=10844.1464\n",
            "  [Epoch 19 | Step 900/1162] AvgTrainLoss=10894.4149\n",
            "  [Epoch 19 | Step 1000/1162] AvgTrainLoss=10827.5089\n",
            "  [Epoch 19 | Step 1100/1162] AvgTrainLoss=10846.8650\n",
            "[Epoch 019] train_loss(MSE)=10831.5139 | val_loss(MSE)=32813.6798 | val_MAE(hours)=69.63\n",
            "\n",
            "========== Epoch 20/20 ==========\n",
            "  [Epoch 20 | Step 0/1162] AvgTrainLoss=8592.8662\n",
            "  [Epoch 20 | Step 100/1162] AvgTrainLoss=10483.7741\n",
            "  [Epoch 20 | Step 200/1162] AvgTrainLoss=10286.6762\n",
            "  [Epoch 20 | Step 300/1162] AvgTrainLoss=10263.1898\n",
            "  [Epoch 20 | Step 400/1162] AvgTrainLoss=10391.1235\n",
            "  [Epoch 20 | Step 500/1162] AvgTrainLoss=10383.1204\n",
            "  [Epoch 20 | Step 600/1162] AvgTrainLoss=10472.7064\n",
            "  [Epoch 20 | Step 700/1162] AvgTrainLoss=10440.0987\n",
            "  [Epoch 20 | Step 800/1162] AvgTrainLoss=10444.2884\n",
            "  [Epoch 20 | Step 900/1162] AvgTrainLoss=10491.1114\n",
            "  [Epoch 20 | Step 1000/1162] AvgTrainLoss=10525.0057\n",
            "  [Epoch 20 | Step 1100/1162] AvgTrainLoss=10560.7230\n",
            "[Epoch 020] train_loss(MSE)=10640.7618 | val_loss(MSE)=36855.2519 | val_MAE(hours)=70.00\n",
            "Training finished. Best val_loss: 18250.027157142576\n"
          ]
        }
      ],
      "source": [
        "# 1. Model / Configuration Creation\n",
        "\n",
        "cfg = ModelConfig(\n",
        "    num_genders=len(gender_stoi),\n",
        "    num_races=len(race_stoi),\n",
        "    num_services=len(service_stoi),\n",
        "    num_drg_codes=len(drg_code_stoi),\n",
        "    diag_vocab_size=len(diag_stoi),\n",
        "    proc_vocab_size=len(proc_all_stoi),\n",
        "    med_vocab_size=len(med_stoi),\n",
        "    order_vocab_size=len(order_stoi),\n",
        "    hidden_dim=128,\n",
        "    dropout=0.2\n",
        ")\n",
        "\n",
        "model = MultiModalLOSModel(cfg)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_model_path = \"los_multibranch_best.pt\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 2. Training Loop\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # ---------- Train ----------\n",
        "    model.train()\n",
        "    train_loss_sum = 0.0\n",
        "    train_count = 0\n",
        "\n",
        "    print(f\"\\n========== Epoch {epoch}/{NUM_EPOCHS} ==========\")\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # LOS\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = y_true.size(0)\n",
        "        train_loss_sum += loss.item() * bs\n",
        "        train_count += bs\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            avg_loss = train_loss_sum / train_count\n",
        "            print(f\"  [Epoch {epoch} | Step {batch_idx}/{len(train_loader)}] \"\n",
        "                  f\"AvgTrainLoss={avg_loss:.4f}\")\n",
        "\n",
        "    train_loss = train_loss_sum / train_count\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    model.eval()\n",
        "    val_loss_sum = 0.0\n",
        "    val_count = 0\n",
        "    val_mae_hours_sum = 0.0 \n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                     for k, v in batch.items()}\n",
        "\n",
        "            y_pred = model(\n",
        "                age=batch[\"age\"],\n",
        "                gender_idx=batch[\"gender_id\"],\n",
        "                race_idx=batch[\"race_id\"],\n",
        "                service_idx=batch[\"service_id\"],\n",
        "                drg_code_idx=batch[\"drg_code_id\"],\n",
        "                drg_severity=batch[\"drg_severity\"],\n",
        "                drg_mortality=batch[\"drg_mortality\"],\n",
        "                diag_codes=batch[\"diag_codes\"],\n",
        "                diag_offsets=batch[\"diag_offsets\"],\n",
        "                proc_codes=batch[\"proc_codes\"],\n",
        "                proc_offsets=batch[\"proc_offsets\"],\n",
        "                med_codes=batch[\"med_codes\"],\n",
        "                med_offsets=batch[\"med_offsets\"],\n",
        "                order_codes=batch[\"order_codes\"],\n",
        "                order_offsets=batch[\"order_offsets\"],\n",
        "            )\n",
        "\n",
        "            y_true = batch[\"target\"]\n",
        "\n",
        "            loss = criterion(y_pred, y_true)\n",
        "\n",
        "            bs = y_true.size(0)\n",
        "            val_loss_sum += loss.item() * bs\n",
        "            val_count += bs\n",
        "\n",
        "            y_true_hours = y_true\n",
        "            y_pred_hours = y_pred\n",
        "\n",
        "            mae_hours = torch.abs(y_pred_hours - y_true_hours).sum().item()\n",
        "            val_mae_hours_sum += mae_hours\n",
        "\n",
        "    val_loss = val_loss_sum / val_count\n",
        "    val_mae_hours = val_mae_hours_sum / val_count\n",
        "\n",
        "    print(f\"[Epoch {epoch:03d}] \"\n",
        "          f\"train_loss(MSE)={train_loss:.4f} | \"\n",
        "          f\"val_loss(MSE)={val_loss:.4f} | \"\n",
        "          f\"val_MAE(hours)={val_mae_hours:.2f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"  ↳ Best model updated, saved to {best_model_path}\")\n",
        "\n",
        "print(\"Training finished. Best val_loss:\", best_val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vDQN05751XD",
        "outputId": "584b2070-0571-4555-ba29-7f3ac5a14c00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Test set MAE =====\n",
            "Test MAE (hours): 63.74\n",
            "Test MAE (days) : 2.66\n"
          ]
        }
      ],
      "source": [
        "# 3. Calculate MAE (hours) on Test set\n",
        "\n",
        "best_model = MultiModalLOSModel(cfg).to(device)\n",
        "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "test_abs_error_sum = 0.0\n",
        "test_count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = best_model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # LOS\n",
        "\n",
        "        y_true_hours = y_true\n",
        "        y_pred_hours = y_pred\n",
        "\n",
        "        abs_err = torch.abs(y_pred_hours - y_true_hours)\n",
        "        test_abs_error_sum += abs_err.sum().item()\n",
        "        test_count += y_true.size(0)\n",
        "\n",
        "test_mae_hours = test_abs_error_sum / test_count\n",
        "\n",
        "print(f\"\\n===== Test set MAE ====\" )\n",
        "print(f\"Test MAE (hours): {test_mae_hours:.2f}\")\n",
        "print(f\"Test MAE (days) : {test_mae_hours / 24:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mpmdUCi5FTdd",
        "outputId": "e499ffe6-88eb-4212-ffac-3a654fa08ec6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "all_abs_errors = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = best_model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # LOS\n",
        "\n",
        "        y_true_hours = y_true\n",
        "        y_pred_hours = y_pred\n",
        "\n",
        "        abs_err = torch.abs(y_pred_hours - y_true_hours)\n",
        "\n",
        "        all_abs_errors.extend(abs_err.cpu().numpy())\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(\n",
        "    all_abs_errors,\n",
        "    bins=100,              # Number of bins\n",
        "    range=(0, 500),        # X-axis range (0~500 hours)\n",
        "    edgecolor='black',\n",
        "    alpha=0.75\n",
        ")\n",
        "\n",
        "plt.title(\"Test Set Prediction Error Distribution (Hours)\")\n",
        "plt.xlabel(\"Absolute Error (hours)\")\n",
        "plt.ylabel(\"Frequency (count)\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPZsDxsmvgvgCy",
        "outputId": "121f2a44-a92f-43eb-aafc-1f1888e5a919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====== Sample Predictions (True vs Predicted LOS) ======\n",
            "\n",
            "True LOS: 44.72 hours | Predicted: 61.00 hours | Error: 16.28\n",
            "True LOS: 55.63 hours | Predicted: 117.91 hours | Error: 62.28\n",
            "True LOS: 90.42 hours | Predicted: 167.17 hours | Error: 76.75\n",
            "True LOS: 24.08 hours | Predicted: 114.77 hours | Error: 90.69\n",
            "True LOS: 106.88 hours | Predicted: 75.24 hours | Error: 31.64\n",
            "True LOS: 247.07 hours | Predicted: 94.34 hours | Error: 152.73\n",
            "True LOS: 261.08 hours | Predicted: 112.72 hours | Error: 148.37\n",
            "True LOS: 35.00 hours | Predicted: 81.11 hours | Error: 46.11\n",
            "True LOS: 63.13 hours | Predicted: 71.45 hours | Error: 8.32\n",
            "True LOS: 102.85 hours | Predicted: 196.67 hours | Error: 93.82\n",
            "True LOS: 80.08 hours | Predicted: 100.43 hours | Error: 20.34\n",
            "True LOS: 44.72 hours | Predicted: 103.86 hours | Error: 59.15\n",
            "True LOS: 255.52 hours | Predicted: 98.99 hours | Error: 156.52\n",
            "True LOS: 45.53 hours | Predicted: 34.14 hours | Error: 11.39\n",
            "True LOS: 840.62 hours | Predicted: 511.99 hours | Error: 328.63\n",
            "True LOS: 132.08 hours | Predicted: 76.38 hours | Error: 55.71\n",
            "True LOS: 301.33 hours | Predicted: 260.39 hours | Error: 40.94\n",
            "True LOS: 265.32 hours | Predicted: 130.10 hours | Error: 135.22\n",
            "True LOS: 37.37 hours | Predicted: 60.40 hours | Error: 23.04\n",
            "True LOS: 373.82 hours | Predicted: 619.70 hours | Error: 245.88\n"
          ]
        }
      ],
      "source": [
        "# 3. true vs Predicted values\n",
        "\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"\\n====== Sample Predictions (True vs Predicted LOS) ======\\n\")\n",
        "\n",
        "num_show = 20 \n",
        "shown = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]\n",
        "\n",
        "        # y_true and y_pred are already LOS (hours), no transformation needed\n",
        "        y_true_hours = y_true.cpu().numpy()\n",
        "        y_pred_hours = y_pred.cpu().numpy()\n",
        "\n",
        "        for t, p in zip(y_true_hours, y_pred_hours):\n",
        "            print(f\"True LOS: {t:.2f} hours | Predicted: {p:.2f} hours | Error: {abs(t - p):.2f}\")\n",
        "            shown += 1\n",
        "            if shown >= num_show:\n",
        "                break\n",
        "\n",
        "        if shown >= num_show:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjuB2FqGVZ5V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
