{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V08e05Ftqyv",
        "outputId": "c4acfc63-fb78-467e-939d-10d313753e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(424803, 17)\n",
            "Index(['subject_id', 'hadm_id', 'admittime', 'dischtime', 'race', 'los_hours',\n",
            "       'gender', 'anchor_age', 'curr_service', 'hcpcs_cd_list',\n",
            "       'diagnoses_icd_code_list', 'procedures_icd_code_list', 'drg_code',\n",
            "       'drg_severity', 'drg_mortality', 'medication_list', 'order_type_list'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_parquet(\"los_dataset_24h.parquet\")\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrTAv2ht3aZ"
      },
      "outputs": [],
      "source": [
        "def build_label_encoder(series):\n",
        "    classes = sorted(series.unique())\n",
        "    stoi = {c: i for i, c in enumerate(classes)}\n",
        "    return stoi\n",
        "\n",
        "\n",
        "def build_vocab_from_list_column(df, col, min_freq=1, add_unk=True):\n",
        "    counter = Counter()\n",
        "    for lst in df[col]:\n",
        "        counter.update(lst)\n",
        "\n",
        "    stoi = {}\n",
        "    idx = 0\n",
        "    if add_unk:\n",
        "        stoi[\"<UNK>\"] = idx\n",
        "        idx += 1\n",
        "\n",
        "    for token, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            if token not in stoi:\n",
        "                stoi[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "    return stoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LpjEFBuIUx",
        "outputId": "cac54473-2b5b-4411-c449-7c8604df1b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_genders: 2\n",
            "num_races: 33\n",
            "num_services: 21\n",
            "num_drg_codes: 301\n"
          ]
        }
      ],
      "source": [
        "# Encoders for gender, race, curr_service, drg_code\n",
        "gender_stoi = build_label_encoder(df[\"gender\"])\n",
        "race_stoi = build_label_encoder(df[\"race\"])\n",
        "service_stoi = build_label_encoder(df[\"curr_service\"])\n",
        "\n",
        "# drg_code is already an int, but treat it as a \"category\" and map it back to an index\n",
        "drg_code_stoi = build_label_encoder(df[\"drg_code\"].astype(int))\n",
        "\n",
        "print(\"num_genders:\", len(gender_stoi))\n",
        "print(\"num_races:\", len(race_stoi))\n",
        "print(\"num_services:\", len(service_stoi))\n",
        "print(\"num_drg_codes:\", len(drg_code_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jysvDQ6KuKI3",
        "outputId": "c8e86c55-aa06-42f1-b5ec-45a05cc4d0fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diag vocab size: 27701\n",
            "proc vocab size: 12184\n",
            "hcpcs vocab size: 1925\n",
            "med vocab size: 3358\n",
            "order vocab size: 17\n"
          ]
        }
      ],
      "source": [
        "list_cols = [\n",
        "    \"diagnoses_icd_code_list\",\n",
        "    \"procedures_icd_code_list\",\n",
        "    \"hcpcs_cd_list\",\n",
        "    \"medication_list\",\n",
        "    \"order_type_list\",\n",
        "]\n",
        "\n",
        "diag_stoi = build_vocab_from_list_column(df, \"diagnoses_icd_code_list\", min_freq=1)\n",
        "proc_stoi = build_vocab_from_list_column(df, \"procedures_icd_code_list\", min_freq=1)\n",
        "hcpcs_stoi = build_vocab_from_list_column(df, \"hcpcs_cd_list\", min_freq=1)\n",
        "med_stoi = build_vocab_from_list_column(df, \"medication_list\", min_freq=1)\n",
        "order_stoi = build_vocab_from_list_column(df, \"order_type_list\", min_freq=1)\n",
        "\n",
        "print(\"diag vocab size:\", len(diag_stoi))\n",
        "print(\"proc vocab size:\", len(proc_stoi))\n",
        "print(\"hcpcs vocab size:\", len(hcpcs_stoi))\n",
        "print(\"med vocab size:\", len(med_stoi))\n",
        "print(\"order vocab size:\", len(order_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prFr0KUjuNiy",
        "outputId": "ec3365a5-42b0-4c3a-d242-52f6807a1532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "combined proc vocab size: 14108\n"
          ]
        }
      ],
      "source": [
        "# Combine proc_stoi and hcpcs_stoi into a single integrated vocab\n",
        "proc_all_stoi = {}\n",
        "idx = 0\n",
        "\n",
        "# Only one UNK\n",
        "proc_all_stoi[\"<UNK>\"] = idx\n",
        "idx += 1\n",
        "\n",
        "# Procedures first\n",
        "for k in proc_stoi.keys():\n",
        "    if k == \"<UNK>\":\n",
        "        continue\n",
        "    proc_all_stoi[\"PROC_\" + k] = idx\n",
        "    idx += 1\n",
        "\n",
        "# HCPCS next\n",
        "for k in hcpcs_stoi.keys():\n",
        "    if k == \"<UNK>\":\n",
        "        continue\n",
        "    key = \"HCPCS_\" + k\n",
        "    if key not in proc_all_stoi:\n",
        "        proc_all_stoi[key] = idx\n",
        "        idx += 1\n",
        "\n",
        "print(\"combined proc vocab size:\", len(proc_all_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Vqz1gkzjuQpZ"
      },
      "outputs": [],
      "source": [
        "UNK_DIAG = diag_stoi[\"<UNK>\"]\n",
        "UNK_PROC = proc_all_stoi[\"<UNK>\"]\n",
        "UNK_MED = med_stoi[\"<UNK>\"]\n",
        "UNK_ORDER = order_stoi[\"<UNK>\"]\n",
        "\n",
        "def map_list_to_ids(lst, stoi, unk_token=\"<UNK>\"):\n",
        "    unk_idx = stoi.get(unk_token, None)\n",
        "    out = []\n",
        "    for x in lst:\n",
        "        idx = stoi.get(x)\n",
        "        if idx is None:\n",
        "            if unk_idx is not None:\n",
        "                out.append(unk_idx)\n",
        "        else:\n",
        "            out.append(idx)\n",
        "    return out\n",
        "\n",
        "# Diagnosis codes\n",
        "df[\"diag_ids\"] = df[\"diagnoses_icd_code_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, diag_stoi)\n",
        ")\n",
        "\n",
        "# Combined procedure + hcpcs IDs\n",
        "def build_proc_ids(row):\n",
        "    ids = []\n",
        "    for code in row[\"procedures_icd_code_list\"]:\n",
        "        tok = \"PROC_\" + code\n",
        "        ids.append(proc_all_stoi.get(tok, UNK_PROC))\n",
        "    for code in row[\"hcpcs_cd_list\"]:\n",
        "        tok = \"HCPCS_\" + code\n",
        "        ids.append(proc_all_stoi.get(tok, UNK_PROC))\n",
        "    return ids\n",
        "\n",
        "df[\"proc_ids\"] = df.apply(build_proc_ids, axis=1)\n",
        "\n",
        "# Medication\n",
        "df[\"med_ids\"] = df[\"medication_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, med_stoi)\n",
        ")\n",
        "\n",
        "# Order type\n",
        "df[\"order_ids\"] = df[\"order_type_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, order_stoi)\n",
        ")\n",
        "\n",
        "# Single categorical -> id\n",
        "df[\"gender_id\"] = df[\"gender\"].map(gender_stoi)\n",
        "df[\"race_id\"] = df[\"race\"].map(race_stoi)\n",
        "df[\"service_id\"] = df[\"curr_service\"].map(service_stoi)\n",
        "df[\"drg_code_id\"] = df[\"drg_code\"].astype(int).map(drg_code_stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTxymZbB-_YY",
        "outputId": "86ab2711-10f2-4373-c1b6-2f72900d41db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================ SAMPLE DATA (after encoding) ================\n",
            "\n",
            "--- Row 0 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 279\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 135\n",
            "diagnoses_icd_code_list   : ['07071' '78959' '2875' '2761' '496' '5715' 'V08' '3051']\n",
            "diag_ids                  : [1, 2, 3, 4, 5, 6, 7, 8]\n",
            "procedures_icd_code_list  : ['5491']\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : [1]\n",
            "medication_list           : ['Raltegravir' 'Rifaximin' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Calcium Carbonate' 'Rifaximin' 'Raltegravir'\n",
            " 'Emtricitabine-Tenofovir (Truvada)' 'Sulfameth/Trimethoprim DS'\n",
            " 'Furosemide' 'Tiotropium Bromide' 'Albuterol Inhaler' 'Lactulose'\n",
            " 'Heparin' 'Sodium Chloride 0.9%  Flush' 'Acetaminophen' 'Heparin'\n",
            " 'Lactulose' 'Albumin 25% (12.5g / 50mL)' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Albumin 25% (12.5g / 50mL)' 'Albumin 25% (12.5g / 50mL)']\n",
            "med_ids                   : [1, 2, 3, 4, 2, 1, 5, 6, 7, 8, '...(+11 more)']\n",
            "order_type_list           : ['Medications' 'General Care' 'Nutrition' 'Blood Bank' 'Lab' 'Respiratory'\n",
            " 'Medications' 'Medications' 'ADT orders' 'Lab' 'Lab' 'Medications'\n",
            " 'ADT orders' 'ADT orders' 'ADT orders' 'ADT orders' 'Lab' 'ADT orders'\n",
            " 'Lab' 'General Care' 'Nutrition' 'Medications' 'ADT orders' 'Lab'\n",
            " 'IV therapy' 'Medications' 'General Care' 'General Care' 'Nutrition'\n",
            " 'Medications' 'Nutrition' 'Lab' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications']\n",
            "order_ids                 : [1, 2, 3, 4, 5, 6, 1, 1, 7, 5, '...(+32 more)']\n",
            "\n",
            "\n",
            "--- Row 1 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 283\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 139\n",
            "diagnoses_icd_code_list   : ['07054' '78959' 'V462' '5715' '2767' '2761' '496' 'V08' '3051' '78791']\n",
            "diag_ids                  : [9, 2, 10, 6, 11, 4, 5, 7, 8, 12]\n",
            "procedures_icd_code_list  : ['5491']\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : [1]\n",
            "medication_list           : ['Heparin' 'Raltegravir' 'Rifaximin' 'Emtricitabine-Tenofovir (Truvada)'\n",
            " 'Lactulose' 'Fluticasone Propionate 110mcg' 'Tiotropium Bromide'\n",
            " 'Albuterol Inhaler' 'Calcium Gluconate' 'Dextrose 50%'\n",
            " 'Insulin (Regular) for Hyperkalemia' 'Sodium Polystyrene Sulfonate'\n",
            " 'TraMADOL (Ultram)' 'Lactulose' 'Heparin' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Lactulose' 'Albuterol Inhaler' 'Insulin (Regular) for Hyperkalemia'\n",
            " 'Sodium Polystyrene Sulfonate' 'Calcium Gluconate' 'Dextrose 50%'\n",
            " 'Furosemide' 'Albumin 25% (12.5g / 50mL)' 'Calcium Carbonate'\n",
            " 'Raltegravir' 'Rifaximin' 'Zolpidem Tartrate'\n",
            " 'Fluticasone Propionate 110mcg' 'Albuterol Inhaler' 'Heparin'\n",
            " 'Sodium Chloride 0.9%  Flush' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Calcium Carbonate']\n",
            "med_ids                   : [11, 1, 2, 5, 10, 14, 8, 9, 15, 16, '...(+24 more)']\n",
            "order_type_list           : ['Lab' 'ADT orders' 'Lab' 'General Care' 'General Care' 'Nutrition'\n",
            " 'Medications' 'ADT orders' 'Lab' 'IV therapy' 'Medications'\n",
            " 'General Care' 'General Care' 'General Care' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Radiology' 'Nutrition' 'Nutrition' 'ADT orders' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Cardiology' 'Lab'\n",
            " 'Medications' 'Consults' 'Consults' 'General Care' 'Medications' 'Lab'\n",
            " 'Medications' 'Lab' 'Lab' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'General Care' 'General Care' 'Medications' 'Medications'\n",
            " 'Lab']\n",
            "order_ids                 : [5, 7, 5, 2, 2, 3, 1, 7, 5, 8, '...(+45 more)']\n",
            "\n",
            "\n",
            "--- Row 2 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 207\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 103\n",
            "diagnoses_icd_code_list   : ['45829' '07044' '7994' '2761' '78959' '2767' '3051' 'V08' 'V4986' 'V462'\n",
            " '496' '29680' '5715']\n",
            "diag_ids                  : [13, 14, 15, 4, 2, 11, 8, 7, 16, 10, '...(+3 more)']\n",
            "procedures_icd_code_list  : []\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : []\n",
            "medication_list           : ['Lactulose' 'TraMADOL (Ultram)' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Albumin 25% (12.5g / 50mL)' 'Bisacodyl' 'Calcium Carbonate'\n",
            " 'Docusate Sodium (Liquid)' 'Emtricitabine-Tenofovir (Truvada)'\n",
            " 'Fluticasone Propionate 110mcg' 'Heparin' 'Lactulose' 'Raltegravir'\n",
            " 'Rifaximin' 'Tiotropium Bromide']\n",
            "med_ids                   : [10, 19, 3, 13, 21, 4, 22, 5, 14, 11, '...(+4 more)']\n",
            "order_type_list           : ['Lab' 'ADT orders' 'Lab' 'General Care' 'General Care' 'General Care'\n",
            " 'Nutrition' 'Medications' 'ADT orders' 'Lab' 'General Care'\n",
            " 'General Care' 'General Care' 'Nutrition' 'Medications' 'Medications'\n",
            " 'Medications' 'General Care' 'Medications' 'Respiratory' 'General Care'\n",
            " 'Lab' 'Medications' 'Lab' 'Nutrition' 'Medications' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Lab' 'ADT orders' 'Lab' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Nutrition' 'Nutrition' 'IV therapy' 'Medications' 'General Care'\n",
            " 'General Care' 'General Care' 'Lab' 'General Care' 'Medications'\n",
            " 'Medications' 'Lab' 'General Care' 'ADT orders' 'Lab' 'Medications'\n",
            " 'Consults' 'Consults' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications']\n",
            "order_ids                 : [5, 7, 5, 2, 2, 2, 3, 1, 7, 5, '...(+61 more)']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def summarize_list(lst, max_len=10):\n",
        "    if lst is None:\n",
        "        return None\n",
        "    if len(lst) <= max_len:\n",
        "        return lst\n",
        "    return lst[:max_len] + [\"...(+{} more)\".format(len(lst) - max_len)]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Output 3 samples\n",
        "# -----------------------------\n",
        "cols_to_show = [\n",
        "    \"gender\", \"race\", \"curr_service\", \"drg_code\",\n",
        "    \"gender_id\", \"race_id\", \"service_id\", \"drg_code_id\",\n",
        "    \"diagnoses_icd_code_list\", \"diag_ids\",\n",
        "    \"procedures_icd_code_list\", \"hcpcs_cd_list\", \"proc_ids\",\n",
        "    \"medication_list\", \"med_ids\",\n",
        "    \"order_type_list\", \"order_ids\",\n",
        "]\n",
        "\n",
        "print(\"\\n================ SAMPLE DATA (after encoding) ================\\n\")\n",
        "\n",
        "for i in range(3):\n",
        "    row = df.iloc[i]\n",
        "    print(f\"--- Row {i} ---\")\n",
        "\n",
        "    for c in cols_to_show:\n",
        "        val = row[c]\n",
        "\n",
        "        # Summarize list\n",
        "        if isinstance(val, list):\n",
        "            val = summarize_list(val)\n",
        "\n",
        "        print(f\"{c:25} : {val}\")\n",
        "\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D0LX9ClZuTkx"
      },
      "outputs": [],
      "source": [
        "class LOSDataset(Dataset):\n",
        "    def __init__(self, df, use_log_target=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.use_log_target = use_log_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        sample = {\n",
        "            # tabular\n",
        "            \"age\": float(row[\"anchor_age\"]),\n",
        "            \"gender_id\": int(row[\"gender_id\"]),\n",
        "            \"race_id\": int(row[\"race_id\"]),\n",
        "            \"service_id\": int(row[\"service_id\"]),\n",
        "            \"drg_code_id\": int(row[\"drg_code_id\"]),\n",
        "            \"drg_severity\": float(row[\"drg_severity\"]),\n",
        "            \"drg_mortality\": float(row[\"drg_mortality\"]),\n",
        "\n",
        "            # List-type IDs\n",
        "            \"diag_ids\": row[\"diag_ids\"],\n",
        "            \"proc_ids\": row[\"proc_ids\"],\n",
        "            \"med_ids\": row[\"med_ids\"],\n",
        "            \"order_ids\": row[\"order_ids\"],\n",
        "        }\n",
        "\n",
        "        # target\n",
        "        los = float(row[\"los_hours\"])\n",
        "        if self.use_log_target:\n",
        "            sample[\"target\"] = np.log1p(los)\n",
        "        else:\n",
        "            sample[\"target\"] = los\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZBngU2IuZuA"
      },
      "outputs": [],
      "source": [
        "def los_collate_fn(batch):\n",
        "    B = len(batch)\n",
        "\n",
        "    # ----- Tabular Stack -----\n",
        "    age = torch.tensor([b[\"age\"] for b in batch], dtype=torch.float32)\n",
        "    gender_id = torch.tensor([b[\"gender_id\"] for b in batch], dtype=torch.long)\n",
        "    race_id = torch.tensor([b[\"race_id\"] for b in batch], dtype=torch.long)\n",
        "    service_id = torch.tensor([b[\"service_id\"] for b in batch], dtype=torch.long)\n",
        "    drg_code_id = torch.tensor([b[\"drg_code_id\"] for b in batch], dtype=torch.long)\n",
        "    drg_severity = torch.tensor([b[\"drg_severity\"] for b in batch], dtype=torch.float32)\n",
        "    drg_mortality = torch.tensor([b[\"drg_mortality\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    target = torch.tensor([b[\"target\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    # ----- List-type: diag / proc / med / order -----\n",
        "    def build_bag_inputs(key):\n",
        "        codes_all = []\n",
        "        offsets = [0]\n",
        "        for b in batch:\n",
        "            ids = b[key]\n",
        "            codes_all.extend(ids)\n",
        "            offsets.append(len(codes_all))\n",
        "        if len(codes_all) == 0:\n",
        "            # In case the list is empty for all admissions\n",
        "            codes_tensor = torch.empty(0, dtype=torch.long)\n",
        "        else:\n",
        "            codes_tensor = torch.tensor(codes_all, dtype=torch.long)\n",
        "        offsets_tensor = torch.tensor(offsets, dtype=torch.long)\n",
        "        return codes_tensor, offsets_tensor\n",
        "\n",
        "    diag_codes, diag_offsets = build_bag_inputs(\"diag_ids\")\n",
        "    proc_codes, proc_offsets = build_bag_inputs(\"proc_ids\")\n",
        "    med_codes, med_offsets = build_bag_inputs(\"med_ids\")\n",
        "    order_codes, order_offsets = build_bag_inputs(\"order_ids\")\n",
        "\n",
        "    batch_out = {\n",
        "        \"age\": age,\n",
        "        \"gender_id\": gender_id,\n",
        "        \"race_id\": race_id,\n",
        "        \"service_id\": service_id,\n",
        "        \"drg_code_id\": drg_code_id,\n",
        "        \"drg_severity\": drg_severity,\n",
        "        \"drg_mortality\": drg_mortality,\n",
        "        \"diag_codes\": diag_codes,\n",
        "        \"diag_offsets\": diag_offsets,\n",
        "        \"proc_codes\": proc_codes,\n",
        "        \"proc_offsets\": proc_offsets,\n",
        "        \"med_codes\": med_codes,\n",
        "        \"med_offsets\": med_offsets,\n",
        "        \"order_codes\": order_codes,\n",
        "        \"order_offsets\": order_offsets,\n",
        "        \"target\": target,\n",
        "    }\n",
        "\n",
        "    return batch_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmEgyvbPuaOO",
        "outputId": "d19aa97c-d2c1-49ed-853e-f5a2a7268fac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#train: 297362, #val: 63720, #test: 63721\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "import torch\n",
        "\n",
        "# Generate Dataset\n",
        "dataset = LOSDataset(df, use_log_target=True)\n",
        "\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * 0.7)\n",
        "n_val = int(n_total * 0.15)\n",
        "n_test = n_total - n_train - n_val\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test], generator=g)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "print(f\"#train: {len(train_ds)}, #val: {len(val_ds)}, #test: {len(test_ds)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoKFkMU2udG8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    # ----- Tabular categorical vocab sizes -----\n",
        "    num_genders: int          # e.g. {\"M\", \"F\"} -> 2\n",
        "    num_races: int            # unique race categories\n",
        "    num_services: int         # curr_service (MED, ORTHO, ...)\n",
        "    num_drg_codes: int        # drg_code vocab size\n",
        "\n",
        "    # ----- Code vocab sizes -----\n",
        "    diag_vocab_size: int      # diagnoses_icd_code_list vocab\n",
        "    proc_vocab_size: int      # procedures_icd_code_list + hcpcs_cd_list combined vocab\n",
        "    med_vocab_size: int       # medication_list vocab\n",
        "    order_vocab_size: int     # order_type_list vocab\n",
        "\n",
        "    # ----- Embedding dimensions -----\n",
        "    emb_dim_gender: int = 4\n",
        "    emb_dim_race: int = 8\n",
        "    emb_dim_service: int = 8\n",
        "    emb_dim_drg: int = 16\n",
        "\n",
        "    emb_dim_diag: int = 32\n",
        "    emb_dim_proc: int = 32\n",
        "    emb_dim_med: int = 32\n",
        "    emb_dim_order: int = 16\n",
        "\n",
        "    # ----- Hidden dimensions -----\n",
        "    tabular_hidden_dim: int = 64\n",
        "    diag_hidden_dim: int = 64\n",
        "    proc_hidden_dim: int = 64\n",
        "    med_hidden_dim: int = 64\n",
        "    order_hidden_dim: int = 32\n",
        "\n",
        "    fusion_hidden_dim: int = 128\n",
        "    dropout: float = 0.2\n",
        "\n",
        "\n",
        "class MultiModalLOSModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-branch model for LOS prediction.\n",
        "\n",
        "    Branches:\n",
        "      - Tabular branch: age, gender, race, drg, severity, mortality, curr_service\n",
        "      - Diagnostic branch: diagnoses_icd_code_list\n",
        "      - Procedure branch: procedures_icd_code_list + hcpcs_cd_list\n",
        "      - Medication branch: medication_list\n",
        "      - Order-type branch: order_type_list\n",
        "\n",
        "    Fusion:\n",
        "      concat([h_tab, h_diag, h_proc, h_med, h_order]) -> MLP -> scalar LOS prediction\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        # ------------- Tabular embeddings -------------\n",
        "        self.gender_emb = nn.Embedding(cfg.num_genders, cfg.emb_dim_gender)\n",
        "        self.race_emb = nn.Embedding(cfg.num_races, cfg.emb_dim_race)\n",
        "        self.service_emb = nn.Embedding(cfg.num_services, cfg.emb_dim_service)\n",
        "        self.drg_emb = nn.Embedding(cfg.num_drg_codes, cfg.emb_dim_drg)\n",
        "\n",
        "        # Tabular MLP input dim:\n",
        "        #   age(1) + severity(1) + mortality(1)\n",
        "        # + gender_emb + race_emb + service_emb + drg_emb\n",
        "        tab_in_dim = (\n",
        "            3\n",
        "            + cfg.emb_dim_gender\n",
        "            + cfg.emb_dim_race\n",
        "            + cfg.emb_dim_service\n",
        "            + cfg.emb_dim_drg\n",
        "        )\n",
        "\n",
        "        self.tabular_mlp = nn.Sequential(\n",
        "            nn.Linear(tab_in_dim, cfg.tabular_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.Linear(cfg.tabular_hidden_dim, cfg.tabular_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # ------------- Code embeddings (EmbeddingBag: bag-of-codes) -------------\n",
        "        self.diag_emb = nn.EmbeddingBag(\n",
        "            cfg.diag_vocab_size, cfg.emb_dim_diag,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.proc_emb = nn.EmbeddingBag(\n",
        "            cfg.proc_vocab_size, cfg.emb_dim_proc,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.med_emb = nn.EmbeddingBag(\n",
        "            cfg.med_vocab_size, cfg.emb_dim_med,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.order_emb = nn.EmbeddingBag(\n",
        "            cfg.order_vocab_size, cfg.emb_dim_order,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "\n",
        "        # Small projection MLP for each branch\n",
        "        self.diag_mlp = nn.Sequential(\n",
        "            nn.Linear(cfg.emb_dim_diag, cfg.diag_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "        )\n",
        "        self.proc_mlp = nn.Sequential(\n",
        "            nn.Linear(cfg.emb_dim_proc, cfg.proc_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "        )\n",
        "        self.med_mlp = nn.Sequential(\n",
        "            nn.Linear(cfg.emb_dim_med, cfg.med_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "        )\n",
        "        self.order_mlp = nn.Sequential(\n",
        "            nn.Linear(cfg.emb_dim_order, cfg.order_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "        )\n",
        "\n",
        "        # ------------- Fusion MLP -------------\n",
        "        fusion_in_dim = (\n",
        "            cfg.tabular_hidden_dim\n",
        "            + cfg.diag_hidden_dim\n",
        "            + cfg.proc_hidden_dim\n",
        "            + cfg.med_hidden_dim\n",
        "            + cfg.order_hidden_dim\n",
        "        )\n",
        "\n",
        "        self.fusion_mlp = nn.Sequential(\n",
        "            nn.Linear(fusion_in_dim, cfg.fusion_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.Linear(cfg.fusion_hidden_dim, cfg.fusion_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "        )\n",
        "\n",
        "        # Final regression output layer (LOS prediction)\n",
        "        self.out = nn.Linear(cfg.fusion_hidden_dim, 1)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        # ----- Tabular -----\n",
        "        age,               # (B,) float tensor (anchor_age or normalized)\n",
        "        gender_idx,        # (B,) long tensor\n",
        "        race_idx,          # (B,) long tensor\n",
        "        service_idx,       # (B,) long tensor (curr_service)\n",
        "        drg_code_idx,      # (B,) long tensor\n",
        "        drg_severity,      # (B,) float or long (float normalization recommended first)\n",
        "        drg_mortality,     # (B,) float or long\n",
        "\n",
        "        # ----- Diagnoses (EmbeddingBag) -----\n",
        "        diag_codes,        # (N_diag_codes,) long tensor (flattened)\n",
        "        diag_offsets,      # (B+1,) long tensor, offset for EmbeddingBag\n",
        "\n",
        "        # ----- Procedures (EmbeddingBag) -----\n",
        "        proc_codes,        # (N_proc_codes,) long tensor\n",
        "        proc_offsets,      # (B+1,) long tensor\n",
        "\n",
        "        # ----- Medications (EmbeddingBag) -----\n",
        "        med_codes,         # (N_med_codes,) long tensor\n",
        "        med_offsets,       # (B+1,) long tensor\n",
        "\n",
        "        # ----- Order types (EmbeddingBag) -----\n",
        "        order_codes,       # (N_order_codes,) long tensor\n",
        "        order_offsets,     # (B+1,) long tensor\n",
        "    ):\n",
        "        # --------- 1. Tabular branch ---------\n",
        "        # Embeddings\n",
        "        g_emb = self.gender_emb(gender_idx)   # (B, emb_dim_gender)\n",
        "        r_emb = self.race_emb(race_idx)       # (B, emb_dim_race)\n",
        "        s_emb = self.service_emb(service_idx) # (B, emb_dim_service)\n",
        "        d_emb = self.drg_emb(drg_code_idx)    # (B, emb_dim_drg)\n",
        "\n",
        "        # Cast continuous features to float\n",
        "        age = age.float().unsqueeze(-1)                 # (B, 1)\n",
        "        sev = drg_severity.float().unsqueeze(-1)        # (B, 1)\n",
        "        mort = drg_mortality.float().unsqueeze(-1)      # (B, 1)\n",
        "\n",
        "        tabular_feat = torch.cat(\n",
        "            [age, sev, mort, g_emb, r_emb, s_emb, d_emb],\n",
        "            dim=-1\n",
        "        )  # (B, tab_in_dim)\n",
        "\n",
        "        h_tab = self.tabular_mlp(tabular_feat)  # (B, tabular_hidden_dim)\n",
        "\n",
        "        # --------- 2. Diagnostic branch ---------\n",
        "        # EmbeddingBag: diag_codes, diag_offsets\n",
        "        # If include_last_offset=True, offsets length is B+1\n",
        "        diag_bag = self.diag_emb(diag_codes, diag_offsets)  # (B, emb_dim_diag)\n",
        "        h_diag = self.diag_mlp(diag_bag)  # (B, diag_hidden_dim)\n",
        "\n",
        "        # --------- 3. Procedure branch ---------\n",
        "        proc_bag = self.proc_emb(proc_codes, proc_offsets)  # (B, emb_dim_proc)\n",
        "        h_proc = self.proc_mlp(proc_bag)  # (B, proc_hidden_dim)\n",
        "\n",
        "        # --------- 4. Medication branch ---------\n",
        "        med_bag = self.med_emb(med_codes, med_offsets)  # (B, emb_dim_med)\n",
        "        h_med = self.med_mlp(med_bag)  # (B, med_hidden_dim)\n",
        "\n",
        "        # --------- 5. Order-type branch ---------\n",
        "        order_bag = self.order_emb(order_codes, order_offsets)  # (B, emb_dim_order)\n",
        "        h_order = self.order_mlp(order_bag)  # (B, order_hidden_dim)\n",
        "\n",
        "        # --------- 6. Fusion ---------\n",
        "        h = torch.cat([h_tab, h_diag, h_proc, h_med, h_order], dim=-1)\n",
        "        h = self.fusion_mlp(h)\n",
        "        out = self.out(h).squeeze(-1)  # (B,)\n",
        "\n",
        "        # Predicted LOS (can be used directly as hours, or designed to predict log1p)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZm2f-aivdkb",
        "outputId": "f7f046ca-94b4-4a4b-f588-e7a4477d2d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "========== Epoch 1/20 ==========\n",
            "  [Epoch 1 | Step 0/1162] AvgTrainLoss=21.5014\n",
            "  [Epoch 1 | Step 100/1162] AvgTrainLoss=2.6779\n",
            "  [Epoch 1 | Step 200/1162] AvgTrainLoss=1.7299\n",
            "  [Epoch 1 | Step 300/1162] AvgTrainLoss=1.3725\n",
            "  [Epoch 1 | Step 400/1162] AvgTrainLoss=1.1806\n",
            "  [Epoch 1 | Step 500/1162] AvgTrainLoss=1.0580\n",
            "  [Epoch 1 | Step 600/1162] AvgTrainLoss=0.9756\n",
            "  [Epoch 1 | Step 700/1162] AvgTrainLoss=0.9137\n",
            "  [Epoch 1 | Step 800/1162] AvgTrainLoss=0.8662\n",
            "  [Epoch 1 | Step 900/1162] AvgTrainLoss=0.8270\n",
            "  [Epoch 1 | Step 1000/1162] AvgTrainLoss=0.7947\n",
            "  [Epoch 1 | Step 1100/1162] AvgTrainLoss=0.7675\n",
            "[Epoch 001] train_loss(log-MSE)=0.7523 | val_loss(log-MSE)=0.3294 | val_MAE(hours)=67.45\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 2/20 ==========\n",
            "  [Epoch 2 | Step 0/1162] AvgTrainLoss=0.5835\n",
            "  [Epoch 2 | Step 100/1162] AvgTrainLoss=0.4709\n",
            "  [Epoch 2 | Step 200/1162] AvgTrainLoss=0.4688\n",
            "  [Epoch 2 | Step 300/1162] AvgTrainLoss=0.4628\n",
            "  [Epoch 2 | Step 400/1162] AvgTrainLoss=0.4598\n",
            "  [Epoch 2 | Step 500/1162] AvgTrainLoss=0.4571\n",
            "  [Epoch 2 | Step 600/1162] AvgTrainLoss=0.4543\n",
            "  [Epoch 2 | Step 700/1162] AvgTrainLoss=0.4494\n",
            "  [Epoch 2 | Step 800/1162] AvgTrainLoss=0.4449\n",
            "  [Epoch 2 | Step 900/1162] AvgTrainLoss=0.4417\n",
            "  [Epoch 2 | Step 1000/1162] AvgTrainLoss=0.4383\n",
            "  [Epoch 2 | Step 1100/1162] AvgTrainLoss=0.4355\n",
            "[Epoch 002] train_loss(log-MSE)=0.4333 | val_loss(log-MSE)=0.3118 | val_MAE(hours)=64.89\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 3/20 ==========\n",
            "  [Epoch 3 | Step 0/1162] AvgTrainLoss=0.3740\n",
            "  [Epoch 3 | Step 100/1162] AvgTrainLoss=0.3833\n",
            "  [Epoch 3 | Step 200/1162] AvgTrainLoss=0.3841\n",
            "  [Epoch 3 | Step 300/1162] AvgTrainLoss=0.3818\n",
            "  [Epoch 3 | Step 400/1162] AvgTrainLoss=0.3792\n",
            "  [Epoch 3 | Step 500/1162] AvgTrainLoss=0.3780\n",
            "  [Epoch 3 | Step 600/1162] AvgTrainLoss=0.3768\n",
            "  [Epoch 3 | Step 700/1162] AvgTrainLoss=0.3739\n",
            "  [Epoch 3 | Step 800/1162] AvgTrainLoss=0.3720\n",
            "  [Epoch 3 | Step 900/1162] AvgTrainLoss=0.3701\n",
            "  [Epoch 3 | Step 1000/1162] AvgTrainLoss=0.3682\n",
            "  [Epoch 3 | Step 1100/1162] AvgTrainLoss=0.3669\n",
            "[Epoch 003] train_loss(log-MSE)=0.3665 | val_loss(log-MSE)=0.2753 | val_MAE(hours)=61.87\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 4/20 ==========\n",
            "  [Epoch 4 | Step 0/1162] AvgTrainLoss=0.3894\n",
            "  [Epoch 4 | Step 100/1162] AvgTrainLoss=0.3386\n",
            "  [Epoch 4 | Step 200/1162] AvgTrainLoss=0.3378\n",
            "  [Epoch 4 | Step 300/1162] AvgTrainLoss=0.3365\n",
            "  [Epoch 4 | Step 400/1162] AvgTrainLoss=0.3377\n",
            "  [Epoch 4 | Step 500/1162] AvgTrainLoss=0.3363\n",
            "  [Epoch 4 | Step 600/1162] AvgTrainLoss=0.3357\n",
            "  [Epoch 4 | Step 700/1162] AvgTrainLoss=0.3345\n",
            "  [Epoch 4 | Step 800/1162] AvgTrainLoss=0.3341\n",
            "  [Epoch 4 | Step 900/1162] AvgTrainLoss=0.3332\n",
            "  [Epoch 4 | Step 1000/1162] AvgTrainLoss=0.3328\n",
            "  [Epoch 4 | Step 1100/1162] AvgTrainLoss=0.3323\n",
            "[Epoch 004] train_loss(log-MSE)=0.3319 | val_loss(log-MSE)=0.2755 | val_MAE(hours)=61.93\n",
            "\n",
            "========== Epoch 5/20 ==========\n",
            "  [Epoch 5 | Step 0/1162] AvgTrainLoss=0.3214\n",
            "  [Epoch 5 | Step 100/1162] AvgTrainLoss=0.3152\n",
            "  [Epoch 5 | Step 200/1162] AvgTrainLoss=0.3140\n",
            "  [Epoch 5 | Step 300/1162] AvgTrainLoss=0.3151\n",
            "  [Epoch 5 | Step 400/1162] AvgTrainLoss=0.3125\n",
            "  [Epoch 5 | Step 500/1162] AvgTrainLoss=0.3137\n",
            "  [Epoch 5 | Step 600/1162] AvgTrainLoss=0.3135\n",
            "  [Epoch 5 | Step 700/1162] AvgTrainLoss=0.3130\n",
            "  [Epoch 5 | Step 800/1162] AvgTrainLoss=0.3123\n",
            "  [Epoch 5 | Step 900/1162] AvgTrainLoss=0.3127\n",
            "  [Epoch 5 | Step 1000/1162] AvgTrainLoss=0.3122\n",
            "  [Epoch 5 | Step 1100/1162] AvgTrainLoss=0.3125\n",
            "[Epoch 005] train_loss(log-MSE)=0.3123 | val_loss(log-MSE)=0.2580 | val_MAE(hours)=59.53\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 6/20 ==========\n",
            "  [Epoch 6 | Step 0/1162] AvgTrainLoss=0.3235\n",
            "  [Epoch 6 | Step 100/1162] AvgTrainLoss=0.2918\n",
            "  [Epoch 6 | Step 200/1162] AvgTrainLoss=0.2932\n",
            "  [Epoch 6 | Step 300/1162] AvgTrainLoss=0.2958\n",
            "  [Epoch 6 | Step 400/1162] AvgTrainLoss=0.2975\n",
            "  [Epoch 6 | Step 500/1162] AvgTrainLoss=0.2969\n",
            "  [Epoch 6 | Step 600/1162] AvgTrainLoss=0.2967\n",
            "  [Epoch 6 | Step 700/1162] AvgTrainLoss=0.2970\n",
            "  [Epoch 6 | Step 800/1162] AvgTrainLoss=0.2972\n",
            "  [Epoch 6 | Step 900/1162] AvgTrainLoss=0.2968\n",
            "  [Epoch 6 | Step 1000/1162] AvgTrainLoss=0.2969\n",
            "  [Epoch 6 | Step 1100/1162] AvgTrainLoss=0.2964\n",
            "[Epoch 006] train_loss(log-MSE)=0.2963 | val_loss(log-MSE)=0.2563 | val_MAE(hours)=59.32\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 7/20 ==========\n",
            "  [Epoch 7 | Step 0/1162] AvgTrainLoss=0.3127\n",
            "  [Epoch 7 | Step 100/1162] AvgTrainLoss=0.2827\n",
            "  [Epoch 7 | Step 200/1162] AvgTrainLoss=0.2843\n",
            "  [Epoch 7 | Step 300/1162] AvgTrainLoss=0.2825\n",
            "  [Epoch 7 | Step 400/1162] AvgTrainLoss=0.2826\n",
            "  [Epoch 7 | Step 500/1162] AvgTrainLoss=0.2825\n",
            "  [Epoch 7 | Step 600/1162] AvgTrainLoss=0.2828\n",
            "  [Epoch 7 | Step 700/1162] AvgTrainLoss=0.2834\n",
            "  [Epoch 7 | Step 800/1162] AvgTrainLoss=0.2832\n",
            "  [Epoch 7 | Step 900/1162] AvgTrainLoss=0.2832\n",
            "  [Epoch 7 | Step 1000/1162] AvgTrainLoss=0.2835\n",
            "  [Epoch 7 | Step 1100/1162] AvgTrainLoss=0.2840\n",
            "[Epoch 007] train_loss(log-MSE)=0.2839 | val_loss(log-MSE)=0.2564 | val_MAE(hours)=59.36\n",
            "\n",
            "========== Epoch 8/20 ==========\n",
            "  [Epoch 8 | Step 0/1162] AvgTrainLoss=0.2557\n",
            "  [Epoch 8 | Step 100/1162] AvgTrainLoss=0.2736\n",
            "  [Epoch 8 | Step 200/1162] AvgTrainLoss=0.2725\n",
            "  [Epoch 8 | Step 300/1162] AvgTrainLoss=0.2727\n",
            "  [Epoch 8 | Step 400/1162] AvgTrainLoss=0.2721\n",
            "  [Epoch 8 | Step 500/1162] AvgTrainLoss=0.2719\n",
            "  [Epoch 8 | Step 600/1162] AvgTrainLoss=0.2723\n",
            "  [Epoch 8 | Step 700/1162] AvgTrainLoss=0.2717\n",
            "  [Epoch 8 | Step 800/1162] AvgTrainLoss=0.2720\n",
            "  [Epoch 8 | Step 900/1162] AvgTrainLoss=0.2718\n",
            "  [Epoch 8 | Step 1000/1162] AvgTrainLoss=0.2725\n",
            "  [Epoch 8 | Step 1100/1162] AvgTrainLoss=0.2725\n",
            "[Epoch 008] train_loss(log-MSE)=0.2724 | val_loss(log-MSE)=0.2562 | val_MAE(hours)=59.55\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 9/20 ==========\n",
            "  [Epoch 9 | Step 0/1162] AvgTrainLoss=0.2798\n",
            "  [Epoch 9 | Step 100/1162] AvgTrainLoss=0.2611\n",
            "  [Epoch 9 | Step 200/1162] AvgTrainLoss=0.2620\n",
            "  [Epoch 9 | Step 300/1162] AvgTrainLoss=0.2610\n",
            "  [Epoch 9 | Step 400/1162] AvgTrainLoss=0.2607\n",
            "  [Epoch 9 | Step 500/1162] AvgTrainLoss=0.2614\n",
            "  [Epoch 9 | Step 600/1162] AvgTrainLoss=0.2615\n",
            "  [Epoch 9 | Step 700/1162] AvgTrainLoss=0.2613\n",
            "  [Epoch 9 | Step 800/1162] AvgTrainLoss=0.2613\n",
            "  [Epoch 9 | Step 900/1162] AvgTrainLoss=0.2614\n",
            "  [Epoch 9 | Step 1000/1162] AvgTrainLoss=0.2611\n",
            "  [Epoch 9 | Step 1100/1162] AvgTrainLoss=0.2612\n",
            "[Epoch 009] train_loss(log-MSE)=0.2613 | val_loss(log-MSE)=0.2526 | val_MAE(hours)=58.85\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 10/20 ==========\n",
            "  [Epoch 10 | Step 0/1162] AvgTrainLoss=0.2733\n",
            "  [Epoch 10 | Step 100/1162] AvgTrainLoss=0.2461\n",
            "  [Epoch 10 | Step 200/1162] AvgTrainLoss=0.2485\n",
            "  [Epoch 10 | Step 300/1162] AvgTrainLoss=0.2502\n",
            "  [Epoch 10 | Step 400/1162] AvgTrainLoss=0.2497\n",
            "  [Epoch 10 | Step 500/1162] AvgTrainLoss=0.2515\n",
            "  [Epoch 10 | Step 600/1162] AvgTrainLoss=0.2518\n",
            "  [Epoch 10 | Step 700/1162] AvgTrainLoss=0.2518\n",
            "  [Epoch 10 | Step 800/1162] AvgTrainLoss=0.2528\n",
            "  [Epoch 10 | Step 900/1162] AvgTrainLoss=0.2530\n",
            "  [Epoch 10 | Step 1000/1162] AvgTrainLoss=0.2527\n",
            "  [Epoch 10 | Step 1100/1162] AvgTrainLoss=0.2528\n",
            "[Epoch 010] train_loss(log-MSE)=0.2526 | val_loss(log-MSE)=0.2529 | val_MAE(hours)=58.90\n",
            "\n",
            "========== Epoch 11/20 ==========\n",
            "  [Epoch 11 | Step 0/1162] AvgTrainLoss=0.2266\n",
            "  [Epoch 11 | Step 100/1162] AvgTrainLoss=0.2426\n",
            "  [Epoch 11 | Step 200/1162] AvgTrainLoss=0.2426\n",
            "  [Epoch 11 | Step 300/1162] AvgTrainLoss=0.2429\n",
            "  [Epoch 11 | Step 400/1162] AvgTrainLoss=0.2419\n",
            "  [Epoch 11 | Step 500/1162] AvgTrainLoss=0.2422\n",
            "  [Epoch 11 | Step 600/1162] AvgTrainLoss=0.2421\n",
            "  [Epoch 11 | Step 700/1162] AvgTrainLoss=0.2429\n",
            "  [Epoch 11 | Step 800/1162] AvgTrainLoss=0.2438\n",
            "  [Epoch 11 | Step 900/1162] AvgTrainLoss=0.2437\n",
            "  [Epoch 11 | Step 1000/1162] AvgTrainLoss=0.2442\n",
            "  [Epoch 11 | Step 1100/1162] AvgTrainLoss=0.2446\n",
            "[Epoch 011] train_loss(log-MSE)=0.2445 | val_loss(log-MSE)=0.2496 | val_MAE(hours)=58.42\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 12/20 ==========\n",
            "  [Epoch 12 | Step 0/1162] AvgTrainLoss=0.2544\n",
            "  [Epoch 12 | Step 100/1162] AvgTrainLoss=0.2286\n",
            "  [Epoch 12 | Step 200/1162] AvgTrainLoss=0.2318\n",
            "  [Epoch 12 | Step 300/1162] AvgTrainLoss=0.2316\n",
            "  [Epoch 12 | Step 400/1162] AvgTrainLoss=0.2334\n",
            "  [Epoch 12 | Step 500/1162] AvgTrainLoss=0.2339\n",
            "  [Epoch 12 | Step 600/1162] AvgTrainLoss=0.2344\n",
            "  [Epoch 12 | Step 700/1162] AvgTrainLoss=0.2349\n",
            "  [Epoch 12 | Step 800/1162] AvgTrainLoss=0.2350\n",
            "  [Epoch 12 | Step 900/1162] AvgTrainLoss=0.2353\n",
            "  [Epoch 12 | Step 1000/1162] AvgTrainLoss=0.2358\n",
            "  [Epoch 12 | Step 1100/1162] AvgTrainLoss=0.2360\n",
            "[Epoch 012] train_loss(log-MSE)=0.2368 | val_loss(log-MSE)=0.2510 | val_MAE(hours)=58.65\n",
            "\n",
            "========== Epoch 13/20 ==========\n",
            "  [Epoch 13 | Step 0/1162] AvgTrainLoss=0.2393\n",
            "  [Epoch 13 | Step 100/1162] AvgTrainLoss=0.2233\n",
            "  [Epoch 13 | Step 200/1162] AvgTrainLoss=0.2260\n",
            "  [Epoch 13 | Step 300/1162] AvgTrainLoss=0.2265\n",
            "  [Epoch 13 | Step 400/1162] AvgTrainLoss=0.2267\n",
            "  [Epoch 13 | Step 500/1162] AvgTrainLoss=0.2280\n",
            "  [Epoch 13 | Step 600/1162] AvgTrainLoss=0.2280\n",
            "  [Epoch 13 | Step 700/1162] AvgTrainLoss=0.2282\n",
            "  [Epoch 13 | Step 800/1162] AvgTrainLoss=0.2283\n",
            "  [Epoch 13 | Step 900/1162] AvgTrainLoss=0.2287\n",
            "  [Epoch 13 | Step 1000/1162] AvgTrainLoss=0.2293\n",
            "  [Epoch 13 | Step 1100/1162] AvgTrainLoss=0.2300\n",
            "[Epoch 013] train_loss(log-MSE)=0.2303 | val_loss(log-MSE)=0.2514 | val_MAE(hours)=58.58\n",
            "\n",
            "========== Epoch 14/20 ==========\n",
            "  [Epoch 14 | Step 0/1162] AvgTrainLoss=0.1752\n",
            "  [Epoch 14 | Step 100/1162] AvgTrainLoss=0.2191\n",
            "  [Epoch 14 | Step 200/1162] AvgTrainLoss=0.2200\n",
            "  [Epoch 14 | Step 300/1162] AvgTrainLoss=0.2190\n",
            "  [Epoch 14 | Step 400/1162] AvgTrainLoss=0.2196\n",
            "  [Epoch 14 | Step 500/1162] AvgTrainLoss=0.2201\n",
            "  [Epoch 14 | Step 600/1162] AvgTrainLoss=0.2208\n",
            "  [Epoch 14 | Step 700/1162] AvgTrainLoss=0.2213\n",
            "  [Epoch 14 | Step 800/1162] AvgTrainLoss=0.2212\n",
            "  [Epoch 14 | Step 900/1162] AvgTrainLoss=0.2215\n",
            "  [Epoch 14 | Step 1000/1162] AvgTrainLoss=0.2223\n",
            "  [Epoch 14 | Step 1100/1162] AvgTrainLoss=0.2233\n",
            "[Epoch 014] train_loss(log-MSE)=0.2235 | val_loss(log-MSE)=0.2507 | val_MAE(hours)=58.65\n",
            "\n",
            "========== Epoch 15/20 ==========\n",
            "  [Epoch 15 | Step 0/1162] AvgTrainLoss=0.1914\n",
            "  [Epoch 15 | Step 100/1162] AvgTrainLoss=0.2129\n",
            "  [Epoch 15 | Step 200/1162] AvgTrainLoss=0.2142\n",
            "  [Epoch 15 | Step 300/1162] AvgTrainLoss=0.2150\n",
            "  [Epoch 15 | Step 400/1162] AvgTrainLoss=0.2150\n",
            "  [Epoch 15 | Step 500/1162] AvgTrainLoss=0.2158\n",
            "  [Epoch 15 | Step 600/1162] AvgTrainLoss=0.2166\n",
            "  [Epoch 15 | Step 700/1162] AvgTrainLoss=0.2161\n",
            "  [Epoch 15 | Step 800/1162] AvgTrainLoss=0.2161\n",
            "  [Epoch 15 | Step 900/1162] AvgTrainLoss=0.2171\n",
            "  [Epoch 15 | Step 1000/1162] AvgTrainLoss=0.2177\n",
            "  [Epoch 15 | Step 1100/1162] AvgTrainLoss=0.2184\n",
            "[Epoch 015] train_loss(log-MSE)=0.2186 | val_loss(log-MSE)=0.2520 | val_MAE(hours)=58.83\n",
            "\n",
            "========== Epoch 16/20 ==========\n",
            "  [Epoch 16 | Step 0/1162] AvgTrainLoss=0.2070\n",
            "  [Epoch 16 | Step 100/1162] AvgTrainLoss=0.2077\n",
            "  [Epoch 16 | Step 200/1162] AvgTrainLoss=0.2092\n",
            "  [Epoch 16 | Step 300/1162] AvgTrainLoss=0.2092\n",
            "  [Epoch 16 | Step 400/1162] AvgTrainLoss=0.2095\n",
            "  [Epoch 16 | Step 500/1162] AvgTrainLoss=0.2103\n",
            "  [Epoch 16 | Step 600/1162] AvgTrainLoss=0.2111\n",
            "  [Epoch 16 | Step 700/1162] AvgTrainLoss=0.2118\n",
            "  [Epoch 16 | Step 800/1162] AvgTrainLoss=0.2125\n",
            "  [Epoch 16 | Step 900/1162] AvgTrainLoss=0.2129\n",
            "  [Epoch 16 | Step 1000/1162] AvgTrainLoss=0.2130\n",
            "  [Epoch 16 | Step 1100/1162] AvgTrainLoss=0.2136\n",
            "[Epoch 016] train_loss(log-MSE)=0.2138 | val_loss(log-MSE)=0.2527 | val_MAE(hours)=58.78\n",
            "\n",
            "========== Epoch 17/20 ==========\n",
            "  [Epoch 17 | Step 0/1162] AvgTrainLoss=0.2005\n",
            "  [Epoch 17 | Step 100/1162] AvgTrainLoss=0.2008\n",
            "  [Epoch 17 | Step 200/1162] AvgTrainLoss=0.2029\n",
            "  [Epoch 17 | Step 300/1162] AvgTrainLoss=0.2033\n",
            "  [Epoch 17 | Step 400/1162] AvgTrainLoss=0.2044\n",
            "  [Epoch 17 | Step 500/1162] AvgTrainLoss=0.2055\n",
            "  [Epoch 17 | Step 600/1162] AvgTrainLoss=0.2063\n",
            "  [Epoch 17 | Step 700/1162] AvgTrainLoss=0.2069\n",
            "  [Epoch 17 | Step 800/1162] AvgTrainLoss=0.2072\n",
            "  [Epoch 17 | Step 900/1162] AvgTrainLoss=0.2077\n",
            "  [Epoch 17 | Step 1000/1162] AvgTrainLoss=0.2082\n",
            "  [Epoch 17 | Step 1100/1162] AvgTrainLoss=0.2087\n",
            "[Epoch 017] train_loss(log-MSE)=0.2087 | val_loss(log-MSE)=0.2523 | val_MAE(hours)=58.88\n",
            "\n",
            "========== Epoch 18/20 ==========\n",
            "  [Epoch 18 | Step 0/1162] AvgTrainLoss=0.2102\n",
            "  [Epoch 18 | Step 100/1162] AvgTrainLoss=0.2012\n",
            "  [Epoch 18 | Step 200/1162] AvgTrainLoss=0.2002\n",
            "  [Epoch 18 | Step 300/1162] AvgTrainLoss=0.2001\n",
            "  [Epoch 18 | Step 400/1162] AvgTrainLoss=0.1995\n",
            "  [Epoch 18 | Step 500/1162] AvgTrainLoss=0.2002\n",
            "  [Epoch 18 | Step 600/1162] AvgTrainLoss=0.2011\n",
            "  [Epoch 18 | Step 700/1162] AvgTrainLoss=0.2020\n",
            "  [Epoch 18 | Step 800/1162] AvgTrainLoss=0.2025\n",
            "  [Epoch 18 | Step 900/1162] AvgTrainLoss=0.2030\n",
            "  [Epoch 18 | Step 1000/1162] AvgTrainLoss=0.2033\n",
            "  [Epoch 18 | Step 1100/1162] AvgTrainLoss=0.2040\n",
            "[Epoch 018] train_loss(log-MSE)=0.2041 | val_loss(log-MSE)=0.2510 | val_MAE(hours)=58.63\n",
            "\n",
            "========== Epoch 19/20 ==========\n",
            "  [Epoch 19 | Step 0/1162] AvgTrainLoss=0.1705\n",
            "  [Epoch 19 | Step 100/1162] AvgTrainLoss=0.1890\n",
            "  [Epoch 19 | Step 200/1162] AvgTrainLoss=0.1918\n",
            "  [Epoch 19 | Step 300/1162] AvgTrainLoss=0.1945\n",
            "  [Epoch 19 | Step 400/1162] AvgTrainLoss=0.1964\n",
            "  [Epoch 19 | Step 500/1162] AvgTrainLoss=0.1964\n",
            "  [Epoch 19 | Step 600/1162] AvgTrainLoss=0.1972\n",
            "  [Epoch 19 | Step 700/1162] AvgTrainLoss=0.1978\n",
            "  [Epoch 19 | Step 800/1162] AvgTrainLoss=0.1986\n",
            "  [Epoch 19 | Step 900/1162] AvgTrainLoss=0.1990\n",
            "  [Epoch 19 | Step 1000/1162] AvgTrainLoss=0.1996\n",
            "  [Epoch 19 | Step 1100/1162] AvgTrainLoss=0.2002\n",
            "[Epoch 019] train_loss(log-MSE)=0.2006 | val_loss(log-MSE)=0.2512 | val_MAE(hours)=58.89\n",
            "\n",
            "========== Epoch 20/20 ==========\n",
            "  [Epoch 20 | Step 0/1162] AvgTrainLoss=0.2180\n",
            "  [Epoch 20 | Step 100/1162] AvgTrainLoss=0.1883\n",
            "  [Epoch 20 | Step 200/1162] AvgTrainLoss=0.1895\n",
            "  [Epoch 20 | Step 300/1162] AvgTrainLoss=0.1914\n",
            "  [Epoch 20 | Step 400/1162] AvgTrainLoss=0.1926\n",
            "  [Epoch 20 | Step 500/1162] AvgTrainLoss=0.1934\n",
            "  [Epoch 20 | Step 600/1162] AvgTrainLoss=0.1944\n",
            "  [Epoch 20 | Step 700/1162] AvgTrainLoss=0.1948\n",
            "  [Epoch 20 | Step 800/1162] AvgTrainLoss=0.1953\n",
            "  [Epoch 20 | Step 900/1162] AvgTrainLoss=0.1956\n",
            "  [Epoch 20 | Step 1000/1162] AvgTrainLoss=0.1963\n",
            "  [Epoch 20 | Step 1100/1162] AvgTrainLoss=0.1971\n",
            "[Epoch 020] train_loss(log-MSE)=0.1974 | val_loss(log-MSE)=0.2507 | val_MAE(hours)=58.64\n",
            "Training finished. Best val_loss: 0.24964938581700752\n"
          ]
        }
      ],
      "source": [
        "# 1. Model / Configuration Creation\n",
        "\n",
        "cfg = ModelConfig(\n",
        "    num_genders=len(gender_stoi),\n",
        "    num_races=len(race_stoi),\n",
        "    num_services=len(service_stoi),\n",
        "    num_drg_codes=len(drg_code_stoi),\n",
        "    diag_vocab_size=len(diag_stoi),\n",
        "    proc_vocab_size=len(proc_all_stoi),\n",
        "    med_vocab_size=len(med_stoi),\n",
        "    order_vocab_size=len(order_stoi),\n",
        ")\n",
        "\n",
        "model = MultiModalLOSModel(cfg)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()  # MSE based on log(1+LOS)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_model_path = \"los_multibranch_best.pt\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 2. Training Loop\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # ---------- Train ----------\n",
        "    model.train()\n",
        "    train_loss_sum = 0.0\n",
        "    train_count = 0\n",
        "\n",
        "    print(f\"\\n========== Epoch {epoch}/{NUM_EPOCHS} ==========\")\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        # Move tensors to device\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # log(1+LOS)\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = y_true.size(0)\n",
        "        train_loss_sum += loss.item() * bs\n",
        "        train_count += bs\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            avg_loss = train_loss_sum / train_count\n",
        "            print(f\"  [Epoch {epoch} | Step {batch_idx}/{len(train_loader)}] \"\n",
        "                  f\"AvgTrainLoss={avg_loss:.4f}\")\n",
        "\n",
        "    train_loss = train_loss_sum / train_count\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    model.eval()\n",
        "    val_loss_sum = 0.0\n",
        "    val_count = 0\n",
        "    val_mae_hours_sum = 0.0  # MAE based on actual LOS (hours)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                     for k, v in batch.items()}\n",
        "\n",
        "            y_pred = model(\n",
        "                age=batch[\"age\"],\n",
        "                gender_idx=batch[\"gender_id\"],\n",
        "                race_idx=batch[\"race_id\"],\n",
        "                service_idx=batch[\"service_id\"],\n",
        "                drg_code_idx=batch[\"drg_code_id\"],\n",
        "                drg_severity=batch[\"drg_severity\"],\n",
        "                drg_mortality=batch[\"drg_mortality\"],\n",
        "                diag_codes=batch[\"diag_codes\"],\n",
        "                diag_offsets=batch[\"diag_offsets\"],\n",
        "                proc_codes=batch[\"proc_codes\"],\n",
        "                proc_offsets=batch[\"proc_offsets\"],\n",
        "                med_codes=batch[\"med_codes\"],\n",
        "                med_offsets=batch[\"med_offsets\"],\n",
        "                order_codes=batch[\"order_codes\"],\n",
        "                order_offsets=batch[\"order_offsets\"],\n",
        "            )\n",
        "\n",
        "            y_true = batch[\"target\"]\n",
        "\n",
        "            loss = criterion(y_pred, y_true)\n",
        "\n",
        "            bs = y_true.size(0)\n",
        "            val_loss_sum += loss.item() * bs\n",
        "            val_count += bs\n",
        "\n",
        "            y_true_hours = torch.expm1(y_true)\n",
        "            y_pred_hours = torch.expm1(y_pred)\n",
        "\n",
        "            mae_hours = torch.abs(y_pred_hours - y_true_hours).sum().item()\n",
        "            val_mae_hours_sum += mae_hours\n",
        "\n",
        "    val_loss = val_loss_sum / val_count\n",
        "    val_mae_hours = val_mae_hours_sum / val_count\n",
        "\n",
        "    print(f\"[Epoch {epoch:03d}] \"\n",
        "          f\"train_loss(log-MSE)={train_loss:.4f} | \"\n",
        "          f\"val_loss(log-MSE)={val_loss:.4f} | \"\n",
        "          f\"val_MAE(hours)={val_mae_hours:.2f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"  ↳ Best model updated, saved to {best_model_path}\")\n",
        "\n",
        "print(\"Training finished. Best val_loss:\", best_val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vDQN05751XD",
        "outputId": "4535eef6-ac6f-4050-bbef-539b59c6d9d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Test set MAE =====\n",
            "Test MAE (hours): 57.84\n",
            "Test MAE (days) : 2.41\n"
          ]
        }
      ],
      "source": [
        "# 3. Calculate MAE (hours) on Test set\n",
        "\n",
        "best_model = MultiModalLOSModel(cfg).to(device)\n",
        "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "test_abs_error_sum = 0.0\n",
        "test_count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = best_model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # log(1+LOS)\n",
        "\n",
        "        # Convert log(1+LOS) to actual hours\n",
        "        y_true_hours = torch.expm1(y_true)\n",
        "        y_pred_hours = torch.expm1(y_pred)\n",
        "\n",
        "        abs_err = torch.abs(y_pred_hours - y_true_hours)\n",
        "        test_abs_error_sum += abs_err.sum().item()\n",
        "        test_count += y_true.size(0)\n",
        "\n",
        "test_mae_hours = test_abs_error_sum / test_count\n",
        "\n",
        "print(f\"\\n===== Test set MAE =====\")\n",
        "print(f\"Test MAE (hours): {test_mae_hours:.2f}\")\n",
        "print(f\"Test MAE (days) : {test_mae_hours / 24:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mpmdUCi5FTdd",
        "outputId": "15777fbb-02fb-4894-b8bc-4f54e552fa12"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAIjCAYAAAD1OgEdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbyVJREFUeJzt3Xl0FFX+/vGnQ+gsZCOQDQkhguzIqpARFSQSJCIgKioqmzpiEFkUB78OgqgoDiAMCC4IojAsijoCCmFHCcoW2RRRlrBkgYF0SIBsXb8/MP2jSQhpTKeT8H6dk3Pse29Xfar7TiYPVXXLZBiGIQAAAABAqXJzdQEAAAAAUBkRtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgDgOrN+/XqZTCatX7/e1ta/f3/VrVu31PYxd+5cmUwmHT58uNS2CXtFfY/OMnbsWJlMJrs2k8mkIUOGOH3fkuvnU2ZmpoKDgzV//nyX7N9Z2rdvr1GjRrm6DKBSI2wBKHUmk6lEP6XxR+K5c+c0duxYh7Z1+PBhDRgwQPXq1ZOnp6dCQ0N1xx136NVXX72mGlasWKGxY8eWeHzHjh3tPofAwEDdcsst+vjjj2W1Wq+pBld588039dVXX7m6DDt169a94pzr2rWrq8sr0uHDh+3qrFq1qmrWrKm//e1vevnll5WUlFRq+yqP31mB8lrb1KlT5evrq4cfftjWVhBAT506VeR76tatq3vvvbesSrwmL730kmbMmKGUlBRXlwJUWibDMAxXFwGgcvnss8/sXs+bN0/x8fH69NNP7drvvvtuhYSE/KV9nTp1SkFBQXr11VdLFHh+//133XLLLfLy8tLAgQNVt25dJScna8eOHfr222914cIFh2sYMmSIZsyYoZL+Ou3YsaP++OMPTZgwQZJ08uRJzZs3T4mJiXrppZf01ltvOVyDI9avX69OnTpp3bp16tixoyQpNzdXVqtVHh4eDm3Lx8dHDzzwgObOnWvXnp+fr9zcXHl4eBQ6I+JsdevWVfXq1TVy5MhCfbVq1dJdd91VpvWUxOHDhxUZGalHHnlE3bp1k9Vq1ZkzZ7R161YtXbpUJpNJs2fPtvtj32q1KicnR2azWW5uJf+30yt9Z8XJy8tTXl6ePD09bW0mk0lxcXGaPn16ibdzrbW5cj7l5ubqhhtu0PDhwzV69Ghb+9ixYzVu3DidPHlSNWvWLPS+unXrqlmzZlq2bFlZlusQq9WqG264QU899ZRee+01V5cDVEruri4AQOXz2GOP2b3esmWL4uPjC7W7wpQpU5SZmanExERFRETY9aWlpZVZHf7+/nafx9///nc1bNhQ06dP1/jx41W1atVC7yn44/rSP3hLS1H7+yuqVKmiKlWqlOo2HXHDDTdc03zLyspStWrVCrWXxmd/pW1fqnXr1oXqPnLkiLp06aJ+/fqpcePGatGihSTJzc3NKXPhUgU1u7u7y93ddX8yuHI+LVu2TCdPntRDDz3kkv07qiTzrICbm5seeOABzZs3T+PGjSvzIAtcD7iMEIBLWK1Wvfvuu2ratKk8PT0VEhKiv//97zpz5ozduG3btikmJkY1a9aUl5eXIiMjNXDgQEkXzwYEBQVJku0PBZPJVOwZrj/++EO1a9cuFLQkKTg4uFDbt99+q9tvv13VqlWTr6+vYmNjtXfvXlt///79NWPGDEn2l086ytvbW+3bt1dWVpZOnjxp296QIUM0f/58NW3aVB4eHvruu+8kScePH9fAgQMVEhIiDw8PNW3aVB9//HGh7R47dkw9e/ZUtWrVFBwcrOHDhys7O7vQuKLu2bJarZo6daqaN28uT09PBQUFqWvXrtq2bZutvqysLH3yySe24+7fv7+kK99j895779mOpVatWoqLi1N6errdmI4dO6pZs2bat2+fOnXqJG9vb91www2aOHGiw59rcfr37y8fHx/98ccf6tatm3x9fdW3b1/bsV3ps9+5c6fuuece+fn5ycfHR507d9aWLVvstl1w/Bs2bNCzzz6r4OBg1a5d+5rqjIiI0Ny5c5WTk2P3GRR1z9aBAwfUu3dvhYaGytPTU7Vr19bDDz8si8ViO64rfWcFl8Xt27dPjz76qKpXr64OHTrY9RVl/vz5atiwoTw9PdWmTRtt3Lix0Odc1P2Al2+zvM6nr776SnXr1lW9evVKNL44WVlZGjlypMLDw+Xh4aGGDRvqX//6l91Z8YJLSos683j577fivrOUlBQNGDBAtWvXloeHh8LCwtSjR49Cn+Hdd9+tI0eOKDEx8S8fH4DCOLMFwCX+/ve/a+7cuRowYICGDh2qQ4cOafr06dq5c6d++OEHVa1aVWlpaerSpYuCgoL0j3/8QwEBATp8+LCWLl0qSQoKCtLMmTM1ePBg9erVS/fff78k6eabb77ifiMiIrR69WqtXbv2qpeTffrpp+rXr59iYmL09ttv69y5c5o5c6Y6dOignTt3qm7duvr73/+uEydOFHmZpKMOHjyoKlWqKCAgwNa2du1aLV68WEOGDFHNmjVVt25dpaamqn379rZAEBQUpG+//VaDBg1SRkaGhg0bJkk6f/68OnfurKSkJA0dOlS1atXSp59+qrVr15aonkGDBmnu3Lm655579OSTTyovL0+bNm3Sli1b1LZtW3366ad68skndeutt+rpp5+WpGL/IC247Co6OlqDBw/W/v37NXPmTG3dutX2nRc4c+aMunbtqvvvv18PPfSQPv/8c7300ktq3ry57rnnnqvWnpubW+S9NNWqVZOXl5ftdV5enmJiYtShQwf961//kre3t62vqM9+7969uv322+Xn56dRo0apatWqev/999WxY0dt2LBB7dq1s9vfs88+q6CgII0ZM0ZZWVlXrftKoqKiVK9ePcXHx19xTE5OjmJiYpSdna3nnntOoaGhOn78uJYtW6b09HT5+/uX6Dt78MEHddNNN+nNN9+86qWxGzZs0KJFizR06FB5eHjovffeU9euXfXTTz+pWbNmDh1jeZ1PmzdvVuvWra/Yf/r06SLbL7//0jAM3XfffVq3bp0GDRqkli1bauXKlXrxxRd1/PhxTZkypdg6ilPUd9a7d2/t3btXzz33nOrWrau0tDTFx8crKSnJLvy2adNGkvTDDz+oVatW11wDgCswAMDJ4uLijEt/3WzatMmQZMyfP99u3HfffWfX/uWXXxqSjK1bt15x2ydPnjQkGa+++mqJatmzZ4/h5eVlSDJatmxpPP/888ZXX31lZGVl2Y07e/asERAQYDz11FN27SkpKYa/v79d++XHdzV33nmn0ahRI+PkyZPGyZMnjV9++cUYOnSoIcno3r27bZwkw83Nzdi7d6/d+wcNGmSEhYUZp06dsmt/+OGHDX9/f+PcuXOGYRjGu+++a0gyFi9ebBuTlZVl1K9f35BkrFu3ztber18/IyIiwvZ67dq1hiRj6NChheq3Wq22/65WrZrRr1+/QmPmzJljSDIOHTpkGIZhpKWlGWaz2ejSpYuRn59vGzd9+nRDkvHxxx/bfT6SjHnz5tnasrOzjdDQUKN3796F9nW5iIgIQ1KRPxMmTLA7ZknGP/7xj0LbuNJn37NnT8NsNht//PGHre3EiROGr6+vcccddxQ6/g4dOhh5eXlXrfnQoUOGJOOdd9654pgePXoYkgyLxWIYhmGsW7fO7nvcuXOnIclYsmRJsfu60nf26quvGpKMRx555Ip9lyr4TLdt22ZrO3LkiOHp6Wn06tXL1nb53Cpum+VtPuXm5homk8kYOXLkFesv7ic2NtY2/quvvjIkGa+//rrddh544AHDZDIZv//+u2EY/38uzJkzp9A+L/9dd6Xv7MyZM1edT5cym83G4MGDSzQWgGO4jBBAmVuyZIn8/f11991369SpU7afNm3ayMfHR+vWrZMk2xmeZcuWKTc3t1T23bRpUyUmJuqxxx7T4cOHNXXqVPXs2VMhISH68MMPbePi4+OVnp6uRx55xK7GKlWqqF27drYar9Wvv/6qoKAgBQUFqXHjxvr3v/+t2NjYQpcC3nnnnWrSpInttWEY+uKLL9S9e3cZhmFXW0xMjCwWi3bs2CHp4iqJYWFheuCBB2zv9/b2tp01KM4XX3whk8lU5AqN13KZ5OrVq5WTk6Nhw4bZLebw1FNPyc/PT8uXL7cb7+PjY3fvktls1q233qqDBw+WaH/t2rVTfHx8oZ9HHnmk0NjBgwcXuY3LP/v8/HytWrVKPXv21I033mhrDwsL06OPPqrvv/9eGRkZdtt46qmnSu1eIx8fH0nS2bNni+z39/eXJK1cuVLnzp275v0888wzJR4bFRVlOzMiSXXq1FGPHj20cuVK5efnX3MNV1NW8+n06dMyDEPVq1e/4pgvvviiyLl2+eI/K1asUJUqVTR06FC79pEjR8owDH377bdXPe4rufw78/Lyktls1vr16wtdml2U6tWrX3FVRQB/DZcRAihzBw4ckMViKfIeKen/L1Rx5513qnfv3ho3bpymTJmijh07qmfPnnr00UcdXjXvUg0aNNCnn36q/Px87du3T8uWLdPEiRP19NNPKzIyUtHR0Tpw4IAkXfFSQz8/v2vev3RxpbIPP/xQJpNJnp6euummm4r8PCIjI+1enzx5Uunp6frggw/0wQcfFLntgs/vyJEjql+/fqFw1LBhw6vW98cff6hWrVoKDAws6SEV68iRI0Xu22w268Ybb7T1F6hdu3ahuqtXr65du3aVaH81a9ZUdHT0Vce5u7tf8V6qoj77c+fOFfn5NW7cWFarVUePHlXTpk2vuI2/IjMzU5Lk6+t7xXpHjBihyZMna/78+br99tt133336bHHHrMFsZJwpOabbrqpUFuDBg107tw5nTx5UqGhoSXeliPKej4ZxVxOeccddxS5GuHli5ccOXJEtWrVKvT9NW7c2NZ/rS7/zjw8PPT2229r5MiRCgkJUfv27XXvvffqiSeeKPI7MQyDxTEAJyFsAShzVqu12AeEFix6YTKZ9Pnnn2vLli365ptvtHLlSg0cOFCTJk3Sli1bbP/Sf62qVKmi5s2bq3nz5oqKilKnTp00f/58RUdH2+63+PTTT4v84+SvrsxWrVq1EoWBS+8vkv7/fSCPPfaY+vXrV+R7irtnraK40tmg4v7ovRYeHh5XXDb98s/+WpTGNgrs2bNHwcHBxQb9SZMmqX///vr666+1atUqDR06VBMmTNCWLVtKvEBHadYsXflMqDPPfF3uWudTYGCgTCZTic4OlZZr+byK+s6GDRum7t2766uvvtLKlSv1z3/+UxMmTNDatWsL3ZuVnp5eZGAE8NcRtgCUuXr16mn16tW67bbbSvSHXfv27dW+fXu98cYbWrBggfr27auFCxfqySefLLV/jW3btq0kKTk52VajdHGFwquForL8F+GgoCD5+voqPz//qnVFRERoz549hf7Vev/+/VfdT7169bRy5UqdPn262LNbJT32gtUf9+/fb3cJXk5Ojg4dOlSi4OlqQUFB8vb2LvLz+/XXX+Xm5qbw8HCn7DshIUF//PFHiZazL/gHhFdeeUWbN2/WbbfdplmzZun111+XVLrzteAM8KV+++03eXt72/7RpHr16oVWCJSKPpNT3uaTu7u76tWrp0OHDv3lbRUsznP27Fm7s1u//vqrrV+S7ZLFyz+zaznzVa9ePY0cOVIjR47UgQMH1LJlS02aNMnuWYjHjx9XTk6O7QwbgNLFPVsAytxDDz2k/Px8jR8/vlBfXl6e7Y+MM2fOFPqX55YtW0qSbfnygtXjivpjriibNm0q8v6vFStWSPr/lyXFxMTIz89Pb775ZpHjC5Znl2R7pk1Ja/grqlSpot69e+uLL77Qnj17iq2rW7duOnHihD7//HNb27lz5654+eGlevfuLcMwNG7cuEJ9l34n1apVK9FxR0dHy2w2a9q0aXbvnz17tiwWi2JjY6+6DVerUqWKunTpoq+//tpu+ezU1FQtWLBAHTp0+MuXlxblyJEj6t+/v8xms1588cUrjsvIyFBeXp5dW/PmzeXm5ma33H9Jv7OSSEhIsN0jKElHjx7V119/rS5dutjOJtWrV08Wi8Xukr3k5GR9+eWXhbZXHudTVFSU7XEHf0W3bt2Un59f6CHQU6ZMkclksq2K6Ofnp5o1axZaQv+9994r8b7OnTtX6AHt9erVk6+vb6FHP2zfvl2S9Le//a3E2wdQcpzZAlDm7rzzTv3973/XhAkTlJiYqC5duqhq1ao6cOCAlixZoqlTp+qBBx7QJ598ovfee0+9evVSvXr1dPbsWX344Yfy8/NTt27dJF28fKZJkyZatGiRGjRooMDAQDVr1uyKy06//fbb2r59u+6//37b5XY7duzQvHnzFBgYaFs23c/PTzNnztTjjz+u1q1b6+GHH1ZQUJCSkpK0fPly3XbbbbY/mgoWCBg6dKhiYmJUpUoVPfzww077/N566y2tW7dO7dq101NPPaUmTZro9OnT2rFjh1avXm1bivqpp57S9OnT9cQTT2j79u0KCwvTp59+are8+ZV06tRJjz/+uKZNm6YDBw6oa9euslqt2rRpkzp16qQhQ4bYjn316tWaPHmyatWqpcjIyELLn0sXzwqNHj1a48aNU9euXXXfffdp//79eu+993TLLbeU+gOvjx8/bvev9wV8fHzUs2fPa97u66+/rvj4eHXo0EHPPvus3N3d9f777ys7O7tUngO2Y8cOffbZZ7JarUpPT9fWrVtti5V8+umnxV4iunbtWg0ZMkQPPvigGjRooLy8PH366ae2gF6gpN9ZSTRr1kwxMTF2S79LsgvpDz/8sF566SX16tVLQ4cOtT1CoUGDBnZBzZHaynI+9ejRQ59++ql+++03NWjQ4Jq30717d3Xq1En/93//p8OHD6tFixZatWqVvv76aw0bNsxumfsnn3xSb731lp588km1bdtWGzdu1G+//Vbiff3222/q3LmzHnroITVp0kTu7u768ssvlZqaWuh3U3x8vOrUqcOy74CzuGIJRADXlystjf7BBx8Ybdq0Mby8vAxfX1+jefPmxqhRo4wTJ04YhmEYO3bsMB555BGjTp06hoeHhxEcHGzce++9dktNG4ZhbN682WjTpo1hNpuvugz8Dz/8YMTFxRnNmjUz/P39japVqxp16tQx+vfvb7ecd4F169YZMTExhr+/v+Hp6WnUq1fP6N+/v10NeXl5xnPPPWcEBQUZJpPpqsvA33nnnUbTpk2LHWMYF5d5jouLK7IvNTXViIuLM8LDw42qVasaoaGhRufOnY0PPvjAbtyRI0eM++67z/D29jZq1qxpPP/887Yl9otb+r3guN555x2jUaNGhtlsNoKCgox77rnH2L59u23Mr7/+atxxxx225fQLlu2+fKnuAtOnTzcaNWpkVK1a1QgJCTEGDx5snDlzpkSfz5WWEL9ccUu/X/r+fv36GdWqVStyG8V99jt27DBiYmIMHx8fw9vb2+jUqZOxefNmuzEFx1/cYwsuVbDcd8GPu7u7ERgYaLRr184YPXq0ceTIkULvuXzp94MHDxoDBw406tWrZ3h6ehqBgYFGp06djNWrV9u970rfWcEy4idPniy0ryst/R4XF2d89tlnxk033WR4eHgYrVq1sptXBVatWmU0a9bMMJvNRsOGDY3PPvusyG2Wx/mUnZ1t1KxZ0xg/fnyRn0lRn5dhXJyHly79bhgXHykxfPhwo1atWkbVqlWNm266yXjnnXfsHqdgGIZx7tw5Y9CgQYa/v7/h6+trPPTQQ0ZaWtoVl36/vIZTp04ZcXFxRqNGjYxq1aoZ/v7+Rrt27eweA2EYhpGfn2+EhYUZr7zyylU/BwDXxmQYpXy3MQAAQCUyfvx4zZkzRwcOHCi1pfzLg6+++kqPPvqo/vjjD4WFhbm6HKBS4p4tAACAYgwfPlyZmZlauHChq0spVW+//baGDBlC0AKciDNbAAAAAOAEnNkCAAAAACcgbAEAAACAExC2AAAAAMAJCFsAAAAA4AQ81LgErFarTpw4IV9fX5lMJleXAwAAAMBFDMPQ2bNnVatWLbm5FX/uirBVAidOnFB4eLirywAAAABQThw9elS1a9cudgxhqwR8fX0lXfxA/fz8XFzNxTNtJ0+eVFBQ0FXTNCAxZ+AY5gscxZyBo5gzcFR5mjMZGRkKDw+3ZYTiELZKoODSQT8/v3ITti5cuCA/Pz+XTzZUDMwZOIL5AkcxZ+Ao5gwcVR7nTEluLyoflQIAAABAJUPYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAncHd1Abg26enpysjIkMlkKtTn7++v4OBgF1QFAAAAoABhqwI6efKkJkz8l3bu/kVWwyjUH+DrraWLFhC4AAAAABcibFVAFotFWeezVeP2PvKuHmrXl3U6Rac2LZTFYiFsAQAAAC5E2KrAqlUPlU9IeKH2Uy6oBQAAAIA9FsgAAAAAACcgbAEAAACAExC2AAAAAMAJuGerEsrLzdXhw4eL7GNZeAAAAKBsELYqmexMi44dTVLcyNEym82F+lkWHgAAACgbhK1KJi/7nKxu7qrZoY+qh0XY9bEsPAAAAFB2CFuVlFdgiHxZFh4AAABwGRbIAAAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAncGnYqlu3rkwmU6GfuLg4SdKFCxcUFxenGjVqyMfHR71791ZqaqrdNpKSkhQbGytvb28FBwfrxRdfVF5ent2Y9evXq3Xr1vLw8FD9+vU1d+7csjpEAAAAANcpl4atrVu3Kjk52fYTHx8vSXrwwQclScOHD9c333yjJUuWaMOGDTpx4oTuv/9+2/vz8/MVGxurnJwcbd68WZ988onmzp2rMWPG2MYcOnRIsbGx6tSpkxITEzVs2DA9+eSTWrlyZdkeLAAAAIDrirsrdx4UFGT3+q233lK9evV05513ymKxaPbs2VqwYIHuuusuSdKcOXPUuHFjbdmyRe3bt9eqVau0b98+rV69WiEhIWrZsqXGjx+vl156SWPHjpXZbNasWbMUGRmpSZMmSZIaN26s77//XlOmTFFMTEyZHzMAAACA64NLw9alcnJy9Nlnn2nEiBEymUzavn27cnNzFR0dbRvTqFEj1alTRwkJCWrfvr0SEhLUvHlzhYSE2MbExMRo8ODB2rt3r1q1aqWEhAS7bRSMGTZs2BVryc7OVnZ2tu11RkaGJMlqtcpqtZbSEV87wzAuXnIpySTDrs9kktzc3Iruk+RmMskwjHJxHCg7VquV7x0lxnyBo5gzcBRzBo4qT3PGkRrKTdj66quvlJ6erv79+0uSUlJSZDabFRAQYDcuJCREKSkptjGXBq2C/oK+4sZkZGTo/Pnz8vLyKlTLhAkTNG7cuELtJ0+e1IULF67p+EpTZmambggLVY6vmzzNOXZ9XoFeym3eVHX93eV3WV+Ar5s869+ozMxMpaWllWXJcDGr1SqLxSLDMOTmxro4KB7zBY5izsBRzBk4qjzNmbNnz5Z4bLkJW7Nnz9Y999yjWrVquboUjR49WiNGjLC9zsjIUHh4uIKCguTn5+fCyi6yWCw6npyiCwFW+Xib7fpSTp9X4u698ozKU5C/fd/Zs1Yl/X5QPj4+Cg4OLsuS4WJWq1Umk0lBQUEu/wWF8o/5AkcxZ+Ao5gwcVZ7mjKenZ4nHlouwdeTIEa1evVpLly61tYWGhionJ0fp6el2Z7dSU1MVGhpqG/PTTz/ZbatgtcJLx1y+gmFqaqr8/PyKPKslSR4eHvLw8CjU7ubm5vIvV5JMf14KaEgyZLLrM4w/T7MW1SfJ+ucliOXhOFC2Cr53vnuUBPMFjmLOwFHMGTiqvMwZR/ZfLmb3nDlzFBwcrNjYWFtbmzZtVLVqVa1Zs8bWtn//fiUlJSkqKkqSFBUVpd27d9tdEhcfHy8/Pz81adLENubSbRSMKdgGAAAAADiDy8OW1WrVnDlz1K9fP7m7//8Tbf7+/ho0aJBGjBihdevWafv27RowYICioqLUvn17SVKXLl3UpEkTPf744/r555+1cuVKvfLKK4qLi7OdmXrmmWd08OBBjRo1Sr/++qvee+89LV68WMOHD3fJ8QIAAAC4Prj8MsLVq1crKSlJAwcOLNQ3ZcoUubm5qXfv3srOzlZMTIzee+89W3+VKlW0bNkyDR48WFFRUapWrZr69eun1157zTYmMjJSy5cv1/DhwzV16lTVrl1bH330Ecu+AwAAAHAql4etLl26yDCMIvs8PT01Y8YMzZgx44rvj4iI0IoVK4rdR8eOHbVz586/VCcAAAAAOMLllxECAAAAQGVE2AIAAAAAJyBsAQAAAIATELYAAAAAwAkIWwAAAADgBIQtAAAAAHACwhYAAAAAOAFhCwAAAACcgLAFAAAAAE5A2AIAAAAAJyBsAQAAAIATELYAAAAAwAkIWwAAAADgBO6uLgBlKy83V4cPHy6yz9/fX8HBwWVbEAAAAFBJEbauI9mZFh07mqS4kaNlNpsL9Qf4emvpogUELgAAAKAUELauI3nZ52R1c1fNDn1UPSzCri/rdIpObVooi8VC2AIAAABKAWHrOuQVGCLfkPBC7adcUAsAAABQWbFABgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACVweto4fP67HHntMNWrUkJeXl5o3b65t27bZ+g3D0JgxYxQWFiYvLy9FR0frwIEDdts4ffq0+vbtKz8/PwUEBGjQoEHKzMy0G7Nr1y7dfvvt8vT0VHh4uCZOnFgmxwcAAADg+uTSsHXmzBnddtttqlq1qr799lvt27dPkyZNUvXq1W1jJk6cqGnTpmnWrFn68ccfVa1aNcXExOjChQu2MX379tXevXsVHx+vZcuWaePGjXr66adt/RkZGerSpYsiIiK0fft2vfPOOxo7dqw++OCDMj1eAAAAANcPd1fu/O2331Z4eLjmzJlja4uMjLT9t2EYevfdd/XKK6+oR48ekqR58+YpJCREX331lR5++GH98ssv+u6777R161a1bdtWkvTvf/9b3bp107/+9S/VqlVL8+fPV05Ojj7++GOZzWY1bdpUiYmJmjx5sl0oAwAAAIDS4tKw9d///lcxMTF68MEHtWHDBt1www169tln9dRTT0mSDh06pJSUFEVHR9ve4+/vr3bt2ikhIUEPP/ywEhISFBAQYAtakhQdHS03Nzf9+OOP6tWrlxISEnTHHXfIbDbbxsTExOjtt9/WmTNn7M6kSVJ2drays7NtrzMyMiRJVqtVVqvVKZ+FIwzDkMlkkkmSSYZdn8kkubm5Od4nyc1kkmEY5eIYUbqsVivfLUqM+QJHMWfgKOYMHFWe5owjNbg0bB08eFAzZ87UiBEj9PLLL2vr1q0aOnSozGaz+vXrp5SUFElSSEiI3ftCQkJsfSkpKQoODrbrd3d3V2BgoN2YS8+YXbrNlJSUQmFrwoQJGjduXKF6T548aXf5oqtkZmbqhrBQ5fi6ydOcY9fnFeil3OZNVdffXX4O9AX4usmz/o3KzMxUWlqa048BZctqtcpiscgwDLm5ufxWTZRzzBc4ijkDRzFn4KjyNGfOnj1b4rEuDVtWq1Vt27bVm2++KUlq1aqV9uzZo1mzZqlfv34uq2v06NEaMWKE7XVGRobCw8MVFBQkPz8/l9VVwGKx6Hhyii4EWOXjbbbrSzl9Xom798ozKk9B/iXvO3vWqqTfD8rHx6dQeEXFZ7VaZTKZFBQU5PJfUCj/mC9wFHMGjmLOwFHlac54enqWeKxLw1ZYWJiaNGli19a4cWN98cUXkqTQ0FBJUmpqqsLCwmxjUlNT1bJlS9uYy8/E5OXl6fTp07b3h4aGKjU11W5MweuCMZfy8PCQh4dHoXY3NzeXf7mSZPrzcj9DkiGTXZ9h/Hma1dE+SdY/L08sD8eI0lfw3fL9oiSYL3AUcwaOYs7AUeVlzjiyf5dWetttt2n//v12bb/99psiIiIkXVwsIzQ0VGvWrLH1Z2Rk6Mcff1RUVJQkKSoqSunp6dq+fbttzNq1a2W1WtWuXTvbmI0bNyo3N9c2Jj4+Xg0bNix0CSEAAAAAlAaXhq3hw4dry5YtevPNN/X7779rwYIF+uCDDxQXFyfpYnodNmyYXn/9df33v//V7t279cQTT6hWrVrq2bOnpItnwrp27aqnnnpKP/30k3744QcNGTJEDz/8sGrVqiVJevTRR2U2mzVo0CDt3btXixYt0tSpU+0uFQQAAACA0uTSywhvueUWffnllxo9erRee+01RUZG6t1331Xfvn1tY0aNGqWsrCw9/fTTSk9PV4cOHfTdd9/ZXSs5f/58DRkyRJ07d5abm5t69+6tadOm2fr9/f21atUqxcXFqU2bNqpZs6bGjBnDsu8AAAAAnMalYUuS7r33Xt17771X7DeZTHrttdf02muvXXFMYGCgFixYUOx+br75Zm3atOma6wQAAAAAR3BHIgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcAJ3VxeA8iMvN1eHDx8uss/f31/BwcFlWxAAAABQgRG2IEnKzrTo2NEkxY0cLbPZXKg/wNdbSxctIHABAAAAJUTYgiQpL/ucrG7uqtmhj6qHRdj1ZZ1O0alNC2WxWAhbAAAAQAkRtmDHKzBEviHhhdpPuaAWAAAAoCJjgQwAAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATuDSsDV27FiZTCa7n0aNGtn6L1y4oLi4ONWoUUM+Pj7q3bu3UlNT7baRlJSk2NhYeXt7Kzg4WC+++KLy8vLsxqxfv16tW7eWh4eH6tevr7lz55bF4QEAAAC4jrn8zFbTpk2VnJxs+/n+++9tfcOHD9c333yjJUuWaMOGDTpx4oTuv/9+W39+fr5iY2OVk5OjzZs365NPPtHcuXM1ZswY25hDhw4pNjZWnTp1UmJiooYNG6Ynn3xSK1euLNPjBAAAAHB9cXd5Ae7uCg0NLdRusVg0e/ZsLViwQHfddZckac6cOWrcuLG2bNmi9u3ba9WqVdq3b59Wr16tkJAQtWzZUuPHj9dLL72ksWPHymw2a9asWYqMjNSkSZMkSY0bN9b333+vKVOmKCYmpsiasrOzlZ2dbXudkZEhSbJarbJaraX9ETjMMIyLZwIlmWTY9ZlMkpubW+n2SXIzmWQYRrk4fjjOarXy/aHEmC9wFHMGjmLOwFHlac44UoPLw9aBAwdUq1YteXp6KioqShMmTFCdOnW0fft25ebmKjo62ja2UaNGqlOnjhISEtS+fXslJCSoefPmCgkJsY2JiYnR4MGDtXfvXrVq1UoJCQl22ygYM2zYsCvWNGHCBI0bN65Q+8mTJ3XhwoW/ftB/UWZmpm4IC1WOr5s8zTl2fV6BXspt3lR1/d3lV0p9Ab5u8qx/ozIzM5WWluacg4JTWa1WWSwWGYYhNzeXn9BGOcd8gaOYM3AUcwaOKk9z5uzZsyUe61DY+uWXX7Rw4UJt2rRJR44c0blz5xQUFKRWrVopJiZGvXv3loeHR4m3165dO82dO1cNGzZUcnKyxo0bp9tvv1179uxRSkqKzGazAgIC7N4TEhKilJQUSVJKSopd0CroL+grbkxGRobOnz8vLy+vQnWNHj1aI0aMsL3OyMhQeHi4goKC5OfnV+LjcxaLxaLjySm6EGCVj7fZri/l9Hkl7t4rz6g8BfmXTt/Zs1Yl/X5QPj4+Cg4Ods5BwamsVqtMJpOCgoJc/gsK5R/zBY5izsBRzBk4qjzNGU9PzxKPLVHY2rFjh0aNGqXvv/9et912m9q1a6devXrJy8tLp0+f1p49e/R///d/eu655zRq1CgNGzasRKHrnnvusf33zTffrHbt2ikiIkKLFy8uMgSVFQ8PjyLrd3Nzc/mXK0mmPy/pMyQZMtn1Gcafp1lLs0+S9c9LF8vD8ePaFHx/fIcoCeYLHMWcgaOYM3BUeZkzjuy/RGGrd+/eevHFF/X5558XOtN0qYSEBE2dOlWTJk3Syy+/XOIiCgQEBKhBgwb6/fffdffddysnJ0fp6el2+0xNTbXd4xUaGqqffvrJbhsFqxVeOubyFQxTU1Pl5+fn0kAHAAAAoHIrUdj67bffVLVq1auOi4qKUlRUlHJzc6+pmMzMTP3xxx96/PHH1aZNG1WtWlVr1qxR7969JUn79+9XUlKSoqKibPt74403lJaWZru8LT4+Xn5+fmrSpIltzIoVK+z2Ex8fb9sGAAAAADhDic6BXRq05s2bZ7dSX4GcnBzNmzev0PjivPDCC9qwYYMOHz6szZs3q1evXqpSpYoeeeQR+fv7a9CgQRoxYoTWrVun7du3a8CAAYqKilL79u0lSV26dFGTJk30+OOP6+eff9bKlSv1yiuvKC4uznYZ4DPPPKODBw9q1KhR+vXXX/Xee+9p8eLFGj58eIlqBAAAAIBr4fAFjwMGDJDFYinUfvbsWQ0YMMChbR07dkyPPPKIGjZsqIceekg1atTQli1bFBQUJEmaMmWK7r33XvXu3Vt33HGHQkNDtXTpUtv7q1SpomXLlqlKlSqKiorSY489pieeeEKvvfaabUxkZKSWL1+u+Ph4tWjRQpMmTdJHH310xWXfAQAAAKA0OLz0e8Ezni537Ngx+fv7O7SthQsXFtvv6empGTNmaMaMGVccExERUegywct17NhRO3fudKg2AAAAAPgrShy2WrVqdfFBuiaTOnfuLHf3///W/Px8HTp0SF27dnVKkQAAAABQ0ZQ4bPXs2VOSlJiYqJiYGPn4+Nj6zGaz6tata1vIAgAAAACudyUOW6+++qokqW7duurTp49DD/MCAAAAgOuNw/ds9evXT9LF1QfT0tJktVrt+uvUqVM6lQEAAABABeZw2Dpw4IAGDhyozZs327UXLJyRn59fasUBAAAAQEXlcNjq37+/3N3dtWzZMoWFhRW5MiEAAAAAXO8cDluJiYnavn27GjVq5Ix6AAAAAKBScPihxk2aNNGpU6ecUQsAAAAAVBoOh623335bo0aN0vr16/W///1PGRkZdj8AAAAAgGu4jDA6OlqS1LlzZ7t2FsgAAAAAgP/P4bC1bt06Z9QBAAAAAJWKw2HrzjvvdEYdKOfycnN1+PDhIvv8/f0VHBxctgUBAAAA5ZzDYWvjxo3F9t9xxx3XXAzKp+xMi44dTVLcyNEym82F+gN8vbV00QICFwAAAHAJh8NWx44dC7Vd+qwt7tmqfPKyz8nq5q6aHfqoeliEXV/W6RSd2rRQFouFsAUAAABcwuGwdebMGbvXubm52rlzp/75z3/qjTfeKLXCUP54BYbINyS8UDsPAgAAAAAKczhs+fv7F2q7++67ZTabNWLECG3fvr1UCgMAAACAiszh52xdSUhIiPbv319amwMAAACACs3hM1u7du2ye20YhpKTk/XWW2+pZcuWpVUXAAAAAFRoDoetli1bymQyyTAMu/b27dvr448/LrXCAAAAAKAiczhsHTp0yO61m5ubgoKC5OnpWWpFAQAAAEBF53DYioiIuPogAAAAALjOXdMCGRs2bFD37t1Vv3591a9fX/fdd582bdpU2rUBAAAAQIXlcNj67LPPFB0dLW9vbw0dOlRDhw6Vl5eXOnfurAULFjijRgAAAACocBy+jPCNN97QxIkTNXz4cFvb0KFDNXnyZI0fP16PPvpoqRYIAAAAABWRw2e2Dh48qO7duxdqv++++wotngEAAAAA1yuHw1Z4eLjWrFlTqH316tUKDw8vlaIAAAAAoKJz+DLCkSNHaujQoUpMTNTf/vY3SdIPP/yguXPnaurUqaVeIAAAAABURA6HrcGDBys0NFSTJk3S4sWLJUmNGzfWokWL1KNHj1IvEAAAAAAqIofDliT16tVLvXr1Ku1aAAAAAKDScPiera1bt+rHH38s1P7jjz9q27ZtpVIUAAAAAFR0DoetuLg4HT16tFD78ePHFRcXVypFAQAAAEBF53DY2rdvn1q3bl2ovVWrVtq3b1+pFAUAAAAAFZ3DYcvDw0OpqamF2pOTk+Xufk23gAEAAABApeNw2OrSpYtGjx4ti8Via0tPT9fLL7+su+++u1SLAwAAAICKyuFTUf/61790xx13KCIiQq1atZIkJSYmKiQkRJ9++mmpFwgAAAAAFZHDYeuGG27Qrl27NH/+fP3888/y8vLSgAED9Mgjj6hq1arOqBEAAAAAKpxrusmqWrVqevrpp0u7FgAAAACoNEp0z9aWLVtKvMFz585p796911wQAAAAAFQGJQpbjz/+uGJiYrRkyRJlZWUVOWbfvn16+eWXVa9ePW3fvr1UiwQAAACAiqZElxHu27dPM2fO1CuvvKJHH31UDRo0UK1ateTp6akzZ87o119/VWZmpnr16qVVq1apefPmzq4bAAAAAMq1EoWtqlWraujQoRo6dKi2bdum77//XkeOHNH58+fVokULDR8+XJ06dVJgYKCz6wUAAACACsHhBTLatm2rtm3bOqMWAAAAAKg0HH6oMQAAAADg6ghbAAAAAOAEhC0AAAAAcALCFgAAAAA4gcNh6+DBg86oAwAAAAAqFYfDVv369dWpUyd99tlnunDhQqkV8tZbb8lkMmnYsGG2tgsXLiguLk41atSQj4+PevfurdTUVLv3JSUlKTY2Vt7e3goODtaLL76ovLw8uzHr169X69at5eHhofr162vu3LmlVjcAAAAAFMXhsLVjxw7dfPPNGjFihEJDQ/X3v/9dP/30018qYuvWrXr//fd1880327UPHz5c33zzjZYsWaINGzboxIkTuv/++239+fn5io2NVU5OjjZv3qxPPvlEc+fO1ZgxY2xjDh06pNjYWHXq1EmJiYkaNmyYnnzySa1cufIv1QwAAAAAxXE4bLVs2VJTp07ViRMn9PHHHys5OVkdOnRQs2bNNHnyZJ08edKh7WVmZqpv37768MMPVb16dVu7xWLR7NmzNXnyZN11111q06aN5syZo82bN2vLli2SpFWrVmnfvn367LPP1LJlS91zzz0aP368ZsyYoZycHEnSrFmzFBkZqUmTJqlx48YaMmSIHnjgAU2ZMsXRQwcAAACAEnP4oca2N7q76/7771dsbKzee+89jR49Wi+88IJefvllPfTQQ3r77bcVFhZ21e3ExcUpNjZW0dHRev31123t27dvV25urqKjo21tjRo1Up06dZSQkKD27dsrISFBzZs3V0hIiG1MTEyMBg8erL1796pVq1ZKSEiw20bBmEsvV7xcdna2srOzba8zMjIkSVarVVar9arH5GyGYchkMskkySTDrs9kktzc3MquT5KbySTDMMrFZ4OiWa1WviOUGPMFjmLOwFHMGTiqPM0ZR2q45rC1bds2ffzxx1q4cKGqVaumF154QYMGDdKxY8c0btw49ejR46qXFy5cuFA7duzQ1q1bC/WlpKTIbDYrICDArj0kJEQpKSm2MZcGrYL+gr7ixmRkZOj8+fPy8vIqtO8JEyZo3LhxhdpPnjxZqvepXavMzEzdEBaqHF83eZpz7Pq8Ar2U27yp6vq7y68M+gJ83eRZ/0ZlZmYqLS2tFI8SpclqtcpiscgwDLm5sQgpisd8gaOYM3AUcwaOKk9z5uzZsyUe63DYmjx5subMmaP9+/erW7dumjdvnrp162Y76MjISM2dO1d169YtdjtHjx7V888/r/j4eHl6ejpahlONHj1aI0aMsL3OyMhQeHi4goKC5Ofn58LKLrJYLDqenKILAVb5eJvt+lJOn1fi7r3yjMpTkL/z+86etSrp94Py8fFRcHBwKR4lSpPVapXJZFJQUJDLf0Gh/GO+wFHMGTiKOQNHlac540h2cThszZw5UwMHDlT//v2veJlgcHCwZs+eXex2tm/frrS0NLVu3drWlp+fr40bN2r69OlauXKlcnJylJ6ebnd2KzU1VaGhoZKk0NDQQmfPClYrvHTM5SsYpqamys/Pr8izWpLk4eEhDw+PQu1ubm4u/3IlyfTnZXuGJEMmuz7D+PM0a1n1SbL+eVljefhscGUF3xHfE0qC+QJHMWfgKOYMHFVe5owj+3c4bB04cOCqY8xms/r161fsmM6dO2v37t12bQMGDFCjRo300ksvKTw8XFWrVtWaNWvUu3dvSdL+/fuVlJSkqKgoSVJUVJTeeOMNpaWl2c6qxMfHy8/PT02aNLGNWbFihd1+4uPjbdsAAAAAAGdwOGzNmTNHPj4+evDBB+3alyxZonPnzl01ZBXw9fVVs2bN7NqqVaumGjVq2NoHDRqkESNGKDAwUH5+fnruuecUFRWl9u3bS5K6dOmiJk2a6PHHH9fEiROVkpKiV155RXFxcbYzU88884ymT5+uUaNGaeDAgVq7dq0WL16s5cuXO3roAAAAAFBiDp+DmzBhgmrWrFmoPTg4WG+++WapFFVgypQpuvfee9W7d2/dcccdCg0N1dKlS239VapU0bJly1SlShVFRUXpscce0xNPPKHXXnvNNiYyMlLLly9XfHy8WrRooUmTJumjjz5STExMqdYKAAAAAJdy+MxWUlKSIiMjC7VHREQoKSnpLxWzfv16u9eenp6aMWOGZsyYccX3REREFLpM8HIdO3bUzp07/1JtAAAAAOAIh89sBQcHa9euXYXaf/75Z9WoUaNUigIAAACAis7hsPXII49o6NChWrdunfLz85Wfn6+1a9fq+eef18MPP+yMGgEAAACgwnH4MsLx48fr8OHD6ty5s9zdL77darXqiSeeKPV7tgAAAACgonI4bJnNZi1atEjjx4/Xzz//LC8vLzVv3lwRERHOqA8AAAAAKiSHw1aBBg0aqEGDBqVZCyqovNxcHT58uMg+f39/2zPQAAAAgOuJw2ErPz9fc+fO1Zo1a5SWliar1WrXv3bt2lIrDuVfdqZFx44mKW7kaJnN5kL9Ab7eWrpoAYELAAAA1x2Hw9bzzz+vuXPnKjY2Vs2aNZPJZHJGXagg8rLPyermrpod+qh6mP2lpFmnU3Rq00JZLBbCFgAAAK47DoethQsXavHixerWrZsz6kEF5RUYIt+Q8ELtp1xQCwAAAFAeOLz0u9lsVv369Z1RCwAAAABUGg6HrZEjR2rq1KkyDMMZ9QAAAABApeDwZYTff/+91q1bp2+//VZNmzZV1apV7fqXLl1aasUBAAAAQEXlcNgKCAhQr169nFELAAAAAFQaDoetOXPmOKMOAAAAAKhUHL5nS5Ly8vK0evVqvf/++zp79qwk6cSJE8rMzCzV4gAAAACgonL4zNaRI0fUtWtXJSUlKTs7W3fffbd8fX319ttvKzs7W7NmzXJGnQAAAABQoTh8Zuv5559X27ZtdebMGXl5ednae/XqpTVr1pRqcQAAAABQUTl8ZmvTpk3avHmzzGazXXvdunV1/PjxUisMAAAAACoyh89sWa1W5efnF2o/duyYfH19S6UoAAAAAKjoHA5bXbp00bvvvmt7bTKZlJmZqVdffVXdunUrzdoAAAAAoMJy+DLCSZMmKSYmRk2aNNGFCxf06KOP6sCBA6pZs6b+85//OKNGAAAAAKhwHA5btWvX1s8//6yFCxdq165dyszM1KBBg9S3b1+7BTMAAAAA4HrmcNiSJHd3dz322GOlXQsAAAAAVBoOh6158+YV2//EE09cczEAAAAAUFk4HLaef/55u9e5ubk6d+6czGazvL29CVsAAAAAoGtYjfDMmTN2P5mZmdq/f786dOjAAhkAAAAA8CeHw1ZRbrrpJr311luFznoBAAAAwPWqVMKWdHHRjBMnTpTW5gAAAACgQnP4nq3//ve/dq8Nw1BycrKmT5+u2267rdQKAwAAAICKzOGw1bNnT7vXJpNJQUFBuuuuuzRp0qTSqgsAAAAAKjSHw5bVanVGHQAAAABQqZTaPVsAAAAAgP/P4TNbI0aMKPHYyZMnO7p5AAAAAKgUHA5bO3fu1M6dO5Wbm6uGDRtKkn777TdVqVJFrVu3to0zmUylVyUAAAAAVDAOh63u3bvL19dXn3zyiapXry7p4oOOBwwYoNtvv10jR44s9SIBAAAAoKJx+J6tSZMmacKECbagJUnVq1fX66+/zmqEAAAAAPAnh8NWRkaGTp48Waj95MmTOnv2bKkUBQAAAAAVncNhq1evXhowYICWLl2qY8eO6dixY/riiy80aNAg3X///c6oEQAAAAAqHIfv2Zo1a5ZeeOEFPfroo8rNzb24EXd3DRo0SO+8806pFwgAAAAAFZHDYcvb21vvvfee3nnnHf3xxx+SpHr16qlatWqlXhwAAAAAVFTX/FDj5ORkJScn66abblK1atVkGEZp1gUAAAAAFZrDYet///ufOnfurAYNGqhbt25KTk6WJA0aNIhl3wEAAADgTw6HreHDh6tq1apKSkqSt7e3rb1Pnz767rvvSrU4AAAAAKioHL5na9WqVVq5cqVq165t137TTTfpyJEjpVYYKoe83FwdPny4yD5/f38FBweXbUEAAABAGXE4bGVlZdmd0Spw+vRpeXh4lEpRqByyMy06djRJcSNHy2w2F+oP8PXW0kULCFwAAAColBwOW7fffrvmzZun8ePHS5JMJpOsVqsmTpyoTp06lXqBqLjyss/J6uaumh36qHpYhF1f1ukUndq0UBaLhbAFAACASsnhsDVx4kR17txZ27ZtU05OjkaNGqW9e/fq9OnT+uGHH5xRIyo4r8AQ+YaEF2o/5YJaAAAAgLLi8AIZzZo102+//aYOHTqoR48eysrK0v3336+dO3eqXr16zqgRAAAAACoch8JWbm6uOnfurLS0NP3f//2fFi9erBUrVuj1119XWFiYwzufOXOmbr75Zvn5+cnPz09RUVH69ttvbf0XLlxQXFycatSoIR8fH/Xu3Vupqal220hKSlJsbKy8vb0VHBysF198UXl5eXZj1q9fr9atW8vDw0P169fX3LlzHa4VAAAAABzhUNiqWrWqdu3aVWo7r127tt566y1t375d27Zt01133aUePXpo7969ki4uM//NN99oyZIl2rBhg06cOKH777/f9v78/HzFxsYqJydHmzdv1ieffKK5c+dqzJgxtjGHDh1SbGysOnXqpMTERA0bNkxPPvmkVq5cWWrHAQAAAACXc/gywscee0yzZ88ulZ13795d3bp100033aQGDRrojTfekI+Pj7Zs2SKLxaLZs2dr8uTJuuuuu9SmTRvNmTNHmzdv1pYtWyRdXIZ+3759+uyzz9SyZUvdc889Gj9+vGbMmKGcnBxJ0qxZsxQZGalJkyapcePGGjJkiB544AFNmTKlVI4BAAAAAIri8AIZeXl5+vjjj7V69Wq1adNG1apVs+ufPHnyNRWSn5+vJUuWKCsrS1FRUdq+fbtyc3MVHR1tG9OoUSPVqVNHCQkJat++vRISEtS8eXOFhITYxsTExGjw4MHau3evWrVqpYSEBLttFIwZNmzYFWvJzs5Wdna27XVGRoYkyWq1ymq1XtPxlSbDMGQymWSSZJJh12cySW5ubuW/T5KbySTDMMrFZ1rZWa1WPmuUGPMFjmLOwFHMGTiqPM0ZR2pwOGzt2bNHrVu3liT99ttvdn0mk8nRzWn37t2KiorShQsX5OPjoy+//FJNmjRRYmKizGazAgIC7MaHhIQoJSVFkpSSkmIXtAr6C/qKG5ORkaHz58/Ly8urUE0TJkzQuHHjCrWfPHlSFy5ccPgYS1tmZqZuCAtVjq+bPM05dn1egV7Kbd5Udf3d5VeO+wJ83eRZ/0ZlZmYqLS3tmj4HlJzVapXFYpFhGHJzc/iENq4zzBc4ijkDRzFn4KjyNGfOnj1b4rElDlsHDx5UZGSk1q1bd01FXUnDhg2VmJgoi8Wizz//XP369dOGDRtKdR+OGj16tEaMGGF7nZGRofDwcAUFBcnPz8+FlV1ksVh0PDlFFwKs8vG2f1hwyunzSty9V55ReQryL799Z89alfT7Qfn4+PCcrTJgtVplMpkUFBTk8l9QKP+YL3AUcwaOYs7AUeVpznh6epZ4bInD1k033aTk5GTbH8Z9+vTRtGnTCp01cpTZbFb9+vUlSW3atNHWrVs1depU9enTRzk5OUpPT7c7u5WamqrQ0FBJUmhoqH766Se77RWsVnjpmMtXMExNTZWfn1+RZ7UkycPDQx4eHoXa3dzcXP7lShfPIBqGIUOSIfuziYbx52nW8t4nyfrn5ZDl4TO9HhR81nzeKAnmCxzFnIGjmDNwVHmZM47sv8QjDcP+npsVK1YoKyur5FWVkNVqVXZ2ttq0aaOqVatqzZo1tr79+/crKSlJUVFRkqSoqCjt3r3b7jK0+Ph4+fn5qUmTJrYxl26jYEzBNgAAAADAGRy+Z6s0jR49Wvfcc4/q1Kmjs2fPasGCBVq/fr1Wrlwpf39/DRo0SCNGjFBgYKD8/Pz03HPPKSoqSu3bt5ckdenSRU2aNNHjjz+uiRMnKiUlRa+88ori4uJsZ6aeeeYZTZ8+XaNGjdLAgQO1du1aLV68WMuXL3floQMAAACo5EoctkwmU6EFMK5lQYxLpaWl6YknnlBycrL8/f118803a+XKlbr77rslSVOmTJGbm5t69+6t7OxsxcTE6L333rO9v0qVKlq2bJkGDx6sqKgoVatWTf369dNrr71mGxMZGanly5dr+PDhmjp1qmrXrq2PPvpIMTExf6l2AAAAAChOicOWYRjq37+/7YzRhQsX9MwzzxRa+n3p0qUl3vnVntfl6empGTNmaMaMGVccExERoRUrVhS7nY4dO2rnzp0lrgsAAAAA/qoSh61+/frZvX7sscdKvRgAAAAAqCxKHLbmzJnjzDoAAAAAoFJhrU0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAncHd1Abh+5eXm6vDhw0X2+fv7Kzg4uGwLAgAAAEoRYQsukZ1p0bGjSYobOVpms7lQf4Cvt5YuWkDgAgAAQIVF2IJL5GWfk9XNXTU79FH1sAi7vqzTKTq1aaEsFgthCwAAABUWYQsu5RUYIt+Q8ELtp1xQCwAAAFCaWCADAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACdxdXQBQlLzcXB0+fLjIPn9/fwUHB5dtQQAAAICDCFsod7IzLTp2NElxI0fLbDYX6g/w9dbSRQsIXAAAACjXCFsod/Kyz8nq5q6aHfqoeliEXV/W6RSd2rRQFouFsAUAAIByjbCFcssrMES+IeGF2k+5oBYAAADAUSyQAQAAAABOQNgCAAAAACcgbAEAAACAExC2AAAAAMAJXBq2JkyYoFtuuUW+vr4KDg5Wz549tX//frsxFy5cUFxcnGrUqCEfHx/17t1bqampdmOSkpIUGxsrb29vBQcH68UXX1ReXp7dmPXr16t169by8PBQ/fr1NXfuXGcfHgAAAIDrmEvD1oYNGxQXF6ctW7YoPj5eubm56tKli7Kysmxjhg8frm+++UZLlizRhg0bdOLECd1///22/vz8fMXGxionJ0ebN2/WJ598orlz52rMmDG2MYcOHVJsbKw6deqkxMREDRs2TE8++aRWrlxZpscLAAAA4Prh0qXfv/vuO7vXc+fOVXBwsLZv36477rhDFotFs2fP1oIFC3TXXXdJkubMmaPGjRtry5Ytat++vVatWqV9+/Zp9erVCgkJUcuWLTV+/Hi99NJLGjt2rMxms2bNmqXIyEhNmjRJktS4cWN9//33mjJlimJiYsr8uAEAAABUfuXqOVsWi0WSFBgYKEnavn27cnNzFR0dbRvTqFEj1alTRwkJCWrfvr0SEhLUvHlzhYSE2MbExMRo8ODB2rt3r1q1aqWEhAS7bRSMGTZsWJF1ZGdnKzs72/Y6IyNDkmS1WmW1WkvlWP8KwzBkMplkkmSSYddnMklubm6Vt0+Sm8kkwzDKxXdRUVitVj4zlBjzBY5izsBRzBk4qjzNGUdqKDdhy2q1atiwYbrtttvUrFkzSVJKSorMZrMCAgLsxoaEhCglJcU25tKgVdBf0FfcmIyMDJ0/f15eXl52fRMmTNC4ceMK1Xjy5ElduHDh2g+ylGRmZuqGsFDl+LrJ05xj1+cV6KXc5k1V199dfpWwL8DXTZ71b1RmZqbS0tKu8kmhgNVqlcVikWEYcnNjXRwUj/kCRzFn4CjmDBxVnubM2bNnSzy23IStuLg47dmzR99//72rS9Ho0aM1YsQI2+uMjAyFh4crKChIfn5+LqzsIovFouPJKboQYJWPt9muL+X0eSXu3ivPqDwF+Ve+vrNnrUr6/aB8fHwUHBx8lU8KBaxWq0wmk4KCglz+CwrlH/MFjmLOwFHMGTiqPM0ZT0/PEo8tF2FryJAhWrZsmTZu3KjatWvb2kNDQ5WTk6P09HS7s1upqakKDQ21jfnpp5/stlewWuGlYy5fwTA1NVV+fn6FzmpJkoeHhzw8PAq1u7m5ufzLlSTTn5fRGZIMmez6DOPP06yVtU+S9c/LKMvDd1GRFHxmfG4oCeYLHMWcgaOYM3BUeZkzjuzfpZUahqEhQ4boyy+/1Nq1axUZGWnX36ZNG1WtWlVr1qyxte3fv19JSUmKioqSJEVFRWn37t12l5TFx8fLz89PTZo0sY25dBsFYwq2AQAAAAClzaVntuLi4rRgwQJ9/fXX8vX1td1j5e/vLy8vL/n7+2vQoEEaMWKEAgMD5efnp+eee05RUVFq3769JKlLly5q0qSJHn/8cU2cOFEpKSl65ZVXFBcXZzs79cwzz2j69OkaNWqUBg4cqLVr12rx4sVavny5y44dAAAAQOXm0jNbM2fOlMViUceOHRUWFmb7WbRokW3MlClTdO+996p379664447FBoaqqVLl9r6q1SpomXLlqlKlSqKiorSY489pieeeEKvvfaabUxkZKSWL1+u+Ph4tWjRQpMmTdJHH33Esu8AAAAAnMalZ7YMw7jqGE9PT82YMUMzZsy44piIiAitWLGi2O107NhRO3fudLhGAAAAALgW3JEIAAAAAE5QLlYjBByRl5urw4cPF9nn7+/PkvAAAAAoFwhbqFCyMy06djRJcSNHy2w2F+oP8PXW0kULCFwAAABwOcIWKpS87HOyurmrZoc+qh4WYdeXdTpFpzYtlMViIWwBAADA5QhbqJC8AkPkGxJeqP2UC2oBAAAAisICGQAAAADgBIQtAAAAAHACwhYAAAAAOAFhCwAAAACcgLAFAAAAAE5A2AIAAAAAJyBsAQAAAIATELYAAAAAwAkIWwAAAADgBIQtAAAAAHACd1cXAJSmvNxcHT58uMg+f39/BQcHl21BAAAAuG4RtlBpZGdadOxokuJGjpbZbC7UH+DrraWLFhC4AAAAUCYIW6g08rLPyermrpod+qh6WIRdX9bpFJ3atFAWi4WwBQAAgDJB2EKl4xUYIt+Q8ELtp1xQCwAAAK5fLJABAAAAAE5A2AIAAAAAJyBsAQAAAIATELYAAAAAwAkIWwAAAADgBIQtAAAAAHACwhYAAAAAOAFhCwAAAACcgLAFAAAAAE5A2AIAAAAAJ3B3dQFAWcnLzdXhw4eL7PP391dwcHDZFgQAAIBKjbCF60J2pkXHjiYpbuRomc3mQv0Bvt5aumgBgQsAAAClhrCF60Je9jlZ3dxVs0MfVQ+LsOvLOp2iU5sWymKxELYAAABQaghbuK54BYbINyS8UPspF9QCAACAyo0FMgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAn4DlbgKS83FwdPny4yD5/f38edgwAAACHEbZw3cvOtOjY0STFjRwts9lcqD/A11tLFy0gcAEAAMAhhC1c9/Kyz8nq5q6aHfqoeliEXV/W6RSd2rRQFouFsAUAAACHELaAP3kFhsg3JLxQ+ykX1AIAAICKjwUyAAAAAMAJOLMFXAWLZwAAAOBaELaAYrB4BgAAAK6VSy8j3Lhxo7p3765atWrJZDLpq6++sus3DENjxoxRWFiYvLy8FB0drQMHDtiNOX36tPr27Ss/Pz8FBARo0KBByszMtBuza9cu3X777fL09FR4eLgmTpzo7ENDJXHp4hkRPYbZ/dS8/WGlnz0ni8Xi6jIBAABQDrk0bGVlZalFixaaMWNGkf0TJ07UtGnTNGvWLP3444+qVq2aYmJidOHCBduYvn37au/evYqPj9eyZcu0ceNGPf3007b+jIwMdenSRREREdq+fbveeecdjR07Vh988IHTjw+VR8HiGZf+VAsMdXVZAAAAKMdcehnhPffco3vuuafIPsMw9O677+qVV15Rjx49JEnz5s1TSEiIvvrqKz388MP65Zdf9N1332nr1q1q27atJOnf//63unXrpn/961+qVauW5s+fr5ycHH388ccym81q2rSpEhMTNXnyZLtQBgAAAAClqdzes3Xo0CGlpKQoOjra1ubv76927dopISFBDz/8sBISEhQQEGALWpIUHR0tNzc3/fjjj+rVq5cSEhJ0xx132N1vExMTo7fffltnzpxR9erVC+07Oztb2dnZttcZGRmSJKvVKqvV6ozDdYhhGDKZTDJJMsmw6zOZJDc3N/rKok+SNT9Phw4dkmHY90kX52tQUFChdlewWq0yDKNczF+Uf8wXOIo5A0cxZ+Co8jRnHKmh3IatlJQUSVJISIhde0hIiK0vJSWl0MIE7u7uCgwMtBsTGRlZaBsFfUWFrQkTJmjcuHGF2k+ePGl3CaOrZGZm6oawUOX4usnTnGPX5xXopdzmTVXX311+9Dm1r1rV87IE+GvGh3NU1b3w/5SqeXlo9KgXFBAQUKivrFmtVlksFhmGITc3nviA4jFf4CjmDBzFnIGjytOcOXv2bInHltuw5UqjR4/WiBEjbK8zMjIUHh6uoKAg+fn5ubCyiywWi44np+hCgFU+3vYr5KWcPq/E3XvlGZWnIH/6nNqXmq6de39ViweHqnpohF1f1pkU/bZpkdzc3MrFSoVWq1Umk0lBQUEu/wWF8o/5AkcxZ+Ao5gwcVZ7mjKenZ4nHltuwFRp6cfGB1NRUhYWF2dpTU1PVsmVL25i0tDS79+Xl5en06dO294eGhio1NdVuTMHrgjGX8/DwkIeHR6F2Nzc3l3+5kmQymWQYhgxJhkx2fYbx52lW+sqsz7N6iHxCwu37JJ3883LP8jBnJNlqKS/1oHxjvsBRzBk4ijkDR5WXOePI/svt7I6MjFRoaKjWrFlja8vIyNCPP/6oqKgoSVJUVJTS09O1fft225i1a9fKarWqXbt2tjEbN25Ubm6ubUx8fLwaNmxY5CWEAAAAAFAaXBq2MjMzlZiYqMTEREkXF8VITExUUlKSTCaThg0bptdff13//e9/tXv3bj3xxBOqVauWevbsKUlq3Lixunbtqqeeeko//fSTfvjhBw0ZMkQPP/ywatWqJUl69NFHZTabNWjQIO3du1eLFi3S1KlT7S4TBAAAAIDS5tLLCLdt26ZOnTrZXhcEoH79+mnu3LkaNWqUsrKy9PTTTys9PV0dOnTQd999Z3ed5Pz58zVkyBB17txZbm5u6t27t6ZNm2br9/f316pVqxQXF6c2bdqoZs2aGjNmDMu+AwAAAHAql4atjh07FrlkdgGTyaTXXntNr7322hXHBAYGasGCBcXu5+abb9amTZuuuU4AAAAAcFS5vWcLAAAAACoywhYAAAAAOEG5XfodqOjycnN1+PDhIvv8/f3LxfO3AAAA4DyELcAJsjMtOnY0SXEjR8tsNhfqD/D11tJFCwhcAAAAlRhhC3CCvOxzsrq5q2aHPqoeFmHXl3U6Rac2LZTFYiFsAQAAVGKELcCJvAJD5BsSXqj9lAtqAQAAQNkibAEuwP1cAAAAlR9hCyhjV7ufy9vDXdMmTVSNGjUK9RHEAAAAKg7CFlDGiruf68yxA9q1ZJqeeHoIC2sAAABUcIQtwEWKup8r63/JLKwBAABQSRC2gHKIhTUAAAAqPjdXFwAAAAAAlRFhCwAAAACcgLAFAAAAAE5A2AIAAAAAJyBsAQAAAIATsBohUIHk5ebq8OHDRfbxwGMAAIDyhbAFVBDZmRYdO5qkuJGjeeAxAABABUDYAiqIvOxzPPAYAACgAiFsARXMlR54nFLMJYaGYSg9PV0ZGRkymUyF+rkEEQAAoPQRtoBK4GqXGFrz8xRUI0Anz1jkZqpSqJ9LEAEAAEofYQuoBIq7xFCSTh3cpfykbare/gEFhHIJIgAAQFkgbAGVyJUuMTx3Olm5SZJX9aL7T5VFcQAAANcZnrMFAAAAAE5A2AIAAAAAJ+AyQgDFSktLk8ViKbKPVQwBAACujLAFQHlXWDb+f//7n55/4SVlXcgt8n3eHu6aNmmiatSoUaiPIAYAAK53hC3gOlfcsvHZF84rJe2kWj40Qn4hte36zhw7oF1LpumJp4cUudw8y8kDAIDrHWELuM4Vt2z8yT926fiyOTIH1Cy0imHW/5Kv+D6WkwcAACBsAfhTUcvGZ/0v+ZreJ0kpV7g0UeISQwAAcH0gbAEodcVdmihxiSEAALg+ELYAlLriLk3MOp2ilLWf6ueff1bdunULvZezXgAAoLIgbAFwmqIuMbzaWS9WOAQAAJUFYQtAmSrurBcrHAIAgMqEsAXAJa60IAcrHAIAgMqCsAWg3LmWFQ5zcnKKPBsmcfkhAABwDcIWgAqhuHu98nJzlXzimMJqh8u9SuFfa9wHBgAAXIGwBaBCuNrDl5OOz1Fg1IMO3wdGEAMAAM5C2AJQoRT38GVH7wNjQQ4AAOBMhC0A14VrWZCjuOeBcY8YAAC4GsIWgOueo88D+yv3iBUX0ghwAABULoQtACiCM+4RKy6kOWuRj7S0NFksliL7CHAAADgXYQsAilGa94gVF9KcscjH//73Pz3/wkvKupBb5LFd6X2GYSg9PV0ZGRkymUyF3kdIAwCgZAhbAOAE1xLSiuu7lkU+si+cV0raSbV8aIT8QmqX+H3W/DwF1QjQyTMWuZmqFDq24s6ySYQxAAAKELYAoIK4ljNpx5fNkTmgpkPvO3Vwl/KTtql6+wcUEOrYWTbp2u9ZI6QBACobwhYAVALFnS1z9H3nTicrN0nyqu5YuJOu/Z41iWeeAQAqH8IWAMBhRYU06drvWfsrD5++1hUeK0MfIRQAyjfCFgCg1JXVfWnXusJjZeiTyv7B21da3dIwDFmtVoIfAFzmugpbM2bM0DvvvKOUlBS1aNFC//73v3Xrrbe6uiwAwJ/KaoXHytD3Vx68fS19xa1u6WYyqXnjmzRk8N9Vs2ZNp9dS4FrP7BX3SATOMgIoTddN2Fq0aJFGjBihWbNmqV27dnr33XcVExOj/fv388sRACqA0l7hsaL3XeuDt6+1r7jVLdOPH1DS/vUaMHio3N2rOr2WAtdyeWlxodFZz8IrT5eelpe+v3I29FqfH+is5w6Wt3pQvlw3YWvy5Ml66qmnNGDAAEnSrFmztHz5cn388cf6xz/+4eLqAABwzLU+ePuv9F1pdctzp5OV61ZFNW57qNAKls6oRbr2y0uLC43OeBZeebr0tDz1XevZ0Gt9fuC1vq881lNeAnNZ91XUy5Wvi7CVk5Oj7du3a/To0bY2Nzc3RUdHKyEhodD47OxsZWdn214X/KtDenq6rFar8wu+irNnzyovL1cZKYeVe+GcXV/myWMyScpMPSJ3w0offZKksyePqWp+vjLTjqhKOa6VvvLRd63zpbwdx/XSl597QXmX/X+BNTfbaX3FzRmjjGqRpJzMdBlu7vJu+DdVq2H/x1fG8cPKO35CnvXbF9lnTflWOdlZpVbPX6nleu07dzJZhw7/ov7PDCkc0vLylJp8QiE33CB3N/tn/WVnZyvt5CnV6/SAvKvbh7SstBP6Zf0XevypZ2WuWrVU3lfe6imulsre52YyqXmThho35hUFBQXJlTIyMiRdDIBXYzJKMqqCO3HihG644QZt3rxZUVFRtvZRo0Zpw4YN+vHHH+3Gjx07VuPGjSvrMgEAAABUEEePHlXt2rWLHXNdnNly1OjRozVixAjba6vVqtOnT6tGjRoymUwurOyijIwMhYeH6+jRo/Lz83N1OagAmDNwBPMFjmLOwFHMGTiqPM0ZwzB09uxZ1apV66pjr4uwVbNmTVWpUkWpqal27ampqQoNDS003sPDQx4eHnZtAQEBzizxmvj5+bl8sqFiYc7AEcwXOIo5A0cxZ+Co8jJn/P39SzTOzcl1lAtms1lt2rTRmjVrbG1Wq1Vr1qyxu6wQAAAAAErLdXFmS5JGjBihfv36qW3btrr11lv17rvvKisry7Y6IQAAAACUpusmbPXp00cnT57UmDFjlJKSopYtW+q7775TSEiIq0tzmIeHh1599dVClzoCV8KcgSOYL3AUcwaOYs7AURV1zlwXqxECAAAAQFm7Lu7ZAgAAAICyRtgCAAAAACcgbAEAAACAExC2AAAAAMAJCFsVzIwZM1S3bl15enqqXbt2+umnn1xdElxk48aN6t69u2rVqiWTyaSvvvrKrt8wDI0ZM0ZhYWHy8vJSdHS0Dhw4YDfm9OnT6tu3r/z8/BQQEKBBgwYpMzOzDI8CZWXChAm65ZZb5Ovrq+DgYPXs2VP79++3G3PhwgXFxcWpRo0a8vHxUe/evQs9DD4pKUmxsbHy9vZWcHCwXnzxReXl5ZXloaCMzJw5UzfffLPtAaJRUVH69ttvbf3MF1zNW2+9JZPJpGHDhtnamDe41NixY2Uymex+GjVqZOuvDPOFsFWBLFq0SCNGjNCrr76qHTt2qEWLFoqJiVFaWpqrS4MLZGVlqUWLFpoxY0aR/RMnTtS0adM0a9Ys/fjjj6pWrZpiYmJ04cIF25i+fftq7969io+P17Jly7Rx40Y9/fTTZXUIKEMbNmxQXFyctmzZovj4eOXm5qpLly7KysqyjRk+fLi++eYbLVmyRBs2bNCJEyd0//332/rz8/MVGxurnJwcbd68WZ988onmzp2rMWPGuOKQ4GS1a9fWW2+9pe3bt2vbtm2666671KNHD+3du1cS8wXF27p1q95//33dfPPNdu3MG1yuadOmSk5Otv18//33tr5KMV8MVBi33nqrERcXZ3udn59v1KpVy5gwYYILq0J5IMn48ssvba+tVqsRGhpqvPPOO7a29PR0w8PDw/jPf/5jGIZh7Nu3z5BkbN261Tbm22+/NUwmk3H8+PEyqx2ukZaWZkgyNmzYYBjGxflRtWpVY8mSJbYxv/zyiyHJSEhIMAzDMFasWGG4ubkZKSkptjEzZ840/Pz8jOzs7LI9ALhE9erVjY8++oj5gmKdPXvWuOmmm4z4+HjjzjvvNJ5//nnDMPg9g8JeffVVo0WLFkX2VZb5wpmtCiInJ0fbt29XdHS0rc3NzU3R0dFKSEhwYWUojw4dOqSUlBS7+eLv76927drZ5ktCQoICAgLUtm1b25jo6Gi5ubnpxx9/LPOaUbYsFoskKTAwUJK0fft25ebm2s2ZRo0aqU6dOnZzpnnz5nYPg4+JiVFGRobtbAcqp/z8fC1cuFBZWVmKiopivqBYcXFxio2NtZsfEr9nULQDBw6oVq1auvHGG9W3b18lJSVJqjzzxd3VBaBkTp06pfz8fLvJJEkhISH69ddfXVQVyquUlBRJKnK+FPSlpKQoODjYrt/d3V2BgYG2MaicrFarhg0bpttuu03NmjWTdHE+mM1mBQQE2I29fM4UNacK+lD57N69W1FRUbpw4YJ8fHz05ZdfqkmTJkpMTGS+oEgLFy7Ujh07tHXr1kJ9/J7B5dq1a6e5c+eqYcOGSk5O1rhx43T77bdrz549lWa+ELYA4DoTFxenPXv22F0XDxSlYcOGSkxMlMVi0eeff65+/fppw4YNri4L5dTRo0f1/PPPKz4+Xp6enq4uBxXAPffcY/vvm2++We3atVNERIQWL14sLy8vF1ZWeriMsIKoWbOmqlSpUmgFltTUVIWGhrqoKpRXBXOiuPkSGhpaaHGVvLw8nT59mjlViQ0ZMkTLli3TunXrVLt2bVt7aGiocnJylJ6ebjf+8jlT1Jwq6EPlYzabVb9+fbVp00YTJkxQixYtNHXqVOYLirR9+3alpaWpdevWcnd3l7u7uzZs2KBp06bJ3d1dISEhzBsUKyAgQA0aNNDvv/9eaX7PELYqCLPZrDZt2mjNmjW2NqvVqjVr1igqKsqFlaE8ioyMVGhoqN18ycjI0I8//mibL1FRUUpPT9f27dttY9auXSur1ap27dqVec1wLsMwNGTIEH355Zdau3atIiMj7frbtGmjqlWr2s2Z/fv3KykpyW7O7N692y6kx8fHy8/PT02aNCmbA4FLWa1WZWdnM19QpM6dO2v37t1KTEy0/bRt21Z9+/a1/TfzBsXJzMzUH3/8obCwsMrze8bVK3Sg5BYuXGh4eHgYc+fONfbt22c8/fTTRkBAgN0KLLh+nD171ti5c6exc+dOQ5IxefJkY+fOncaRI0cMwzCMt956ywgICDC+/vprY9euXUaPHj2MyMhI4/z587ZtdO3a1WjVqpXx448/Gt9//71x0003GY888oirDglONHjwYMPf399Yv369kZycbPs5d+6cbcwzzzxj1KlTx1i7dq2xbds2IyoqyoiKirL15+XlGc2aNTO6dOliJCYmGt99950RFBRkjB492hWHBCf7xz/+YWzYsME4dOiQsWvXLuMf//iHYTKZjFWrVhmGwXxByVy6GqFhMG9gb+TIkcb69euNQ4cOGT/88IMRHR1t1KxZ00hLSzMMo3LMF8JWBfPvf//bqFOnjmE2m41bb73V2LJli6tLgousW7fOkFTop1+/foZhXFz+/Z///KcREhJieHh4GJ07dzb2799vt43//e9/xiOPPGL4+PgYfn5+xoABA4yzZ8+64GjgbEXNFUnGnDlzbGPOnz9vPPvss0b16tUNb29vo1evXkZycrLddg4fPmzcc889hpeXl1GzZk1j5MiRRm5ubhkfDcrCwIEDjYiICMNsNhtBQUFG586dbUHLMJgvKJnLwxbzBpfq06ePERYWZpjNZuOGG24w+vTpY/z++++2/sowX0yGYRiuOacGAAAAAJUX92wBAAAAgBMQtgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAK5q/fr1MplMSk9Pd9o+OnbsqGHDhjlt+xXZ448/rjfffNP2um7dunr33XddV9AV5OTkqG7dutq2bZurSwGAcoGwBQCQJCUkJKhKlSqKjY11dSklcvjwYZlMJiUmJv7lbfXv318mk6nQT9euXf96oX/Rzz//rBUrVmjo0KGuLuWqzGazXnjhBb300kuuLgUAygXCFgBAkjR79mw999xz2rhxo06cOOHqcspc165dlZycbPfzn//854rjc3NzC7Xl5ORc076Le9+///1vPfjgg/Lx8bmmbZemkhxf37599f3332vv3r1lUBEAlG+ELQCAMjMztWjRIg0ePFixsbGaO3dukeN++OEH3XzzzfL09FT79u21Z88eW9+RI0fUvXt3Va9eXdWqVVPTpk21YsUKW/+GDRt06623ysPDQ2FhYfrHP/6hvLy8K9ZkMpn01Vdf2bUFBATYaouMjJQktWrVSiaTSR07drSN++ijj9S4cWN5enqqUaNGeu+99676GXh4eCg0NNTup3r16nb1zJw5U/fdd5+qVaumN954Q2PHjlXLli310UcfKTIyUp6enpKkpKQk9ejRQz4+PvLz89NDDz2k1NRU27au9L7L5efn6/PPP1f37t0L9Z07d04DBw6Ur6+v6tSpow8++MCuf/fu3brrrrvk5eWlGjVq6Omnn1ZmZqatv6jLNnv27Kn+/fvbXtetW1fjx4/XE088IT8/Pz399NPKycnRkCFDFBYWJk9PT0VERGjChAm291SvXl233XabFi5ceNXPHAAqO8IWAECLFy9Wo0aN1LBhQz322GP6+OOPZRhGoXEvvviiJk2apK1btyooKEjdu3e3neGJi4tTdna2Nm7cqN27d+vtt9+2nY05fvy4unXrpltuuUU///yzZs6cqdmzZ+v111+/5pp/+uknSdLq1auVnJyspUuXSpLmz5+vMWPG6I033tAvv/yiN998U//85z/1ySefXPO+CowdO1a9evXS7t27NXDgQEnS77//ri+++EJLly5VYmKirFarevToodOnT2vDhg2Kj4/XwYMH1adPH7ttXf6+ouzatUsWi0Vt27Yt1Ddp0iS1bdtWO3fu1LPPPqvBgwdr//79kqSsrCzFxMSoevXq2rp1q5YsWaLVq1dryJAhDh/zv/71L7Vo0UI7d+7UP//5T02bNk3//e9/tXjxYu3fv1/z589X3bp17d5z6623atOmTQ7vCwAqG3dXFwAAcL3Zs2frsccek3TxcjqLxaINGzbYnS2SpFdffVV33323JOmTTz5R7dq19eWXX+qhhx5SUlKSevfurebNm0uSbrzxRtv73nvvPYWHh2v69OkymUxq1KiRTpw4oZdeekljxoyRm5vj//YXFBQkSapRo4ZCQ0Ptapw0aZLuv/9+SRfPgO3bt0/vv/+++vXrd8XtLVu2rNClei+//LJefvll2+tHH31UAwYMsBuTk5OjefPm2eqJj4/X7t27dejQIYWHh0uS5s2bp6ZNm2rr1q265ZZbinxfUY4cOaIqVaooODi4UF+3bt307LPPSpJeeuklTZkyRevWrVPDhg21YMECXbhwQfPmzVO1atUkSdOnT1f37t319ttvKyQk5Ir7vNxdd92lkSNH2l4nJSXppptuUocOHWQymRQREVHoPbVq1dKRI0dKvA8AqKwIWwBwndu/f79++uknffnll5Ikd3d39enTR7Nnzy4UtqKiomz/HRgYqIYNG+qXX36RJA0dOlSDBw/WqlWrFB0drd69e+vmm2+WJP3yyy+KioqSyWSyvf+2225TZmamjh07pjp16pTKsWRlZemPP/7QoEGD9NRTT9na8/Ly5O/vX+x7O3XqpJkzZ9q1BQYG2r0u6gxTRESEXWD65ZdfFB4ebgtaktSkSRMFBATol19+sYWty99XlPPnz8vDw8PucytQ8NlKFy9xDA0NVVpamq2GFi1a2IKWdPHztlqt2r9/v0Nh6/Jj7t+/v+6++241bNhQXbt21b333qsuXbrYjfHy8tK5c+dKvA8AqKwIWwBwnZs9e7by8vJUq1YtW5thGPLw8ND06dOvGlIKPPnkk4qJidHy5cu1atUqTZgwQZMmTdJzzz13TXWZTKZClzIWtSjFpQruSfrwww/Vrl07u74qVaoU+95q1aqpfv36Vx1TkraSKMn7atasqXPnziknJ0dms9mur2rVqnavTSaTrFZriffv5uZWos/38jpbt26tQ4cO6dtvv9Xq1av10EMPKTo6Wp9//rltzOnTp68aJAHgesA9WwBwHcvLy9O8efM0adIkJSYm2n5+/vln1apVq9BqfFu2bLH995kzZ/Tbb7+pcePGtrbw8HA988wzWrp0qUaOHKkPP/xQktS4cWMlJCTY/XH/ww8/yNfXV7Vr1y6ytqCgICUnJ9teHzhwwO5sSUH4yM/Pt7WFhISoVq1aOnjwoOrXr2/3U7CghrM1btxYR48e1dGjR21t+/btU3p6upo0aeLQtlq2bGl7v6M1/Pzzz8rKyrK1/fDDD3Jzc1PDhg0lFf588/Pz7RY8KY6fn5/69OmjDz/8UIsWLdIXX3yh06dP2/r37NmjVq1aOVQzAFRGhC0AuI4tW7ZMZ86c0aBBg9SsWTO7n969e2v27Nl241977TWtWbNGe/bsUf/+/VWzZk317NlTkjRs2DCtXLlShw4d0o4dO7Ru3TpbEHv22Wd19OhRPffcc/r111/19ddf69VXX9WIESOueL/WXXfdpenTp2vnzp3atm2bnnnmGbuzOcHBwfLy8tJ3332n1NRUWSwWSdK4ceM0YcIETZs2Tb/99pt2796tOXPmaPLkycV+FtnZ2UpJSbH7OXXqlMOfaXR0tJo3b66+fftqx44d+umnn/TEE0/ozjvvLPIyxOIEBQWpdevW+v777x16X9++feXp6al+/fppz549WrdunZ577jk9/vjjtksI77rrLi1fvlzLly/Xr7/+qsGDB5foodWTJ0/Wf/7zH/3666/67bfftGTJEoWGhiogIMA2ZtOmTYUuLQSA6xFhCwCuY7Nnz1Z0dHSRlwr27t1b27Zt065du2xtb731lp5//nm1adNGKSkp+uabb+zOMMXFxalx48bq2rWrGjRoYFty/YYbbtCKFSv0008/qUWLFnrmmWc0aNAgvfLKK1esbdKkSQoPD9ftt9+uRx99VC+88IK8vb1t/e7u7po2bZref/991apVSz169JB08XLGjz76SHPmzFHz5s115513au7cuVc9s/Xdd98pLCzM7qdDhw4l/zD/ZDKZ9PXXX6t69eq64447FB0drRtvvFGLFi1yeFsFxzN//nyH3uPt7a2VK1fq9OnTuuWWW/TAAw+oc+fOmj59um3MwIED1a9fP1sQvPHGG9WpU6erbtvX11cTJ05U27Ztdcstt+jw4cNasWKFLTQnJCTIYrHogQcecOxAAaASMhlFre0LAADKhfPnz6thw4ZatGiR3QIl5VWfPn3UokULu1UcAeB6xZktAADKMS8vL82bN++aLmksazk5OWrevLmGDx/u6lIAoFzgzBYAAAAAOAFntgAAAADACQhbAAAAAOAEhC0AAAAAcALCFgAAAAA4AWELAAAAAJyAsAUAAAAATkDYAgAAAAAnIGwBAAAAgBMQtgAAAADACf4fqrIbMTx9kEEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "all_abs_errors = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = best_model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # log(1+LOS)\n",
        "\n",
        "        y_true_hours = torch.expm1(y_true)\n",
        "        y_pred_hours = torch.expm1(y_pred)\n",
        "\n",
        "        abs_err = torch.abs(y_pred_hours - y_true_hours)\n",
        "\n",
        "        all_abs_errors.extend(abs_err.cpu().numpy())\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(\n",
        "    all_abs_errors,\n",
        "    bins=100,              # Number of bins\n",
        "    range=(0, 500),        # X-axis range (0~500 hours)\n",
        "    edgecolor='black',\n",
        "    alpha=0.75\n",
        ")\n",
        "\n",
        "plt.title(\"Test Set Prediction Error Distribution (Hours)\")\n",
        "plt.xlabel(\"Absolute Error (hours)\")\n",
        "plt.ylabel(\"Frequency (count)\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPZsDxsmvgCy",
        "outputId": "a25d1a6e-b136-4046-cceb-0913d52a8471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====== Sample Predictions (True vs Predicted LOS) ======\n",
            "\n",
            "True LOS: 44.72 hours | Predicted: 58.28 hours | Error: 13.56\n",
            "True LOS: 55.63 hours | Predicted: 112.83 hours | Error: 57.20\n",
            "True LOS: 90.42 hours | Predicted: 143.91 hours | Error: 53.50\n",
            "True LOS: 24.08 hours | Predicted: 83.94 hours | Error: 59.85\n",
            "True LOS: 106.88 hours | Predicted: 53.03 hours | Error: 53.85\n",
            "True LOS: 247.07 hours | Predicted: 87.43 hours | Error: 159.64\n",
            "True LOS: 261.08 hours | Predicted: 108.87 hours | Error: 152.22\n",
            "True LOS: 35.00 hours | Predicted: 40.05 hours | Error: 5.05\n",
            "True LOS: 63.13 hours | Predicted: 66.32 hours | Error: 3.19\n",
            "True LOS: 102.85 hours | Predicted: 149.83 hours | Error: 46.98\n",
            "True LOS: 80.08 hours | Predicted: 90.95 hours | Error: 10.86\n",
            "True LOS: 44.72 hours | Predicted: 76.19 hours | Error: 31.48\n",
            "True LOS: 255.52 hours | Predicted: 99.61 hours | Error: 155.91\n",
            "True LOS: 45.53 hours | Predicted: 42.76 hours | Error: 2.78\n",
            "True LOS: 840.62 hours | Predicted: 596.84 hours | Error: 243.78\n",
            "True LOS: 132.08 hours | Predicted: 70.07 hours | Error: 62.02\n",
            "True LOS: 301.33 hours | Predicted: 144.51 hours | Error: 156.82\n",
            "True LOS: 265.32 hours | Predicted: 96.49 hours | Error: 168.83\n",
            "True LOS: 37.37 hours | Predicted: 58.12 hours | Error: 20.75\n",
            "True LOS: 373.82 hours | Predicted: 489.19 hours | Error: 115.37\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"\\n====== Sample Predictions (True vs Predicted LOS) ======\\n\")\n",
        "\n",
        "num_show = 20  # How many to show\n",
        "shown = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]\n",
        "\n",
        "        # Convert log-scale to hours\n",
        "        y_true_hours = torch.expm1(y_true).cpu().numpy()\n",
        "        y_pred_hours = torch.expm1(y_pred).cpu().numpy()\n",
        "\n",
        "        for t, p in zip(y_true_hours, y_pred_hours):\n",
        "            print(f\"True LOS: {t:.2f} hours | Predicted: {p:.2f} hours | Error: {abs(t - p):.2f}\")\n",
        "            shown += 1\n",
        "            if shown >= num_show:\n",
        "                break\n",
        "\n",
        "        if shown >= num_show:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWY7G3EB5NyJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
