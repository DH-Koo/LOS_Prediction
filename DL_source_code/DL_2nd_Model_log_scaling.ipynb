{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V08e05Ftqyv",
        "outputId": "54b744bf-d218-4409-8f62-35eca6f0a07c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(424803, 17)\n",
            "Index(['subject_id', 'hadm_id', 'admittime', 'dischtime', 'race', 'los_hours',\n",
            "       'gender', 'anchor_age', 'curr_service', 'hcpcs_cd_list',\n",
            "       'diagnoses_icd_code_list', 'procedures_icd_code_list', 'drg_code',\n",
            "       'drg_severity', 'drg_mortality', 'medication_list', 'order_type_list'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_parquet(\"los_dataset_24h.parquet\")\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrTAv2ht3aZ"
      },
      "outputs": [],
      "source": [
        "def build_label_encoder(series):\n",
        "    classes = sorted(series.unique())\n",
        "    stoi = {c: i for i, c in enumerate(classes)}\n",
        "    return stoi\n",
        "\n",
        "\n",
        "def build_vocab_from_list_column(df, col, min_freq=1, add_unk=True):\n",
        "    counter = Counter()\n",
        "    for lst in df[col]:\n",
        "        counter.update(lst)\n",
        "\n",
        "    stoi = {}\n",
        "    idx = 0\n",
        "    if add_unk:\n",
        "        stoi[\"<UNK>\"] = idx\n",
        "        idx += 1\n",
        "\n",
        "    for token, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            if token not in stoi:\n",
        "                stoi[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "    return stoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LpjEFBuIUx",
        "outputId": "422cb9c7-bbfa-4350-eccb-2c6b50eb0e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_genders: 2\n",
            "num_races: 33\n",
            "num_services: 21\n",
            "num_drg_codes: 301\n"
          ]
        }
      ],
      "source": [
        "# Encoders for gender, race, curr_service, drg_code\n",
        "gender_stoi = build_label_encoder(df[\"gender\"])\n",
        "race_stoi = build_label_encoder(df[\"race\"])\n",
        "service_stoi = build_label_encoder(df[\"curr_service\"])\n",
        "\n",
        "# drg_code is already an int, but treated as a \"category\" and re-mapped to an index\n",
        "drg_code_stoi = build_label_encoder(df[\"drg_code\"].astype(int))\n",
        "\n",
        "print(\"num_genders:\", len(gender_stoi))\n",
        "print(\"num_races:\", len(race_stoi))\n",
        "print(\"num_services:\", len(service_stoi))\n",
        "print(\"num_drg_codes:\", len(drg_code_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jysvDQ6KuKI3",
        "outputId": "236806f7-58d9-4896-bc9d-f751e8afa69c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diag vocab size: 27701\n",
            "proc vocab size: 12184\n",
            "hcpcs vocab size: 1925\n",
            "med vocab size: 3358\n",
            "order vocab size: 17\n"
          ]
        }
      ],
      "source": [
        "list_cols = [\n",
        "    \"diagnoses_icd_code_list\",\n",
        "    \"procedures_icd_code_list\",\n",
        "    \"hcpcs_cd_list\",\n",
        "    \"medication_list\",\n",
        "    \"order_type_list\",\n",
        "]\n",
        "\n",
        "diag_stoi = build_vocab_from_list_column(df, \"diagnoses_icd_code_list\", min_freq=1)\n",
        "proc_stoi = build_vocab_from_list_column(df, \"procedures_icd_code_list\", min_freq=1)\n",
        "hcpcs_stoi = build_vocab_from_list_column(df, \"hcpcs_cd_list\", min_freq=1)\n",
        "med_stoi = build_vocab_from_list_column(df, \"medication_list\", min_freq=1)\n",
        "order_stoi = build_vocab_from_list_column(df, \"order_type_list\", min_freq=1)\n",
        "\n",
        "print(\"diag vocab size:\", len(diag_stoi))\n",
        "print(\"proc vocab size:\", len(proc_stoi))\n",
        "print(\"hcpcs vocab size:\", len(hcpcs_stoi))\n",
        "print(\"med vocab size:\", len(med_stoi))\n",
        "print(\"order vocab size:\", len(order_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prFr0KUjuNiy",
        "outputId": "b71c0aa8-ddcf-42df-feb2-ee8d595e7922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "combined proc vocab size: 14108\n"
          ]
        }
      ],
      "source": [
        "# Combine proc_stoi and hcpcs_stoi into a single unified vocab\n",
        "proc_all_stoi = {}\n",
        "idx = 0\n",
        "\n",
        "# Only one UNK\n",
        "proc_all_stoi[\"<UNK>\"] = idx\n",
        "idx += 1\n",
        "\n",
        "# Procedures first\n",
        "for k in proc_stoi.keys():\n",
        "    if k == \"<UNK>\":\n",
        "        continue\n",
        "    proc_all_stoi[\"PROC_\" + k] = idx\n",
        "    idx += 1\n",
        "\n",
        "# HCPCS next\n",
        "for k in hcpcs_stoi.keys():\n",
        "    if k == \"<UNK>\":\n",
        "        continue\n",
        "    key = \"HCPCS_\" + k\n",
        "    if key not in proc_all_stoi:\n",
        "        proc_all_stoi[key] = idx\n",
        "        idx += 1\n",
        "\n",
        "print(\"combined proc vocab size:\", len(proc_all_stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vqz1gkzjuQpZ"
      },
      "outputs": [],
      "source": [
        "UNK_DIAG = diag_stoi[\"<UNK>\"]\n",
        "UNK_PROC = proc_all_stoi[\"<UNK>\"]\n",
        "UNK_MED = med_stoi[\"<UNK>\"]\n",
        "UNK_ORDER = order_stoi[\"<UNK>\"]\n",
        "\n",
        "def map_list_to_ids(lst, stoi, unk_token=\"<UNK>\"):\n",
        "    unk_idx = stoi.get(unk_token, None)\n",
        "    out = []\n",
        "    for x in lst:\n",
        "        idx = stoi.get(x)\n",
        "        if idx is None:\n",
        "            if unk_idx is not None:\n",
        "                out.append(unk_idx)\n",
        "        else:\n",
        "            out.append(idx)\n",
        "    return out\n",
        "\n",
        "# Diagnosis codes\n",
        "df[\"diag_ids\"] = df[\"diagnoses_icd_code_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, diag_stoi)\n",
        ")\n",
        "\n",
        "# Combined procedure + hcpcs ids\n",
        "def build_proc_ids(row):\n",
        "    ids = []\n",
        "    for code in row[\"procedures_icd_code_list\"]:\n",
        "        tok = \"PROC_\" + code\n",
        "        ids.append(proc_all_stoi.get(tok, UNK_PROC))\n",
        "    for code in row[\"hcpcs_cd_list\"]:\n",
        "        tok = \"HCPCS_\" + code\n",
        "        ids.append(proc_all_stoi.get(tok, UNK_PROC))\n",
        "    return ids\n",
        "\n",
        "df[\"proc_ids\"] = df.apply(build_proc_ids, axis=1)\n",
        "\n",
        "# Medication\n",
        "df[\"med_ids\"] = df[\"medication_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, med_stoi)\n",
        ")\n",
        "\n",
        "# Order type\n",
        "df[\"order_ids\"] = df[\"order_type_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, order_stoi)\n",
        ")\n",
        "\n",
        "# Single categorical -> id\n",
        "df[\"gender_id\"] = df[\"gender\"].map(gender_stoi)\n",
        "df[\"race_id\"] = df[\"race\"].map(race_stoi)\n",
        "df[\"service_id\"] = df[\"curr_service\"].map(service_stoi)\n",
        "df[\"drg_code_id\"] = df[\"drg_code\"].astype(int).map(drg_code_stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTxymZbB-_YY",
        "outputId": "d9033e31-733d-4567-b85b-2469f45605b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================ SAMPLE DATA (after encoding) ================\n",
            "\n",
            "--- Row 0 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 279\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 135\n",
            "diagnoses_icd_code_list   : ['07071' '78959' '2875' '2761' '496' '5715' 'V08' '3051']\n",
            "diag_ids                  : [1, 2, 3, 4, 5, 6, 7, 8]\n",
            "procedures_icd_code_list  : ['5491']\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : [1]\n",
            "medication_list           : ['Raltegravir' 'Rifaximin' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Calcium Carbonate' 'Rifaximin' 'Raltegravir'\n",
            " 'Emtricitabine-Tenofovir (Truvada)' 'Sulfameth/Trimethoprim DS'\n",
            " 'Furosemide' 'Tiotropium Bromide' 'Albuterol Inhaler' 'Lactulose'\n",
            " 'Heparin' 'Sodium Chloride 0.9%  Flush' 'Acetaminophen' 'Heparin'\n",
            " 'Lactulose' 'Albumin 25% (12.5g / 50mL)' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Albumin 25% (12.5g / 50mL)' 'Albumin 25% (12.5g / 50mL)']\n",
            "med_ids                   : [1, 2, 3, 4, 2, 1, 5, 6, 7, 8, '...(+11 more)']\n",
            "order_type_list           : ['Medications' 'General Care' 'Nutrition' 'Blood Bank' 'Lab' 'Respiratory'\n",
            " 'Medications' 'Medications' 'ADT orders' 'Lab' 'Lab' 'Medications'\n",
            " 'ADT orders' 'ADT orders' 'ADT orders' 'ADT orders' 'Lab' 'ADT orders'\n",
            " 'Lab' 'General Care' 'Nutrition' 'Medications' 'ADT orders' 'Lab'\n",
            " 'IV therapy' 'Medications' 'General Care' 'General Care' 'Nutrition'\n",
            " 'Medications' 'Nutrition' 'Lab' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications']\n",
            "order_ids                 : [1, 2, 3, 4, 5, 6, 1, 1, 7, 5, '...(+32 more)']\n",
            "\n",
            "\n",
            "--- Row 1 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 283\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 139\n",
            "diagnoses_icd_code_list   : ['07054' '78959' 'V462' '5715' '2767' '2761' '496' 'V08' '3051' '78791']\n",
            "diag_ids                  : [9, 2, 10, 6, 11, 4, 5, 7, 8, 12]\n",
            "procedures_icd_code_list  : ['5491']\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : [1]\n",
            "medication_list           : ['Heparin' 'Raltegravir' 'Rifaximin' 'Emtricitabine-Tenofovir (Truvada)'\n",
            " 'Lactulose' 'Fluticasone Propionate 110mcg' 'Tiotropium Bromide'\n",
            " 'Albuterol Inhaler' 'Calcium Gluconate' 'Dextrose 50%'\n",
            " 'Insulin (Regular) for Hyperkalemia' 'Sodium Polystyrene Sulfonate'\n",
            " 'TraMADOL (Ultram)' 'Lactulose' 'Heparin' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Lactulose' 'Albuterol Inhaler' 'Insulin (Regular) for Hyperkalemia'\n",
            " 'Sodium Polystyrene Sulfonate' 'Calcium Gluconate' 'Dextrose 50%'\n",
            " 'Furosemide' 'Albumin 25% (12.5g / 50mL)' 'Calcium Carbonate'\n",
            " 'Raltegravir' 'Rifaximin' 'Zolpidem Tartrate'\n",
            " 'Fluticasone Propionate 110mcg' 'Albuterol Inhaler' 'Heparin'\n",
            " 'Sodium Chloride 0.9%  Flush' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Calcium Carbonate']\n",
            "med_ids                   : [11, 1, 2, 5, 10, 14, 8, 9, 15, 16, '...(+24 more)']\n",
            "order_type_list           : ['Lab' 'ADT orders' 'Lab' 'General Care' 'General Care' 'Nutrition'\n",
            " 'Medications' 'ADT orders' 'Lab' 'IV therapy' 'Medications'\n",
            " 'General Care' 'General Care' 'General Care' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Radiology' 'Nutrition' 'Nutrition' 'ADT orders' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Cardiology' 'Lab'\n",
            " 'Medications' 'Consults' 'Consults' 'General Care' 'Medications' 'Lab'\n",
            " 'Medications' 'Lab' 'Lab' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'General Care' 'General Care' 'Medications' 'Medications'\n",
            " 'Lab']\n",
            "order_ids                 : [5, 7, 5, 2, 2, 3, 1, 7, 5, 8, '...(+45 more)']\n",
            "\n",
            "\n",
            "--- Row 2 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 207\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 103\n",
            "diagnoses_icd_code_list   : ['45829' '07044' '7994' '2761' '78959' '2767' '3051' 'V08' 'V4986' 'V462'\n",
            " '496' '29680' '5715']\n",
            "diag_ids                  : [13, 14, 15, 4, 2, 11, 8, 7, 16, 10, '...(+3 more)']\n",
            "procedures_icd_code_list  : []\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : []\n",
            "medication_list           : ['Lactulose' 'TraMADOL (Ultram)' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Albumin 25% (12.5g / 50mL)' 'Bisacodyl' 'Calcium Carbonate'\n",
            " 'Docusate Sodium (Liquid)' 'Emtricitabine-Tenofovir (Truvada)'\n",
            " 'Fluticasone Propionate 110mcg' 'Heparin' 'Lactulose' 'Raltegravir'\n",
            " 'Rifaximin' 'Tiotropium Bromide']\n",
            "med_ids                   : [10, 19, 3, 13, 21, 4, 22, 5, 14, 11, '...(+4 more)']\n",
            "order_type_list           : ['Lab' 'ADT orders' 'Lab' 'General Care' 'General Care' 'General Care'\n",
            " 'Nutrition' 'Medications' 'ADT orders' 'Lab' 'General Care'\n",
            " 'General Care' 'General Care' 'Nutrition' 'Medications' 'Medications'\n",
            " 'Medications' 'General Care' 'Medications' 'Respiratory' 'General Care'\n",
            " 'Lab' 'Medications' 'Lab' 'Nutrition' 'Medications' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Lab' 'ADT orders' 'Lab' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Nutrition' 'Nutrition' 'IV therapy' 'Medications' 'General Care'\n",
            " 'General Care' 'General Care' 'Lab' 'General Care' 'Medications'\n",
            " 'Medications' 'Lab' 'General Care' 'ADT orders' 'Lab' 'Medications'\n",
            " 'Consults' 'Consults' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications']\n",
            "order_ids                 : [5, 7, 5, 2, 2, 2, 3, 1, 7, 5, '...(+61 more)']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def summarize_list(lst, max_len=10):\n",
        "    \"\"\"\n",
        "    Summarizes a list by truncating if it's too long, showing only the beginning.\n",
        "    \"\"\"\n",
        "    if lst is None:\n",
        "        return None\n",
        "    if len(lst) <= max_len:\n",
        "        return lst\n",
        "    return lst[:max_len] + [\"...(+{} more)\".format(len(lst) - max_len)]\n",
        "\n",
        "\n",
        "# Print 3 samples\n",
        "cols_to_show = [\n",
        "    \"gender\", \"race\", \"curr_service\", \"drg_code\",\n",
        "    \"gender_id\", \"race_id\", \"service_id\", \"drg_code_id\",\n",
        "    \"diagnoses_icd_code_list\", \"diag_ids\",\n",
        "    \"procedures_icd_code_list\", \"hcpcs_cd_list\", \"proc_ids\",\n",
        "    \"medication_list\", \"med_ids\",\n",
        "    \"order_type_list\", \"order_ids\",\n",
        "]\n",
        "\n",
        "print(\"\\n================ SAMPLE DATA (after encoding) ================\\n\")\n",
        "\n",
        "for i in range(3):\n",
        "    row = df.iloc[i]\n",
        "    print(f\"--- Row {i} ---\")\n",
        "\n",
        "    for c in cols_to_show:\n",
        "        val = row[c]\n",
        "\n",
        "        # Summarize list\n",
        "        if isinstance(val, list):\n",
        "            val = summarize_list(val)\n",
        "\n",
        "        print(f\"{c:25} : {val}\")\n",
        "\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D0LX9ClZuTkx"
      },
      "outputs": [],
      "source": [
        "class LOSDataset(Dataset):\n",
        "    def __init__(self, df, use_log_target=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.use_log_target = use_log_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        sample = {\n",
        "            # tabular\n",
        "            \"age\": float(row[\"anchor_age\"]),\n",
        "            \"gender_id\": int(row[\"gender_id\"]),\n",
        "            \"race_id\": int(row[\"race_id\"]),\n",
        "            \"service_id\": int(row[\"service_id\"]),\n",
        "            \"drg_code_id\": int(row[\"drg_code_id\"]),\n",
        "            \"drg_severity\": float(row[\"drg_severity\"]),\n",
        "            \"drg_mortality\": float(row[\"drg_mortality\"]),\n",
        "\n",
        "            # List-type IDs\n",
        "            \"diag_ids\": row[\"diag_ids\"],\n",
        "            \"proc_ids\": row[\"proc_ids\"],\n",
        "            \"med_ids\": row[\"med_ids\"],\n",
        "            \"order_ids\": row[\"order_ids\"],\n",
        "        }\n",
        "\n",
        "        # target\n",
        "        los = float(row[\"los_hours\"])\n",
        "        if self.use_log_target:\n",
        "            sample[\"target\"] = np.log1p(los)\n",
        "        else:\n",
        "            sample[\"target\"] = los\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZBngU2IuZuA"
      },
      "outputs": [],
      "source": [
        "def los_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: list of samples(dict)\n",
        "    For EmbeddingBag, creates and returns:\n",
        "    - codes: 1D LongTensor\n",
        "    - offsets: LongTensor (length B+1, based on include_last_offset=True)\n",
        "    for each list-type feature.\n",
        "    \"\"\"\n",
        "    B = len(batch)\n",
        "\n",
        "    # ----- Stack Tabular Features -----\n",
        "    age = torch.tensor([b[\"age\"] for b in batch], dtype=torch.float32)\n",
        "    gender_id = torch.tensor([b[\"gender_id\"] for b in batch], dtype=torch.long)\n",
        "    race_id = torch.tensor([b[\"race_id\"] for b in batch], dtype=torch.long)\n",
        "    service_id = torch.tensor([b[\"service_id\"] for b in batch], dtype=torch.long)\n",
        "    drg_code_id = torch.tensor([b[\"drg_code_id\"] for b in batch], dtype=torch.long)\n",
        "    drg_severity = torch.tensor([b[\"drg_severity\"] for b in batch], dtype=torch.float32)\n",
        "    drg_mortality = torch.tensor([b[\"drg_mortality\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    target = torch.tensor([b[\"target\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    # ----- List-type Features: diag / proc / med / order -----\n",
        "    def build_bag_inputs(key):\n",
        "        codes_all = []\n",
        "        offsets = [0]\n",
        "        for b in batch:\n",
        "            ids = b[key]\n",
        "            codes_all.extend(ids)\n",
        "            offsets.append(len(codes_all))\n",
        "        if len(codes_all) == 0:\n",
        "            # Handle cases where the list is empty for all admissions\n",
        "            codes_tensor = torch.empty(0, dtype=torch.long)\n",
        "        else:\n",
        "            codes_tensor = torch.tensor(codes_all, dtype=torch.long)\n",
        "        offsets_tensor = torch.tensor(offsets, dtype=torch.long)\n",
        "        return codes_tensor, offsets_tensor\n",
        "\n",
        "    diag_codes, diag_offsets = build_bag_inputs(\"diag_ids\")\n",
        "    proc_codes, proc_offsets = build_bag_inputs(\"proc_ids\")\n",
        "    med_codes, med_offsets = build_bag_inputs(\"med_ids\")\n",
        "    order_codes, order_offsets = build_bag_inputs(\"order_ids\")\n",
        "\n",
        "    batch_out = {\n",
        "        \"age\": age,\n",
        "        \"gender_id\": gender_id,\n",
        "        \"race_id\": race_id,\n",
        "        \"service_id\": service_id,\n",
        "        \"drg_code_id\": drg_code_id,\n",
        "        \"drg_severity\": drg_severity,\n",
        "        \"drg_mortality\": drg_mortality,\n",
        "        \"diag_codes\": diag_codes,\n",
        "        \"diag_offsets\": diag_offsets,\n",
        "        \"proc_codes\": proc_codes,\n",
        "        \"proc_offsets\": proc_offsets,\n",
        "        \"med_codes\": med_codes,\n",
        "        \"med_offsets\": med_offsets,\n",
        "        \"order_codes\": order_codes,\n",
        "        \"order_offsets\": order_offsets,\n",
        "        \"target\": target,\n",
        "    }\n",
        "\n",
        "    return batch_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmEgyvbPuaOO",
        "outputId": "24fb3df0-e86f-4e77-a512-2bc87786e71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#train: 297362, #val: 63720, #test: 63721\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "import torch\n",
        "\n",
        "# Create Dataset\n",
        "dataset = LOSDataset(df, use_log_target=True)\n",
        "\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * 0.7)\n",
        "n_val = int(n_total * 0.15)\n",
        "n_test = n_total - n_train - n_val   # remaining\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test], generator=g)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "print(f\"#train: {len(train_ds)}, #val: {len(val_ds)}, #test: {len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoKFkMU2udG8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    # ----- Tabular categorical vocab sizes -----\n",
        "    num_genders: int          # e.g. {\"M\", \"F\"} -> 2\n",
        "    num_races: int            # unique race categories\n",
        "    num_services: int         # curr_service (MED, ORTHO, ...)\n",
        "    num_drg_codes: int        # drg_code vocab size\n",
        "\n",
        "    # ----- Code vocab sizes -----\n",
        "    diag_vocab_size: int      # diagnoses_icd_code_list vocab\n",
        "    proc_vocab_size: int      # procedures_icd_code_list + hcpcs_cd_list integrated vocab\n",
        "    med_vocab_size: int       # medication_list vocab\n",
        "    order_vocab_size: int     # order_type_list vocab\n",
        "\n",
        "    # ----- Embedding dimensions -----\n",
        "    emb_dim_gender: int = 4\n",
        "    emb_dim_race: int = 8\n",
        "    emb_dim_service: int = 8\n",
        "    emb_dim_drg: int = 16\n",
        "\n",
        "    emb_dim_diag: int = 32\n",
        "    emb_dim_proc: int = 32\n",
        "    emb_dim_med: int = 32\n",
        "    emb_dim_order: int = 16\n",
        "\n",
        "    # ----- Hidden dimension for the single MLP -----\n",
        "    hidden_dim: int = 128 # This will be the hidden dimension for the combined MLP\n",
        "    dropout: float = 0.2\n",
        "\n",
        "\n",
        "class MultiModalLOSModel(nn.Module):\n",
        "    def __init__(self, cfg: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        # ------------- Embeddings for all categorical and list features -------------\n",
        "        self.gender_emb = nn.Embedding(cfg.num_genders, cfg.emb_dim_gender)\n",
        "        self.race_emb = nn.Embedding(cfg.num_races, cfg.emb_dim_race)\n",
        "        self.service_emb = nn.Embedding(cfg.num_services, cfg.emb_dim_service)\n",
        "        self.drg_emb = nn.Embedding(cfg.num_drg_codes, cfg.emb_dim_drg)\n",
        "\n",
        "        self.diag_emb = nn.EmbeddingBag(\n",
        "            cfg.diag_vocab_size, cfg.emb_dim_diag,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.proc_emb = nn.EmbeddingBag(\n",
        "            cfg.proc_vocab_size, cfg.emb_dim_proc,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.med_emb = nn.EmbeddingBag(\n",
        "            cfg.med_vocab_size, cfg.emb_dim_med,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "        self.order_emb = nn.EmbeddingBag(\n",
        "            cfg.order_vocab_size, cfg.emb_dim_order,\n",
        "            mode=\"mean\", include_last_offset=True\n",
        "        )\n",
        "\n",
        "        # Calculate total input dimension for the single MLP\n",
        "        total_in_dim = (\n",
        "            3 # for age, drg_severity, drg_mortality\n",
        "            + cfg.emb_dim_gender\n",
        "            + cfg.emb_dim_race\n",
        "            + cfg.emb_dim_service\n",
        "            + cfg.emb_dim_drg\n",
        "            + cfg.emb_dim_diag\n",
        "            + cfg.emb_dim_proc\n",
        "            + cfg.emb_dim_med\n",
        "            + cfg.emb_dim_order\n",
        "        )\n",
        "\n",
        "        # Single MLP for all combined features\n",
        "        self.main_mlp = nn.Sequential(\n",
        "            nn.Linear(total_in_dim, cfg.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.Linear(cfg.hidden_dim, cfg.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "        )\n",
        "\n",
        "        # Final regression output layer (LOS prediction)\n",
        "        self.out = nn.Linear(cfg.hidden_dim, 1)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        # ----- Tabular -----\n",
        "        age,               # (B,) float tensor (anchor_age or normalized)\n",
        "        gender_idx,        # (B,) long tensor\n",
        "        race_idx,          # (B,) long tensor\n",
        "        service_idx,       # (B,) long tensor (curr_service)\n",
        "        drg_code_idx,      # (B,) long tensor\n",
        "        drg_severity,      # (B,) float or long (normalize to float first)\n",
        "        drg_mortality,     # (B,) float or long\n",
        "\n",
        "        # ----- Diagnoses (EmbeddingBag) -----\n",
        "        diag_codes,        # (N_diag_codes,) long tensor (flattened)\n",
        "        diag_offsets,      # (B+1,) long tensor, offsets for EmbeddingBag\n",
        "\n",
        "        # ----- Procedures (EmbeddingBag) -----\n",
        "        proc_codes,        # (N_proc_codes,) long tensor\n",
        "        proc_offsets,      # (B+1,) long tensor\n",
        "\n",
        "        # ----- Medications (EmbeddingBag) -----\n",
        "        med_codes,         # (N_med_codes,) long tensor\n",
        "        med_offsets,       # (B+1,) long tensor\n",
        "\n",
        "        # ----- Order types (EmbeddingBag) -----\n",
        "        order_codes,       # (N_order_codes,) long tensor\n",
        "        order_offsets,     # (B+1,) long tensor\n",
        "    ):\n",
        "        # Embeddings for categorical features\n",
        "        g_emb = self.gender_emb(gender_idx)   # (B, emb_dim_gender)\n",
        "        r_emb = self.race_emb(race_idx)       # (B, emb_dim_race)\n",
        "        s_emb = self.service_emb(service_idx) # (B, emb_dim_service)\n",
        "        d_emb = self.drg_emb(drg_code_idx)    # (B, emb_dim_drg)\n",
        "\n",
        "        # EmbeddingBag for list features\n",
        "        diag_bag = self.diag_emb(diag_codes, diag_offsets)  # (B, emb_dim_diag)\n",
        "        proc_bag = self.proc_emb(proc_codes, proc_offsets)  # (B, emb_dim_proc)\n",
        "        med_bag = self.med_emb(med_codes, med_offsets)      # (B, emb_dim_med)\n",
        "        order_bag = self.order_emb(order_codes, order_offsets) # (B, emb_dim_order)\n",
        "\n",
        "        # Continuous features (unsqueeze for concatenation)\n",
        "        age = age.float().unsqueeze(-1)                 # (B, 1)\n",
        "        sev = drg_severity.float().unsqueeze(-1)        # (B, 1)\n",
        "        mort = drg_mortality.float().unsqueeze(-1)      # (B, 1)\n",
        "\n",
        "        # Concatenate all features into a single tensor\n",
        "        all_features = torch.cat(\n",
        "            [\n",
        "                age, sev, mort,\n",
        "                g_emb, r_emb, s_emb, d_emb,\n",
        "                diag_bag, proc_bag, med_bag, order_bag\n",
        "            ],\n",
        "            dim=-1\n",
        "        )\n",
        "\n",
        "        # Pass the combined features through the main MLP\n",
        "        h = self.main_mlp(all_features)\n",
        "        out = self.out(h).squeeze(-1)  # (B,)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZm2f-aivdkb",
        "outputId": "c12c999c-b78e-46da-89bf-c4d1b2750483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "========== Epoch 1/20 ==========\n",
            "  [Epoch 1 | Step 0/1162] AvgTrainLoss=36.3356\n",
            "  [Epoch 1 | Step 100/1162] AvgTrainLoss=3.0450\n",
            "  [Epoch 1 | Step 200/1162] AvgTrainLoss=1.9264\n",
            "  [Epoch 1 | Step 300/1162] AvgTrainLoss=1.5110\n",
            "  [Epoch 1 | Step 400/1162] AvgTrainLoss=1.2952\n",
            "  [Epoch 1 | Step 500/1162] AvgTrainLoss=1.1597\n",
            "  [Epoch 1 | Step 600/1162] AvgTrainLoss=1.0666\n",
            "  [Epoch 1 | Step 700/1162] AvgTrainLoss=0.9969\n",
            "  [Epoch 1 | Step 800/1162] AvgTrainLoss=0.9423\n",
            "  [Epoch 1 | Step 900/1162] AvgTrainLoss=0.8989\n",
            "  [Epoch 1 | Step 1000/1162] AvgTrainLoss=0.8637\n",
            "  [Epoch 1 | Step 1100/1162] AvgTrainLoss=0.8330\n",
            "[Epoch 001] train_loss(log-MSE)=0.8169 | val_loss(log-MSE)=0.3788 | val_MAE(hours)=70.34\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 2/20 ==========\n",
            "  [Epoch 2 | Step 0/1162] AvgTrainLoss=0.5073\n",
            "  [Epoch 2 | Step 100/1162] AvgTrainLoss=0.5092\n",
            "  [Epoch 2 | Step 200/1162] AvgTrainLoss=0.5009\n",
            "  [Epoch 2 | Step 300/1162] AvgTrainLoss=0.4953\n",
            "  [Epoch 2 | Step 400/1162] AvgTrainLoss=0.4924\n",
            "  [Epoch 2 | Step 500/1162] AvgTrainLoss=0.4883\n",
            "  [Epoch 2 | Step 600/1162] AvgTrainLoss=0.4857\n",
            "  [Epoch 2 | Step 700/1162] AvgTrainLoss=0.4824\n",
            "  [Epoch 2 | Step 800/1162] AvgTrainLoss=0.4792\n",
            "  [Epoch 2 | Step 900/1162] AvgTrainLoss=0.4760\n",
            "  [Epoch 2 | Step 1000/1162] AvgTrainLoss=0.4724\n",
            "  [Epoch 2 | Step 1100/1162] AvgTrainLoss=0.4704\n",
            "[Epoch 002] train_loss(log-MSE)=0.4691 | val_loss(log-MSE)=0.3076 | val_MAE(hours)=64.72\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 3/20 ==========\n",
            "  [Epoch 3 | Step 0/1162] AvgTrainLoss=0.3816\n",
            "  [Epoch 3 | Step 100/1162] AvgTrainLoss=0.4291\n",
            "  [Epoch 3 | Step 200/1162] AvgTrainLoss=0.4257\n",
            "  [Epoch 3 | Step 300/1162] AvgTrainLoss=0.4262\n",
            "  [Epoch 3 | Step 400/1162] AvgTrainLoss=0.4246\n",
            "  [Epoch 3 | Step 500/1162] AvgTrainLoss=0.4231\n",
            "  [Epoch 3 | Step 600/1162] AvgTrainLoss=0.4220\n",
            "  [Epoch 3 | Step 700/1162] AvgTrainLoss=0.4190\n",
            "  [Epoch 3 | Step 800/1162] AvgTrainLoss=0.4170\n",
            "  [Epoch 3 | Step 900/1162] AvgTrainLoss=0.4152\n",
            "  [Epoch 3 | Step 1000/1162] AvgTrainLoss=0.4132\n",
            "  [Epoch 3 | Step 1100/1162] AvgTrainLoss=0.4112\n",
            "[Epoch 003] train_loss(log-MSE)=0.4097 | val_loss(log-MSE)=0.2944 | val_MAE(hours)=63.92\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 4/20 ==========\n",
            "  [Epoch 4 | Step 0/1162] AvgTrainLoss=0.3141\n",
            "  [Epoch 4 | Step 100/1162] AvgTrainLoss=0.3842\n",
            "  [Epoch 4 | Step 200/1162] AvgTrainLoss=0.3802\n",
            "  [Epoch 4 | Step 300/1162] AvgTrainLoss=0.3786\n",
            "  [Epoch 4 | Step 400/1162] AvgTrainLoss=0.3770\n",
            "  [Epoch 4 | Step 500/1162] AvgTrainLoss=0.3761\n",
            "  [Epoch 4 | Step 600/1162] AvgTrainLoss=0.3755\n",
            "  [Epoch 4 | Step 700/1162] AvgTrainLoss=0.3744\n",
            "  [Epoch 4 | Step 800/1162] AvgTrainLoss=0.3733\n",
            "  [Epoch 4 | Step 900/1162] AvgTrainLoss=0.3715\n",
            "  [Epoch 4 | Step 1000/1162] AvgTrainLoss=0.3709\n",
            "  [Epoch 4 | Step 1100/1162] AvgTrainLoss=0.3700\n",
            "[Epoch 004] train_loss(log-MSE)=0.3695 | val_loss(log-MSE)=0.2820 | val_MAE(hours)=62.37\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 5/20 ==========\n",
            "  [Epoch 5 | Step 0/1162] AvgTrainLoss=0.3776\n",
            "  [Epoch 5 | Step 100/1162] AvgTrainLoss=0.3498\n",
            "  [Epoch 5 | Step 200/1162] AvgTrainLoss=0.3483\n",
            "  [Epoch 5 | Step 300/1162] AvgTrainLoss=0.3470\n",
            "  [Epoch 5 | Step 400/1162] AvgTrainLoss=0.3453\n",
            "  [Epoch 5 | Step 500/1162] AvgTrainLoss=0.3458\n",
            "  [Epoch 5 | Step 600/1162] AvgTrainLoss=0.3453\n",
            "  [Epoch 5 | Step 700/1162] AvgTrainLoss=0.3445\n",
            "  [Epoch 5 | Step 800/1162] AvgTrainLoss=0.3443\n",
            "  [Epoch 5 | Step 900/1162] AvgTrainLoss=0.3439\n",
            "  [Epoch 5 | Step 1000/1162] AvgTrainLoss=0.3436\n",
            "  [Epoch 5 | Step 1100/1162] AvgTrainLoss=0.3431\n",
            "[Epoch 005] train_loss(log-MSE)=0.3430 | val_loss(log-MSE)=0.2774 | val_MAE(hours)=61.97\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 6/20 ==========\n",
            "  [Epoch 6 | Step 0/1162] AvgTrainLoss=0.2728\n",
            "  [Epoch 6 | Step 100/1162] AvgTrainLoss=0.3268\n",
            "  [Epoch 6 | Step 200/1162] AvgTrainLoss=0.3282\n",
            "  [Epoch 6 | Step 300/1162] AvgTrainLoss=0.3282\n",
            "  [Epoch 6 | Step 400/1162] AvgTrainLoss=0.3258\n",
            "  [Epoch 6 | Step 500/1162] AvgTrainLoss=0.3264\n",
            "  [Epoch 6 | Step 600/1162] AvgTrainLoss=0.3275\n",
            "  [Epoch 6 | Step 700/1162] AvgTrainLoss=0.3266\n",
            "  [Epoch 6 | Step 800/1162] AvgTrainLoss=0.3266\n",
            "  [Epoch 6 | Step 900/1162] AvgTrainLoss=0.3267\n",
            "  [Epoch 6 | Step 1000/1162] AvgTrainLoss=0.3265\n",
            "  [Epoch 6 | Step 1100/1162] AvgTrainLoss=0.3263\n",
            "[Epoch 006] train_loss(log-MSE)=0.3264 | val_loss(log-MSE)=0.2830 | val_MAE(hours)=62.32\n",
            "\n",
            "========== Epoch 7/20 ==========\n",
            "  [Epoch 7 | Step 0/1162] AvgTrainLoss=0.3708\n",
            "  [Epoch 7 | Step 100/1162] AvgTrainLoss=0.3095\n",
            "  [Epoch 7 | Step 200/1162] AvgTrainLoss=0.3102\n",
            "  [Epoch 7 | Step 300/1162] AvgTrainLoss=0.3108\n",
            "  [Epoch 7 | Step 400/1162] AvgTrainLoss=0.3125\n",
            "  [Epoch 7 | Step 500/1162] AvgTrainLoss=0.3116\n",
            "  [Epoch 7 | Step 600/1162] AvgTrainLoss=0.3118\n",
            "  [Epoch 7 | Step 700/1162] AvgTrainLoss=0.3131\n",
            "  [Epoch 7 | Step 800/1162] AvgTrainLoss=0.3129\n",
            "  [Epoch 7 | Step 900/1162] AvgTrainLoss=0.3138\n",
            "  [Epoch 7 | Step 1000/1162] AvgTrainLoss=0.3142\n",
            "  [Epoch 7 | Step 1100/1162] AvgTrainLoss=0.3137\n",
            "[Epoch 007] train_loss(log-MSE)=0.3135 | val_loss(log-MSE)=0.2800 | val_MAE(hours)=62.32\n",
            "\n",
            "========== Epoch 8/20 ==========\n",
            "  [Epoch 8 | Step 0/1162] AvgTrainLoss=0.2724\n",
            "  [Epoch 8 | Step 100/1162] AvgTrainLoss=0.3004\n",
            "  [Epoch 8 | Step 200/1162] AvgTrainLoss=0.3025\n",
            "  [Epoch 8 | Step 300/1162] AvgTrainLoss=0.3050\n",
            "  [Epoch 8 | Step 400/1162] AvgTrainLoss=0.3056\n",
            "  [Epoch 8 | Step 500/1162] AvgTrainLoss=0.3059\n",
            "  [Epoch 8 | Step 600/1162] AvgTrainLoss=0.3057\n",
            "  [Epoch 8 | Step 700/1162] AvgTrainLoss=0.3046\n",
            "  [Epoch 8 | Step 800/1162] AvgTrainLoss=0.3048\n",
            "  [Epoch 8 | Step 900/1162] AvgTrainLoss=0.3046\n",
            "  [Epoch 8 | Step 1000/1162] AvgTrainLoss=0.3043\n",
            "  [Epoch 8 | Step 1100/1162] AvgTrainLoss=0.3039\n",
            "[Epoch 008] train_loss(log-MSE)=0.3043 | val_loss(log-MSE)=0.2738 | val_MAE(hours)=61.67\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 9/20 ==========\n",
            "  [Epoch 9 | Step 0/1162] AvgTrainLoss=0.2927\n",
            "  [Epoch 9 | Step 100/1162] AvgTrainLoss=0.2961\n",
            "  [Epoch 9 | Step 200/1162] AvgTrainLoss=0.2915\n",
            "  [Epoch 9 | Step 300/1162] AvgTrainLoss=0.2941\n",
            "  [Epoch 9 | Step 400/1162] AvgTrainLoss=0.2949\n",
            "  [Epoch 9 | Step 500/1162] AvgTrainLoss=0.2947\n",
            "  [Epoch 9 | Step 600/1162] AvgTrainLoss=0.2945\n",
            "  [Epoch 9 | Step 700/1162] AvgTrainLoss=0.2948\n",
            "  [Epoch 9 | Step 800/1162] AvgTrainLoss=0.2950\n",
            "  [Epoch 9 | Step 900/1162] AvgTrainLoss=0.2950\n",
            "  [Epoch 9 | Step 1000/1162] AvgTrainLoss=0.2947\n",
            "  [Epoch 9 | Step 1100/1162] AvgTrainLoss=0.2947\n",
            "[Epoch 009] train_loss(log-MSE)=0.2951 | val_loss(log-MSE)=0.2698 | val_MAE(hours)=60.94\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 10/20 ==========\n",
            "  [Epoch 10 | Step 0/1162] AvgTrainLoss=0.2713\n",
            "  [Epoch 10 | Step 100/1162] AvgTrainLoss=0.2789\n",
            "  [Epoch 10 | Step 200/1162] AvgTrainLoss=0.2797\n",
            "  [Epoch 10 | Step 300/1162] AvgTrainLoss=0.2818\n",
            "  [Epoch 10 | Step 400/1162] AvgTrainLoss=0.2831\n",
            "  [Epoch 10 | Step 500/1162] AvgTrainLoss=0.2845\n",
            "  [Epoch 10 | Step 600/1162] AvgTrainLoss=0.2855\n",
            "  [Epoch 10 | Step 700/1162] AvgTrainLoss=0.2855\n",
            "  [Epoch 10 | Step 800/1162] AvgTrainLoss=0.2854\n",
            "  [Epoch 10 | Step 900/1162] AvgTrainLoss=0.2854\n",
            "  [Epoch 10 | Step 1000/1162] AvgTrainLoss=0.2857\n",
            "  [Epoch 10 | Step 1100/1162] AvgTrainLoss=0.2860\n",
            "[Epoch 010] train_loss(log-MSE)=0.2860 | val_loss(log-MSE)=0.2667 | val_MAE(hours)=60.61\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 11/20 ==========\n",
            "  [Epoch 11 | Step 0/1162] AvgTrainLoss=0.3126\n",
            "  [Epoch 11 | Step 100/1162] AvgTrainLoss=0.2774\n",
            "  [Epoch 11 | Step 200/1162] AvgTrainLoss=0.2761\n",
            "  [Epoch 11 | Step 300/1162] AvgTrainLoss=0.2778\n",
            "  [Epoch 11 | Step 400/1162] AvgTrainLoss=0.2781\n",
            "  [Epoch 11 | Step 500/1162] AvgTrainLoss=0.2780\n",
            "  [Epoch 11 | Step 600/1162] AvgTrainLoss=0.2788\n",
            "  [Epoch 11 | Step 700/1162] AvgTrainLoss=0.2787\n",
            "  [Epoch 11 | Step 800/1162] AvgTrainLoss=0.2788\n",
            "  [Epoch 11 | Step 900/1162] AvgTrainLoss=0.2796\n",
            "  [Epoch 11 | Step 1000/1162] AvgTrainLoss=0.2795\n",
            "  [Epoch 11 | Step 1100/1162] AvgTrainLoss=0.2794\n",
            "[Epoch 011] train_loss(log-MSE)=0.2797 | val_loss(log-MSE)=0.2662 | val_MAE(hours)=60.51\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 12/20 ==========\n",
            "  [Epoch 12 | Step 0/1162] AvgTrainLoss=0.2768\n",
            "  [Epoch 12 | Step 100/1162] AvgTrainLoss=0.2702\n",
            "  [Epoch 12 | Step 200/1162] AvgTrainLoss=0.2710\n",
            "  [Epoch 12 | Step 300/1162] AvgTrainLoss=0.2721\n",
            "  [Epoch 12 | Step 400/1162] AvgTrainLoss=0.2712\n",
            "  [Epoch 12 | Step 500/1162] AvgTrainLoss=0.2717\n",
            "  [Epoch 12 | Step 600/1162] AvgTrainLoss=0.2717\n",
            "  [Epoch 12 | Step 700/1162] AvgTrainLoss=0.2719\n",
            "  [Epoch 12 | Step 800/1162] AvgTrainLoss=0.2723\n",
            "  [Epoch 12 | Step 900/1162] AvgTrainLoss=0.2721\n",
            "  [Epoch 12 | Step 1000/1162] AvgTrainLoss=0.2722\n",
            "  [Epoch 12 | Step 1100/1162] AvgTrainLoss=0.2726\n",
            "[Epoch 012] train_loss(log-MSE)=0.2728 | val_loss(log-MSE)=0.2650 | val_MAE(hours)=60.56\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 13/20 ==========\n",
            "  [Epoch 13 | Step 0/1162] AvgTrainLoss=0.1985\n",
            "  [Epoch 13 | Step 100/1162] AvgTrainLoss=0.2616\n",
            "  [Epoch 13 | Step 200/1162] AvgTrainLoss=0.2618\n",
            "  [Epoch 13 | Step 300/1162] AvgTrainLoss=0.2632\n",
            "  [Epoch 13 | Step 400/1162] AvgTrainLoss=0.2642\n",
            "  [Epoch 13 | Step 500/1162] AvgTrainLoss=0.2648\n",
            "  [Epoch 13 | Step 600/1162] AvgTrainLoss=0.2649\n",
            "  [Epoch 13 | Step 700/1162] AvgTrainLoss=0.2654\n",
            "  [Epoch 13 | Step 800/1162] AvgTrainLoss=0.2663\n",
            "  [Epoch 13 | Step 900/1162] AvgTrainLoss=0.2666\n",
            "  [Epoch 13 | Step 1000/1162] AvgTrainLoss=0.2667\n",
            "  [Epoch 13 | Step 1100/1162] AvgTrainLoss=0.2668\n",
            "[Epoch 013] train_loss(log-MSE)=0.2670 | val_loss(log-MSE)=0.2625 | val_MAE(hours)=60.20\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 14/20 ==========\n",
            "  [Epoch 14 | Step 0/1162] AvgTrainLoss=0.2871\n",
            "  [Epoch 14 | Step 100/1162] AvgTrainLoss=0.2531\n",
            "  [Epoch 14 | Step 200/1162] AvgTrainLoss=0.2563\n",
            "  [Epoch 14 | Step 300/1162] AvgTrainLoss=0.2583\n",
            "  [Epoch 14 | Step 400/1162] AvgTrainLoss=0.2601\n",
            "  [Epoch 14 | Step 500/1162] AvgTrainLoss=0.2603\n",
            "  [Epoch 14 | Step 600/1162] AvgTrainLoss=0.2602\n",
            "  [Epoch 14 | Step 700/1162] AvgTrainLoss=0.2603\n",
            "  [Epoch 14 | Step 800/1162] AvgTrainLoss=0.2602\n",
            "  [Epoch 14 | Step 900/1162] AvgTrainLoss=0.2606\n",
            "  [Epoch 14 | Step 1000/1162] AvgTrainLoss=0.2608\n",
            "  [Epoch 14 | Step 1100/1162] AvgTrainLoss=0.2615\n",
            "[Epoch 014] train_loss(log-MSE)=0.2619 | val_loss(log-MSE)=0.2687 | val_MAE(hours)=60.86\n",
            "\n",
            "========== Epoch 15/20 ==========\n",
            "  [Epoch 15 | Step 0/1162] AvgTrainLoss=0.2556\n",
            "  [Epoch 15 | Step 100/1162] AvgTrainLoss=0.2546\n",
            "  [Epoch 15 | Step 200/1162] AvgTrainLoss=0.2528\n",
            "  [Epoch 15 | Step 300/1162] AvgTrainLoss=0.2553\n",
            "  [Epoch 15 | Step 400/1162] AvgTrainLoss=0.2539\n",
            "  [Epoch 15 | Step 500/1162] AvgTrainLoss=0.2548\n",
            "  [Epoch 15 | Step 600/1162] AvgTrainLoss=0.2551\n",
            "  [Epoch 15 | Step 700/1162] AvgTrainLoss=0.2560\n",
            "  [Epoch 15 | Step 800/1162] AvgTrainLoss=0.2563\n",
            "  [Epoch 15 | Step 900/1162] AvgTrainLoss=0.2570\n",
            "  [Epoch 15 | Step 1000/1162] AvgTrainLoss=0.2571\n",
            "  [Epoch 15 | Step 1100/1162] AvgTrainLoss=0.2573\n",
            "[Epoch 015] train_loss(log-MSE)=0.2576 | val_loss(log-MSE)=0.2650 | val_MAE(hours)=60.58\n",
            "\n",
            "========== Epoch 16/20 ==========\n",
            "  [Epoch 16 | Step 0/1162] AvgTrainLoss=0.2236\n",
            "  [Epoch 16 | Step 100/1162] AvgTrainLoss=0.2447\n",
            "  [Epoch 16 | Step 200/1162] AvgTrainLoss=0.2449\n",
            "  [Epoch 16 | Step 300/1162] AvgTrainLoss=0.2477\n",
            "  [Epoch 16 | Step 400/1162] AvgTrainLoss=0.2497\n",
            "  [Epoch 16 | Step 500/1162] AvgTrainLoss=0.2496\n",
            "  [Epoch 16 | Step 600/1162] AvgTrainLoss=0.2501\n",
            "  [Epoch 16 | Step 700/1162] AvgTrainLoss=0.2502\n",
            "  [Epoch 16 | Step 800/1162] AvgTrainLoss=0.2509\n",
            "  [Epoch 16 | Step 900/1162] AvgTrainLoss=0.2520\n",
            "  [Epoch 16 | Step 1000/1162] AvgTrainLoss=0.2527\n",
            "  [Epoch 16 | Step 1100/1162] AvgTrainLoss=0.2530\n",
            "[Epoch 016] train_loss(log-MSE)=0.2530 | val_loss(log-MSE)=0.2587 | val_MAE(hours)=59.65\n",
            "  ↳ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 17/20 ==========\n",
            "  [Epoch 17 | Step 0/1162] AvgTrainLoss=0.2174\n",
            "  [Epoch 17 | Step 100/1162] AvgTrainLoss=0.2398\n",
            "  [Epoch 17 | Step 200/1162] AvgTrainLoss=0.2436\n",
            "  [Epoch 17 | Step 300/1162] AvgTrainLoss=0.2443\n",
            "  [Epoch 17 | Step 400/1162] AvgTrainLoss=0.2442\n",
            "  [Epoch 17 | Step 500/1162] AvgTrainLoss=0.2453\n",
            "  [Epoch 17 | Step 600/1162] AvgTrainLoss=0.2453\n",
            "  [Epoch 17 | Step 700/1162] AvgTrainLoss=0.2457\n",
            "  [Epoch 17 | Step 800/1162] AvgTrainLoss=0.2458\n",
            "  [Epoch 17 | Step 900/1162] AvgTrainLoss=0.2462\n",
            "  [Epoch 17 | Step 1000/1162] AvgTrainLoss=0.2469\n",
            "  [Epoch 17 | Step 1100/1162] AvgTrainLoss=0.2480\n",
            "[Epoch 017] train_loss(log-MSE)=0.2487 | val_loss(log-MSE)=0.2609 | val_MAE(hours)=59.78\n",
            "\n",
            "========== Epoch 18/20 ==========\n",
            "  [Epoch 18 | Step 0/1162] AvgTrainLoss=0.2322\n",
            "  [Epoch 18 | Step 100/1162] AvgTrainLoss=0.2340\n",
            "  [Epoch 18 | Step 200/1162] AvgTrainLoss=0.2362\n",
            "  [Epoch 18 | Step 300/1162] AvgTrainLoss=0.2367\n",
            "  [Epoch 18 | Step 400/1162] AvgTrainLoss=0.2395\n",
            "  [Epoch 18 | Step 500/1162] AvgTrainLoss=0.2409\n",
            "  [Epoch 18 | Step 600/1162] AvgTrainLoss=0.2425\n",
            "  [Epoch 18 | Step 700/1162] AvgTrainLoss=0.2434\n",
            "  [Epoch 18 | Step 800/1162] AvgTrainLoss=0.2439\n",
            "  [Epoch 18 | Step 900/1162] AvgTrainLoss=0.2441\n",
            "  [Epoch 18 | Step 1000/1162] AvgTrainLoss=0.2447\n",
            "  [Epoch 18 | Step 1100/1162] AvgTrainLoss=0.2447\n",
            "[Epoch 018] train_loss(log-MSE)=0.2447 | val_loss(log-MSE)=0.2611 | val_MAE(hours)=60.09\n",
            "\n",
            "========== Epoch 19/20 ==========\n",
            "  [Epoch 19 | Step 0/1162] AvgTrainLoss=0.2657\n",
            "  [Epoch 19 | Step 100/1162] AvgTrainLoss=0.2327\n",
            "  [Epoch 19 | Step 200/1162] AvgTrainLoss=0.2348\n",
            "  [Epoch 19 | Step 300/1162] AvgTrainLoss=0.2363\n",
            "  [Epoch 19 | Step 400/1162] AvgTrainLoss=0.2380\n",
            "  [Epoch 19 | Step 500/1162] AvgTrainLoss=0.2389\n",
            "  [Epoch 19 | Step 600/1162] AvgTrainLoss=0.2393\n",
            "  [Epoch 19 | Step 700/1162] AvgTrainLoss=0.2399\n",
            "  [Epoch 19 | Step 800/1162] AvgTrainLoss=0.2408\n",
            "  [Epoch 19 | Step 900/1162] AvgTrainLoss=0.2410\n",
            "  [Epoch 19 | Step 1000/1162] AvgTrainLoss=0.2415\n",
            "  [Epoch 19 | Step 1100/1162] AvgTrainLoss=0.2415\n",
            "[Epoch 019] train_loss(log-MSE)=0.2418 | val_loss(log-MSE)=0.2597 | val_MAE(hours)=59.93\n",
            "\n",
            "========== Epoch 20/20 ==========\n",
            "  [Epoch 20 | Step 0/1162] AvgTrainLoss=0.2432\n",
            "  [Epoch 20 | Step 100/1162] AvgTrainLoss=0.2327\n",
            "  [Epoch 20 | Step 200/1162] AvgTrainLoss=0.2324\n",
            "  [Epoch 20 | Step 300/1162] AvgTrainLoss=0.2337\n",
            "  [Epoch 20 | Step 400/1162] AvgTrainLoss=0.2350\n",
            "  [Epoch 20 | Step 500/1162] AvgTrainLoss=0.2350\n",
            "  [Epoch 20 | Step 600/1162] AvgTrainLoss=0.2357\n",
            "  [Epoch 20 | Step 700/1162] AvgTrainLoss=0.2361\n",
            "  [Epoch 20 | Step 800/1162] AvgTrainLoss=0.2370\n",
            "  [Epoch 20 | Step 900/1162] AvgTrainLoss=0.2378\n",
            "  [Epoch 20 | Step 1000/1162] AvgTrainLoss=0.2380\n",
            "  [Epoch 20 | Step 1100/1162] AvgTrainLoss=0.2384\n",
            "[Epoch 020] train_loss(log-MSE)=0.2384 | val_loss(log-MSE)=0.2600 | val_MAE(hours)=59.81\n",
            "Training finished. Best val_loss: 0.258672682395613\n"
          ]
        }
      ],
      "source": [
        "# 1. Model / Configuration Setup\n",
        "\n",
        "cfg = ModelConfig(\n",
        "    num_genders=len(gender_stoi),\n",
        "    num_races=len(race_stoi),\n",
        "    num_services=len(service_stoi),\n",
        "    num_drg_codes=len(drg_code_stoi),\n",
        "    diag_vocab_size=len(diag_stoi),\n",
        "    proc_vocab_size=len(proc_all_stoi),\n",
        "    med_vocab_size=len(med_stoi),\n",
        "    order_vocab_size=len(order_stoi),\n",
        "    hidden_dim=128,\n",
        "    dropout=0.2\n",
        ")\n",
        "\n",
        "model = MultiModalLOSModel(cfg)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()  # MSE based on log(1+LOS)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_model_path = \"los_multibranch_best.pt\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# 2. Training Loop\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # ---------- Train ----------\n",
        "    model.train()\n",
        "    train_loss_sum = 0.0\n",
        "    train_count = 0\n",
        "\n",
        "    print(f\"\\n========== Epoch {epoch}/{NUM_EPOCHS} ==========\")\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        # Move tensors to device\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # log(1+LOS)\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = y_true.size(0)\n",
        "        train_loss_sum += loss.item() * bs\n",
        "        train_count += bs\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            avg_loss = train_loss_sum / train_count\n",
        "            print(f\"  [Epoch {epoch} | Step {batch_idx}/{len(train_loader)}] \"\n",
        "                  f\"AvgTrainLoss={avg_loss:.4f}\")\n",
        "\n",
        "    train_loss = train_loss_sum / train_count\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    model.eval()\n",
        "    val_loss_sum = 0.0\n",
        "    val_count = 0\n",
        "    val_mae_hours_sum = 0.0  # MAE based on actual LOS(hours)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                     for k, v in batch.items()}\n",
        "\n",
        "            y_pred = model(\n",
        "                age=batch[\"age\"],\n",
        "                gender_idx=batch[\"gender_id\"],\n",
        "                race_idx=batch[\"race_id\"],\n",
        "                service_idx=batch[\"service_id\"],\n",
        "                drg_code_idx=batch[\"drg_code_id\"],\n",
        "                drg_severity=batch[\"drg_severity\"],\n",
        "                drg_mortality=batch[\"drg_mortality\"],\n",
        "                diag_codes=batch[\"diag_codes\"],\n",
        "                diag_offsets=batch[\"diag_offsets\"],\n",
        "                proc_codes=batch[\"proc_codes\"],\n",
        "                proc_offsets=batch[\"proc_offsets\"],\n",
        "                med_codes=batch[\"med_codes\"],\n",
        "                med_offsets=batch[\"med_offsets\"],\n",
        "                order_codes=batch[\"order_codes\"],\n",
        "                order_offsets=batch[\"order_offsets\"],\n",
        "            )\n",
        "\n",
        "            y_true = batch[\"target\"]\n",
        "\n",
        "            loss = criterion(y_pred, y_true)\n",
        "\n",
        "            bs = y_true.size(0)\n",
        "            val_loss_sum += loss.item() * bs\n",
        "            val_count += bs\n",
        "\n",
        "            # Convert log(1+LOS) -> actual LOS(hours) for MAE calculation\n",
        "            y_true_hours = torch.expm1(y_true)\n",
        "            y_pred_hours = torch.expm1(y_pred)\n",
        "\n",
        "            mae_hours = torch.abs(y_pred_hours - y_true_hours).sum().item()\n",
        "            val_mae_hours_sum += mae_hours\n",
        "\n",
        "    val_loss = val_loss_sum / val_count\n",
        "    val_mae_hours = val_mae_hours_sum / val_count\n",
        "\n",
        "    print(f\"[Epoch {epoch:03d}] \"\\\n",
        "          f\"train_loss(log-MSE)={train_loss:.4f} | \"\\\n",
        "          f\"val_loss(log-MSE)={val_loss:.4f} | \"\\\n",
        "          f\"val_MAE(hours)={val_mae_hours:.2f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"  ↳ Best model updated, saved to {best_model_path}\")\n",
        "\n",
        "print(\"Training finished. Best val_loss:\", best_val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vDQN05751XD",
        "outputId": "db3d3de6-f43b-4808-d90a-186c52323d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Test set MAE =====\n",
            "Test MAE (hours): 59.12\n",
            "Test MAE (days) : 2.46\n"
          ]
        }
      ],
      "source": [
        "# 3. Calculate MAE (hours) on the Test set\n",
        "\n",
        "best_model = MultiModalLOSModel(cfg).to(device)\n",
        "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "test_abs_error_sum = 0.0\n",
        "test_count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = best_model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # log(1+LOS)\n",
        "\n",
        "        # Convert log(1+LOS) -> actual hours\n",
        "        y_true_hours = torch.expm1(y_true)\n",
        "        y_pred_hours = torch.expm1(y_pred)\n",
        "\n",
        "        abs_err = torch.abs(y_pred_hours - y_true_hours)\n",
        "        test_abs_error_sum += abs_err.sum().item()\n",
        "        test_count += y_true.size(0)\n",
        "\n",
        "test_mae_hours = test_abs_error_sum / test_count\n",
        "\n",
        "print(f\"\\n===== Test set MAE =====\")\n",
        "print(f\"Test MAE (hours): {test_mae_hours:.2f}\")\n",
        "print(f\"Test MAE (days) : {test_mae_hours / 24:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mpmdUCi5FTdd",
        "outputId": "679c261f-e287-40c3-fd07-525f85fd2d64"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "all_abs_errors = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = best_model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # log(1+LOS)\n",
        "\n",
        "        y_true_hours = torch.expm1(y_true)\n",
        "        y_pred_hours = torch.expm1(y_pred)\n",
        "\n",
        "        abs_err = torch.abs(y_pred_hours - y_true_hours)\n",
        "\n",
        "        all_abs_errors.extend(abs_err.cpu().numpy())\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(\n",
        "    all_abs_errors,\n",
        "    bins=100,              # Number of bins\n",
        "    range=(0, 500),        # x-axis range (0~500 hours)\n",
        "    edgecolor='black',\n",
        "    alpha=0.75\n",
        ")\n",
        "\n",
        "plt.title(\"Test Set Prediction Error Distribution (Hours)\")\n",
        "plt.xlabel(\"Absolute Error (hours)\")\n",
        "plt.ylabel(\"Frequency (count)\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPZsDxsmvgCy",
        "outputId": "94038aaa-5a8e-4979-a775-3a21428caa28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====== Sample Predictions (True vs Predicted LOS) ======\n",
            "\n",
            "True LOS: 44.72 hours | Predicted: 61.32 hours | Error: 16.60\n",
            "True LOS: 55.63 hours | Predicted: 125.80 hours | Error: 70.16\n",
            "True LOS: 90.42 hours | Predicted: 150.41 hours | Error: 60.00\n",
            "True LOS: 24.08 hours | Predicted: 81.25 hours | Error: 57.17\n",
            "True LOS: 106.88 hours | Predicted: 55.25 hours | Error: 51.63\n",
            "True LOS: 247.07 hours | Predicted: 94.80 hours | Error: 152.26\n",
            "True LOS: 261.08 hours | Predicted: 131.88 hours | Error: 129.21\n",
            "True LOS: 35.00 hours | Predicted: 50.31 hours | Error: 15.31\n",
            "True LOS: 63.13 hours | Predicted: 57.03 hours | Error: 6.10\n",
            "True LOS: 102.85 hours | Predicted: 149.22 hours | Error: 46.37\n",
            "True LOS: 80.08 hours | Predicted: 83.33 hours | Error: 3.25\n",
            "True LOS: 44.72 hours | Predicted: 71.86 hours | Error: 27.14\n",
            "True LOS: 255.52 hours | Predicted: 102.79 hours | Error: 152.73\n",
            "True LOS: 45.53 hours | Predicted: 42.65 hours | Error: 2.88\n",
            "True LOS: 840.62 hours | Predicted: 462.14 hours | Error: 378.48\n",
            "True LOS: 132.08 hours | Predicted: 58.77 hours | Error: 73.31\n",
            "True LOS: 301.33 hours | Predicted: 134.74 hours | Error: 166.59\n",
            "True LOS: 265.32 hours | Predicted: 110.01 hours | Error: 155.31\n",
            "True LOS: 37.37 hours | Predicted: 52.56 hours | Error: 15.19\n",
            "True LOS: 373.82 hours | Predicted: 483.09 hours | Error: 109.27\n"
          ]
        }
      ],
      "source": [
        "# Print True vs Predicted values\n",
        "\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"\\n====== Sample Predictions (True vs Predicted LOS) ======\\n\")\n",
        "\n",
        "num_show = 20  \n",
        "shown = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]\n",
        "\n",
        "        # Convert log-scale → hours\n",
        "        y_true_hours = torch.expm1(y_true).cpu().numpy()\n",
        "        y_pred_hours = torch.expm1(y_pred).cpu().numpy()\n",
        "\n",
        "        for t, p in zip(y_true_hours, y_pred_hours):\n",
        "            print(f\"True LOS: {t:.2f} hours | Predicted: {p:.2f} hours | Error: {abs(t - p):.2f}\")\n",
        "            shown += 1\n",
        "            if shown >= num_show:\n",
        "                break\n",
        "\n",
        "        if shown >= num_show:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWY7G3EB5NyJ",
        "outputId": "a287ca2a-3b68-40d8-d506-1fdec1db1439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== MAE by LOS Range (Test Set) ====\n",
            "  0-200 hours    : MAE = 30.98 hours (N=52437)\n",
            "  200-400 hours  : MAE = 105.52 hours (N=7713)\n",
            "  >400 hours     : MAE = 372.01 hours (N=3571)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load the best weighted model (re-initializing it in case the kernel state was lost)\n",
        "best_model = MultiModalLOSModel(cfg).to(device)\n",
        "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "all_true_los_hours = []\n",
        "all_pred_los_hours = []\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "best_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred_log = best_model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true_log = batch[\"target\"]\n",
        "\n",
        "        # Convert log(1+LOS) to actual LOS hours\n",
        "        y_true_hours = torch.expm1(y_true_log).cpu().numpy()\n",
        "        y_pred_hours = torch.expm1(y_pred_log).cpu().numpy()\n",
        "\n",
        "        all_true_los_hours.extend(y_true_hours)\n",
        "        all_pred_los_hours.extend(y_pred_hours)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "all_true_los_hours = np.array(all_true_los_hours)\n",
        "all_pred_los_hours = np.array(all_pred_los_hours)\n",
        "\n",
        "# Define LOS ranges and calculate MAE for each\n",
        "los_ranges = [\n",
        "    (0, 200, \"0-200 hours\"),\n",
        "    (200, 400, \"200-400 hours\"),\n",
        "    (400, np.inf, \">400 hours\"),\n",
        "]\n",
        "\n",
        "print(\"\\n===== MAE by LOS Range (Test Set) ====\")\n",
        "for lower_bound, upper_bound, label in los_ranges:\n",
        "    if upper_bound == np.inf:\n",
        "        mask = (all_true_los_hours >= lower_bound)\n",
        "    else:\n",
        "        mask = (all_true_los_hours >= lower_bound) & (all_true_los_hours < upper_bound)\n",
        "\n",
        "    filtered_true_los = all_true_los_hours[mask]\n",
        "    filtered_pred_los = all_pred_los_hours[mask]\n",
        "\n",
        "    if len(filtered_true_los) > 0:\n",
        "        mae = np.mean(np.abs(filtered_pred_los - filtered_true_los))\n",
        "        print(f\"  {label:15}: MAE = {mae:.2f} hours (N={len(filtered_true_los)})\")\n",
        "    else:\n",
        "        print(f\"  {label:15}: No samples in this range.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDyX0T_jY7Qp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
