{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V08e05Ftqyv",
        "outputId": "c4323425-2209-4824-9836-83c7c2e4d09c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(424803, 17)\n",
            "Index(['subject_id', 'hadm_id', 'admittime', 'dischtime', 'race', 'los_hours',\n",
            "       'gender', 'anchor_age', 'curr_service', 'hcpcs_cd_list',\n",
            "       'diagnoses_icd_code_list', 'procedures_icd_code_list', 'drg_code',\n",
            "       'drg_severity', 'drg_mortality', 'medication_list', 'order_type_list'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_parquet(\"los_dataset_24h.parquet\")\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_label_encoder(series):\n",
        "    classes = sorted(series.unique())\n",
        "    stoi = {c: i for i, c in enumerate(classes)}\n",
        "    return stoi\n",
        "\n",
        "\n",
        "def build_vocab_from_list_column(df, col, min_freq=1, add_unk=True):\n",
        "    counter = Counter()\n",
        "    for lst in df[col]:\n",
        "        counter.update(lst)\n",
        "\n",
        "    stoi = {}\n",
        "    idx = 0\n",
        "    if add_unk:\n",
        "        stoi[\"<UNK>\"] = idx\n",
        "        idx += 1\n",
        "\n",
        "    for token, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            if token not in stoi:\n",
        "                stoi[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "    return stoi"
      ],
      "metadata": {
        "id": "eTrTAv2ht3aZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoders for gender, race, curr_service, drg_code\n",
        "gender_stoi = build_label_encoder(df[\"gender\"])\n",
        "race_stoi = build_label_encoder(df[\"race\"])\n",
        "service_stoi = build_label_encoder(df[\"curr_service\"])\n",
        "\n",
        "# drg_code is already an int, but treat it as a \"category\" and map it to an index\n",
        "drg_code_stoi = build_label_encoder(df[\"drg_code\"].astype(int))\n",
        "\n",
        "print(\"num_genders:\", len(gender_stoi))\n",
        "print(\"num_races:\", len(race_stoi))\n",
        "print(\"num_services:\", len(service_stoi))\n",
        "print(\"num_drg_codes:\", len(drg_code_stoi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LpjEFBuIUx",
        "outputId": "ae36542c-8400-421c-8395-90eedec5dbaf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_genders: 2\n",
            "num_races: 33\n",
            "num_services: 21\n",
            "num_drg_codes: 301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_cols = [\n",
        "    \"diagnoses_icd_code_list\",\n",
        "    \"procedures_icd_code_list\",\n",
        "    \"hcpcs_cd_list\",\n",
        "    \"medication_list\",\n",
        "    \"order_type_list\",\n",
        "]\n",
        "\n",
        "diag_stoi = build_vocab_from_list_column(df, \"diagnoses_icd_code_list\", min_freq=1)\n",
        "proc_stoi = build_vocab_from_list_column(df, \"procedures_icd_code_list\", min_freq=1)\n",
        "hcpcs_stoi = build_vocab_from_list_column(df, \"hcpcs_cd_list\", min_freq=1)\n",
        "med_stoi = build_vocab_from_list_column(df, \"medication_list\", min_freq=1)\n",
        "order_stoi = build_vocab_from_list_column(df, \"order_type_list\", min_freq=1)\n",
        "\n",
        "print(\"diag vocab size:\", len(diag_stoi))\n",
        "print(\"proc vocab size:\", len(proc_stoi))\n",
        "print(\"hcpcs vocab size:\", len(hcpcs_stoi))\n",
        "print(\"med vocab size:\", len(med_stoi))\n",
        "print(\"order vocab size:\", len(order_stoi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jysvDQ6KuKI3",
        "outputId": "4cd418e2-ebb5-4aef-9b4f-dd8a90b3c2aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diag vocab size: 27701\n",
            "proc vocab size: 12184\n",
            "hcpcs vocab size: 1925\n",
            "med vocab size: 3358\n",
            "order vocab size: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine proc_stoi and hcpcs_stoi into a single unified vocabulary\n",
        "proc_all_stoi = {}\n",
        "idx = 0\n",
        "\n",
        "# Only one UNK\n",
        "proc_all_stoi[\"<UNK>\"] = idx\n",
        "idx += 1\n",
        "\n",
        "# Procedures first\n",
        "for k in proc_stoi.keys():\n",
        "    if k == \"<UNK>\":\n",
        "        continue\n",
        "    proc_all_stoi[\"PROC_\" + k] = idx\n",
        "    idx += 1\n",
        "\n",
        "# Then hcpcs\n",
        "for k in hcpcs_stoi.keys():\n",
        "    if k == \"<UNK>\":\n",
        "        continue\n",
        "    key = \"HCPCS_\" + k\n",
        "    if key not in proc_all_stoi:\n",
        "        proc_all_stoi[key] = idx\n",
        "        idx += 1\n",
        "\n",
        "print(\"combined proc vocab size:\", len(proc_all_stoi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prFr0KUjuNiy",
        "outputId": "39a8a616-145e-4291-a2b6-ce0230e28af6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combined proc vocab size: 14108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_DIAG = diag_stoi[\"<UNK>\"]\n",
        "UNK_PROC = proc_all_stoi[\"<UNK>\"]\n",
        "UNK_MED = med_stoi[\"<UNK>\"]\n",
        "UNK_ORDER = order_stoi[\"<UNK>\"]\n",
        "\n",
        "def map_list_to_ids(lst, stoi, unk_token=\"<UNK>\"):\n",
        "    unk_idx = stoi.get(unk_token, None)\n",
        "    out = []\n",
        "    for x in lst:\n",
        "        idx = stoi.get(x)\n",
        "        if idx is None:\n",
        "            if unk_idx is not None:\n",
        "                out.append(unk_idx)\n",
        "        else:\n",
        "            out.append(idx)\n",
        "    return out\n",
        "\n",
        "# Diagnostic codes\n",
        "df[\"diag_ids\"] = df[\"diagnoses_icd_code_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, diag_stoi)\n",
        ")\n",
        "\n",
        "# Combined procedure + hcpcs IDs\n",
        "def build_proc_ids(row):\n",
        "    ids = []\n",
        "    for code in row[\"procedures_icd_code_list\"]:\n",
        "        tok = \"PROC_\" + code\n",
        "        ids.append(proc_all_stoi.get(tok, UNK_PROC))\n",
        "    for code in row[\"hcpcs_cd_list\"]:\n",
        "        tok = \"HCPCS_\" + code\n",
        "        ids.append(proc_all_stoi.get(tok, UNK_PROC))\n",
        "    return ids\n",
        "\n",
        "df[\"proc_ids\"] = df.apply(build_proc_ids, axis=1)\n",
        "\n",
        "# Medication\n",
        "df[\"med_ids\"] = df[\"medication_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, med_stoi)\n",
        ")\n",
        "\n",
        "# Order type\n",
        "df[\"order_ids\"] = df[\"order_type_list\"].apply(\n",
        "    lambda lst: map_list_to_ids(lst, order_stoi)\n",
        ")\n",
        "\n",
        "# Single categorical â†’ ID\n",
        "df[\"gender_id\"] = df[\"gender\"].map(gender_stoi)\n",
        "df[\"race_id\"] = df[\"race\"].map(race_stoi)\n",
        "df[\"service_id\"] = df[\"curr_service\"].map(service_stoi)\n",
        "df[\"drg_code_id\"] = df[\"drg_code\"].astype(int).map(drg_code_stoi)"
      ],
      "metadata": {
        "id": "Vqz1gkzjuQpZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_list(lst, max_len=10):\n",
        "    \"\"\"\n",
        "    Summarizes a list by truncating it if it's too long.\n",
        "    \"\"\"\n",
        "    if lst is None:\n",
        "        return None\n",
        "    if len(lst) <= max_len:\n",
        "        return lst\n",
        "    return lst[:max_len] + [\"...(+{} more)\".format(len(lst) - max_len)]\n",
        "\n",
        "\n",
        "cols_to_show = [\n",
        "    \"gender\", \"race\", \"curr_service\", \"drg_code\",\n",
        "    \"gender_id\", \"race_id\", \"service_id\", \"drg_code_id\",\n",
        "    \"diagnoses_icd_code_list\", \"diag_ids\",\n",
        "    \"procedures_icd_code_list\", \"hcpcs_cd_list\", \"proc_ids\",\n",
        "    \"medication_list\", \"med_ids\",\n",
        "    \"order_type_list\", \"order_ids\",\n",
        "]\n",
        "\n",
        "print(\"\\n================ SAMPLE DATA (after encoding) ================\\n\")\n",
        "\n",
        "for i in range(3):\n",
        "    row = df.iloc[i]\n",
        "    print(f\"--- Row {i} ---\")\n",
        "\n",
        "    for c in cols_to_show:\n",
        "        val = row[c]\n",
        "\n",
        "        # Summarize list\n",
        "        if isinstance(val, list):\n",
        "            val = summarize_list(val)\n",
        "\n",
        "        print(f\"{c:25} : {val}\")\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "HTxymZbB-_YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62334fff-724a-4f19-98cd-31c1dd395cb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ SAMPLE DATA (after encoding) ================\n",
            "\n",
            "--- Row 0 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 279\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 135\n",
            "diagnoses_icd_code_list   : ['07071' '78959' '2875' '2761' '496' '5715' 'V08' '3051']\n",
            "diag_ids                  : [1, 2, 3, 4, 5, 6, 7, 8]\n",
            "procedures_icd_code_list  : ['5491']\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : [1]\n",
            "medication_list           : ['Raltegravir' 'Rifaximin' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Calcium Carbonate' 'Rifaximin' 'Raltegravir'\n",
            " 'Emtricitabine-Tenofovir (Truvada)' 'Sulfameth/Trimethoprim DS'\n",
            " 'Furosemide' 'Tiotropium Bromide' 'Albuterol Inhaler' 'Lactulose'\n",
            " 'Heparin' 'Sodium Chloride 0.9%  Flush' 'Acetaminophen' 'Heparin'\n",
            " 'Lactulose' 'Albumin 25% (12.5g / 50mL)' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Albumin 25% (12.5g / 50mL)' 'Albumin 25% (12.5g / 50mL)']\n",
            "med_ids                   : [1, 2, 3, 4, 2, 1, 5, 6, 7, 8, '...(+11 more)']\n",
            "order_type_list           : ['Medications' 'General Care' 'Nutrition' 'Blood Bank' 'Lab' 'Respiratory'\n",
            " 'Medications' 'Medications' 'ADT orders' 'Lab' 'Lab' 'Medications'\n",
            " 'ADT orders' 'ADT orders' 'ADT orders' 'ADT orders' 'Lab' 'ADT orders'\n",
            " 'Lab' 'General Care' 'Nutrition' 'Medications' 'ADT orders' 'Lab'\n",
            " 'IV therapy' 'Medications' 'General Care' 'General Care' 'Nutrition'\n",
            " 'Medications' 'Nutrition' 'Lab' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications']\n",
            "order_ids                 : [1, 2, 3, 4, 5, 6, 1, 1, 7, 5, '...(+32 more)']\n",
            "\n",
            "\n",
            "--- Row 1 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 283\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 139\n",
            "diagnoses_icd_code_list   : ['07054' '78959' 'V462' '5715' '2767' '2761' '496' 'V08' '3051' '78791']\n",
            "diag_ids                  : [9, 2, 10, 6, 11, 4, 5, 7, 8, 12]\n",
            "procedures_icd_code_list  : ['5491']\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : [1]\n",
            "medication_list           : ['Heparin' 'Raltegravir' 'Rifaximin' 'Emtricitabine-Tenofovir (Truvada)'\n",
            " 'Lactulose' 'Fluticasone Propionate 110mcg' 'Tiotropium Bromide'\n",
            " 'Albuterol Inhaler' 'Calcium Gluconate' 'Dextrose 50%'\n",
            " 'Insulin (Regular) for Hyperkalemia' 'Sodium Polystyrene Sulfonate'\n",
            " 'TraMADOL (Ultram)' 'Lactulose' 'Heparin' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Lactulose' 'Albuterol Inhaler' 'Insulin (Regular) for Hyperkalemia'\n",
            " 'Sodium Polystyrene Sulfonate' 'Calcium Gluconate' 'Dextrose 50%'\n",
            " 'Furosemide' 'Albumin 25% (12.5g / 50mL)' 'Calcium Carbonate'\n",
            " 'Raltegravir' 'Rifaximin' 'Zolpidem Tartrate'\n",
            " 'Fluticasone Propionate 110mcg' 'Albuterol Inhaler' 'Heparin'\n",
            " 'Sodium Chloride 0.9%  Flush' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Calcium Carbonate']\n",
            "med_ids                   : [11, 1, 2, 5, 10, 14, 8, 9, 15, 16, '...(+24 more)']\n",
            "order_type_list           : ['Lab' 'ADT orders' 'Lab' 'General Care' 'General Care' 'Nutrition'\n",
            " 'Medications' 'ADT orders' 'Lab' 'IV therapy' 'Medications'\n",
            " 'General Care' 'General Care' 'General Care' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Radiology' 'Nutrition' 'Nutrition' 'ADT orders' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Cardiology' 'Lab'\n",
            " 'Medications' 'Consults' 'Consults' 'General Care' 'Medications' 'Lab'\n",
            " 'Medications' 'Lab' 'Lab' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'General Care' 'General Care' 'Medications' 'Medications'\n",
            " 'Lab']\n",
            "order_ids                 : [5, 7, 5, 2, 2, 3, 1, 7, 5, 8, '...(+45 more)']\n",
            "\n",
            "\n",
            "--- Row 2 ---\n",
            "gender                    : F\n",
            "race                      : WHITE\n",
            "curr_service              : MED\n",
            "drg_code                  : 207\n",
            "gender_id                 : 0\n",
            "race_id                   : 28\n",
            "service_id                : 7\n",
            "drg_code_id               : 103\n",
            "diagnoses_icd_code_list   : ['45829' '07044' '7994' '2761' '78959' '2767' '3051' 'V08' 'V4986' 'V462'\n",
            " '496' '29680' '5715']\n",
            "diag_ids                  : [13, 14, 15, 4, 2, 11, 8, 7, 16, 10, '...(+3 more)']\n",
            "procedures_icd_code_list  : []\n",
            "hcpcs_cd_list             : []\n",
            "proc_ids                  : []\n",
            "medication_list           : ['Lactulose' 'TraMADOL (Ultram)' 'Sodium Chloride 0.9%  Flush'\n",
            " 'Albumin 25% (12.5g / 50mL)' 'Bisacodyl' 'Calcium Carbonate'\n",
            " 'Docusate Sodium (Liquid)' 'Emtricitabine-Tenofovir (Truvada)'\n",
            " 'Fluticasone Propionate 110mcg' 'Heparin' 'Lactulose' 'Raltegravir'\n",
            " 'Rifaximin' 'Tiotropium Bromide']\n",
            "med_ids                   : [10, 19, 3, 13, 21, 4, 22, 5, 14, 11, '...(+4 more)']\n",
            "order_type_list           : ['Lab' 'ADT orders' 'Lab' 'General Care' 'General Care' 'General Care'\n",
            " 'Nutrition' 'Medications' 'ADT orders' 'Lab' 'General Care'\n",
            " 'General Care' 'General Care' 'Nutrition' 'Medications' 'Medications'\n",
            " 'Medications' 'General Care' 'Medications' 'Respiratory' 'General Care'\n",
            " 'Lab' 'Medications' 'Lab' 'Nutrition' 'Medications' 'Lab' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Lab' 'ADT orders' 'Lab' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications' 'Medications' 'Medications' 'Medications' 'Medications'\n",
            " 'Nutrition' 'Nutrition' 'IV therapy' 'Medications' 'General Care'\n",
            " 'General Care' 'General Care' 'Lab' 'General Care' 'Medications'\n",
            " 'Medications' 'Lab' 'General Care' 'ADT orders' 'Lab' 'Medications'\n",
            " 'Consults' 'Consults' 'Medications' 'Medications' 'Medications'\n",
            " 'Medications']\n",
            "order_ids                 : [5, 7, 5, 2, 2, 2, 3, 1, 7, 5, '...(+61 more)']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LOSDataset(Dataset):\n",
        "    def __init__(self, df, use_log_target=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.use_log_target = use_log_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        sample = {\n",
        "            # Tabular features\n",
        "            \"age\": float(row[\"anchor_age\"]),\n",
        "            \"gender_id\": int(row[\"gender_id\"]),\n",
        "            \"race_id\": int(row[\"race_id\"]),\n",
        "            \"service_id\": int(row[\"service_id\"]),\n",
        "            \"drg_code_id\": int(row[\"drg_code_id\"]),\n",
        "            \"drg_severity\": float(row[\"drg_severity\"]),\n",
        "            \"drg_mortality\": float(row[\"drg_mortality\"]),\n",
        "\n",
        "            # List-type IDs\n",
        "            \"diag_ids\": row[\"diag_ids\"],\n",
        "            \"proc_ids\": row[\"proc_ids\"],\n",
        "            \"med_ids\": row[\"med_ids\"],\n",
        "            \"order_ids\": row[\"order_ids\"],\n",
        "        }\n",
        "\n",
        "        # Target\n",
        "        los = float(row[\"los_hours\"])\n",
        "        if self.use_log_target:\n",
        "            sample[\"target\"] = np.log1p(los)\n",
        "        else:\n",
        "            sample[\"target\"] = los\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "D0LX9ClZuTkx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def los_collate_fn(batch):\n",
        "    B = len(batch)\n",
        "\n",
        "    # ----- Tabular Stack -----\n",
        "    age = torch.tensor([b[\"age\"] for b in batch], dtype=torch.float32)\n",
        "    gender_id = torch.tensor([b[\"gender_id\"] for b in batch], dtype=torch.long)\n",
        "    race_id = torch.tensor([b[\"race_id\"] for b in batch], dtype=torch.long)\n",
        "    service_id = torch.tensor([b[\"service_id\"] for b in batch], dtype=torch.long)\n",
        "    drg_code_id = torch.tensor([b[\"drg_code_id\"] for b in batch], dtype=torch.long)\n",
        "    drg_severity = torch.tensor([b[\"drg_severity\"] for b in batch], dtype=torch.float32)\n",
        "    drg_mortality = torch.tensor([b[\"drg_mortality\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    target = torch.tensor([b[\"target\"] for b in batch], dtype=torch.float32)\n",
        "\n",
        "    # ----- List-type: diag / proc / med / order -----\n",
        "    def build_bag_inputs(key):\n",
        "        codes_all = []\n",
        "        offsets = [0]\n",
        "        for b in batch:\n",
        "            ids = b[key]\n",
        "            codes_all.extend(ids)\n",
        "            offsets.append(len(codes_all))\n",
        "        if len(codes_all) == 0:\n",
        "            codes_tensor = torch.empty(0, dtype=torch.long)\n",
        "        else:\n",
        "            codes_tensor = torch.tensor(codes_all, dtype=torch.long)\n",
        "        offsets_tensor = torch.tensor(offsets, dtype=torch.long)\n",
        "        return codes_tensor, offsets_tensor\n",
        "\n",
        "    diag_codes, diag_offsets = build_bag_inputs(\"diag_ids\")\n",
        "    proc_codes, proc_offsets = build_bag_inputs(\"proc_ids\")\n",
        "    med_codes, med_offsets = build_bag_inputs(\"med_ids\")\n",
        "    order_codes, order_offsets = build_bag_inputs(\"order_ids\")\n",
        "\n",
        "    batch_out = {\n",
        "        \"age\": age,\n",
        "        \"gender_id\": gender_id,\n",
        "        \"race_id\": race_id,\n",
        "        \"service_id\": service_id,\n",
        "        \"drg_code_id\": drg_code_id,\n",
        "        \"drg_severity\": drg_severity,\n",
        "        \"drg_mortality\": drg_mortality,\n",
        "        \"diag_codes\": diag_codes,\n",
        "        \"diag_offsets\": diag_offsets,\n",
        "        \"proc_codes\": proc_codes,\n",
        "        \"proc_offsets\": proc_offsets,\n",
        "        \"med_codes\": med_codes,\n",
        "        \"med_offsets\": med_offsets,\n",
        "        \"order_codes\": order_codes,\n",
        "        \"order_offsets\": order_offsets,\n",
        "        \"target\": target,\n",
        "    }\n",
        "\n",
        "    return batch_out"
      ],
      "metadata": {
        "id": "TZBngU2IuZuA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "import torch\n",
        "\n",
        "# Create Dataset\n",
        "dataset = LOSDataset(df, use_log_target=True)\n",
        "\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * 0.7)\n",
        "n_val = int(n_total * 0.15)\n",
        "n_test = n_total - n_train - n_val   # Remaining\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test], generator=g)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    collate_fn=los_collate_fn,\n",
        ")\n",
        "\n",
        "print(f\"#train: {len(train_ds)}, #val: {len(val_ds)}, #test: {len(test_ds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmEgyvbPuaOO",
        "outputId": "0a4a3957-bc9f-47d2-9903-86672a21c325"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#train: 297362, #val: 63720, #test: 63721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed0948b6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    # ----- Tabular categorical vocab sizes -----\n",
        "    num_genders: int          # e.g. {\"M\", \"F\"} -> 2\n",
        "    num_races: int            # unique race categories\n",
        "    num_services: int         # curr_service (MED, ORTHO, ...)\n",
        "    num_drg_codes: int        # drg_code vocab size\n",
        "\n",
        "    # ----- Code vocab sizes -----\n",
        "    diag_vocab_size: int      # diagnoses_icd_code_list vocab\n",
        "    proc_vocab_size: int      # Combined vocab for procedures_icd_code_list + hcpcs_cd_list\n",
        "    med_vocab_size: int       # medication_list vocab\n",
        "    order_vocab_size: int     # order_type_list vocab\n",
        "\n",
        "    # ----- Embedding dimensions (ADDED THESE) -----\n",
        "    emb_dim_gender: int = 4\n",
        "    emb_dim_race: int = 8\n",
        "    emb_dim_service: int = 8\n",
        "    emb_dim_drg: int = 16\n",
        "\n",
        "    emb_dim_diag: int = 32\n",
        "    emb_dim_proc: int = 32\n",
        "    emb_dim_med: int = 32\n",
        "    emb_dim_order: int = 16\n",
        "\n",
        "    # ----- Transformer parameters -----\n",
        "    transformer_d_model: int = 64 # Embedding dimension for transformer, output dim of individual branch MLPs\n",
        "    transformer_n_heads: int = 8  # Number of attention heads\n",
        "    transformer_n_layers: int = 2 # Number of transformer encoder layers\n",
        "    transformer_dim_feedforward: int = 256 # Feedforward network dimension\n",
        "\n",
        "    # ----- Dropout -----\n",
        "    dropout: float = 0.2\n",
        "\n",
        "    # ----- Max sequence lengths for codes -----\n",
        "    max_seq_len_diag: int = 80\n",
        "    max_seq_len_proc: int = 50\n",
        "    max_seq_len_med: int = 110\n",
        "    max_seq_len_order: int = 50\n",
        "\n",
        "    # ----- Feature counts for modality embeddings -----\n",
        "    num_scalar_features: int = 3 # age, drg_severity, drg_mortality\n",
        "    num_categorical_features: int = 4 # gender, race, service, drg_code\n",
        "    num_code_modalities: int = 4 # diag, proc, med, order\n",
        "    num_token_types: int = 1 + 3 + 4 + 4 # 1 for CLS, 3 for scalar, 4 for categorical, 4 for code modalities (total 12)\n",
        "\n",
        "\n",
        "class MultiModalTransformerLOSModel(nn.Module):\n",
        "    def __init__(self, cfg: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        # 3. Initialize a learnable [CLS] token\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, cfg.transformer_d_model))\n",
        "\n",
        "        # 4. Define nn.Linear layers for scalar features\n",
        "        self.age_proj = nn.Linear(1, cfg.transformer_d_model)\n",
        "        self.drg_severity_proj = nn.Linear(1, cfg.transformer_d_model)\n",
        "        self.drg_mortality_proj = nn.Linear(1, cfg.transformer_d_model)\n",
        "\n",
        "        # 5. Define nn.Embedding layers for categorical features\n",
        "        self.gender_emb = nn.Embedding(cfg.num_genders, cfg.transformer_d_model)\n",
        "        self.race_emb = nn.Embedding(cfg.num_races, cfg.transformer_d_model)\n",
        "        self.service_emb = nn.Embedding(cfg.num_services, cfg.transformer_d_model)\n",
        "        self.drg_code_emb = nn.Embedding(cfg.num_drg_codes, cfg.transformer_d_model)\n",
        "\n",
        "        # 6. Define nn.Embedding layers for code features\n",
        "        self.diag_emb = nn.Embedding(cfg.diag_vocab_size, cfg.transformer_d_model, padding_idx=0)\n",
        "        self.proc_emb = nn.Embedding(cfg.proc_vocab_size, cfg.transformer_d_model, padding_idx=0)\n",
        "        self.med_emb = nn.Embedding(cfg.med_vocab_size, cfg.transformer_d_model, padding_idx=0)\n",
        "        self.order_emb = nn.Embedding(cfg.order_vocab_size, cfg.transformer_d_model, padding_idx=0)\n",
        "\n",
        "        # 7. Initialize nn.Embedding for modality type embeddings\n",
        "        # Modality types: CLS=0, age=1, severity=2, mortality=3, gender=4, race=5, service=6, drg_code=7, diag_codes=8, proc_codes=9, med_codes=10, order_codes=11\n",
        "        self.modality_type_emb = nn.Embedding(cfg.num_token_types, cfg.transformer_d_model)\n",
        "\n",
        "        # 8. Calculate the maximum total sequence length\n",
        "        max_total_seq_len = (\n",
        "            1  # CLS token\n",
        "            + cfg.num_scalar_features # age, severity, mortality\n",
        "            + cfg.num_categorical_features # gender, race, service, drg_code\n",
        "            + cfg.max_seq_len_diag\n",
        "            + cfg.max_seq_len_proc\n",
        "            + cfg.max_seq_len_med\n",
        "            + cfg.max_seq_len_order\n",
        "        )\n",
        "        self.max_total_seq_len = max_total_seq_len\n",
        "\n",
        "        # 9. Initialize nn.Embedding for positional embeddings\n",
        "        self.positional_emb = nn.Embedding(max_total_seq_len, cfg.transformer_d_model)\n",
        "\n",
        "        # 10. Create a nn.TransformerEncoderLayer\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=cfg.transformer_d_model,\n",
        "            nhead=cfg.transformer_n_heads,\n",
        "            dim_feedforward=cfg.transformer_dim_feedforward,\n",
        "            dropout=cfg.dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # 11. Instantiate the nn.TransformerEncoder\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=cfg.transformer_n_layers\n",
        "        )\n",
        "\n",
        "        # 12. Define the regression head\n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.Linear(cfg.transformer_d_model, cfg.transformer_d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.transformer_d_model // 2, 1)\n",
        "        )\n",
        "\n",
        "    def _get_modality_emb_with_type(self, embedding_tensor, modality_type_idx):\n",
        "        \"\"\"\n",
        "        Adds the modality type embedding to the given embedding tensor.\n",
        "        Ensures correct device for the modality type index tensor.\n",
        "        \"\"\"\n",
        "        modality_type_tensor = torch.tensor([modality_type_idx], device=embedding_tensor.device)\n",
        "        modality_emb = self.modality_type_emb(modality_type_tensor).unsqueeze(0) # (1, 1, d_model)\n",
        "        # modality_emb will broadcast correctly to embedding_tensor's shape (B, 1, d_model) or (B, max_len, d_model)\n",
        "        return embedding_tensor + modality_emb\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        age: torch.Tensor,\n",
        "        gender_idx: torch.Tensor,\n",
        "        race_idx: torch.Tensor,\n",
        "        service_idx: torch.Tensor,\n",
        "        drg_code_idx: torch.Tensor,\n",
        "        drg_severity: torch.Tensor,\n",
        "        drg_mortality: torch.Tensor,\n",
        "        diag_codes: torch.Tensor,\n",
        "        diag_offsets: torch.Tensor,\n",
        "        proc_codes: torch.Tensor,\n",
        "        proc_offsets: torch.Tensor,\n",
        "        med_codes: torch.Tensor,\n",
        "        med_offsets: torch.Tensor,\n",
        "        order_codes: torch.Tensor,\n",
        "        order_offsets: torch.Tensor,\n",
        "    ):\n",
        "        B = age.size(0) # Batch size\n",
        "        device = age.device\n",
        "\n",
        "        all_embeddings = []\n",
        "        src_key_padding_mask_components = []\n",
        "\n",
        "        # 1. Prepare the [CLS] token\n",
        "        cls_embedding = self.cls_token.expand(B, -1, -1) # (B, 1, d_model)\n",
        "        cls_embedding = self._get_modality_emb_with_type(cls_embedding, 0) # CLS modality type 0\n",
        "        all_embeddings.append(cls_embedding)\n",
        "        src_key_padding_mask_components.append(torch.zeros(B, 1, dtype=torch.bool, device=device))\n",
        "\n",
        "        # 2. Process scalar features\n",
        "        # age (modality type 1)\n",
        "        age_proj_emb = self.age_proj(age.float().unsqueeze(-1)).unsqueeze(1) # Project (B,1) to (B, d_model), then add 1 for sequence dim: (B, 1, d_model)\n",
        "        age_emb = self._get_modality_emb_with_type(age_proj_emb, 1)\n",
        "        all_embeddings.append(age_emb)\n",
        "        src_key_padding_mask_components.append(torch.zeros(B, 1, dtype=torch.bool, device=device))\n",
        "\n",
        "        # drg_severity (modality type 2)\n",
        "        sev_proj_emb = self.drg_severity_proj(drg_severity.float().unsqueeze(-1)).unsqueeze(1) # (B, 1, d_model)\n",
        "        sev_emb = self._get_modality_emb_with_type(sev_proj_emb, 2)\n",
        "        all_embeddings.append(sev_emb)\n",
        "        src_key_padding_mask_components.append(torch.zeros(B, 1, dtype=torch.bool, device=device))\n",
        "\n",
        "        # drg_mortality (modality type 3)\n",
        "        mort_proj_emb = self.drg_mortality_proj(drg_mortality.float().unsqueeze(-1)).unsqueeze(1) # (B, 1, d_model)\n",
        "        mort_emb = self._get_modality_emb_with_type(mort_proj_emb, 3)\n",
        "        all_embeddings.append(mort_emb)\n",
        "        src_key_padding_mask_components.append(torch.zeros(B, 1, dtype=torch.bool, device=device))\n",
        "\n",
        "        # 3. Process categorical features\n",
        "        # gender (modality type 4)\n",
        "        gender_proj_emb = self.gender_emb(gender_idx).unsqueeze(1) # (B, 1, d_model)\n",
        "        gender_emb = self._get_modality_emb_with_type(gender_proj_emb, 4)\n",
        "        all_embeddings.append(gender_emb)\n",
        "        src_key_padding_mask_components.append(torch.zeros(B, 1, dtype=torch.bool, device=device))\n",
        "\n",
        "        # race (modality type 5)\n",
        "        race_proj_emb = self.race_emb(race_idx).unsqueeze(1) # (B, 1, d_model)\n",
        "        race_emb = self._get_modality_emb_with_type(race_proj_emb, 5)\n",
        "        all_embeddings.append(race_emb)\n",
        "        src_key_padding_mask_components.append(torch.zeros(B, 1, dtype=torch.bool, device=device))\n",
        "\n",
        "        # service (modality type 6)\n",
        "        service_proj_emb = self.service_emb(service_idx).unsqueeze(1) # (B, 1, d_model)\n",
        "        service_emb = self._get_modality_emb_with_type(service_proj_emb, 6)\n",
        "        all_embeddings.append(service_emb)\n",
        "        src_key_padding_mask_components.append(torch.zeros(B, 1, dtype=torch.bool, device=device))\n",
        "\n",
        "        # drg_code (modality type 7)\n",
        "        drg_code_proj_emb = self.drg_code_emb(drg_code_idx).unsqueeze(1) # (B, 1, d_model)\n",
        "        drg_code_emb = self._get_modality_emb_with_type(drg_code_proj_emb, 7)\n",
        "        all_embeddings.append(drg_code_emb)\n",
        "        src_key_padding_mask_components.append(torch.zeros(B, 1, dtype=torch.bool, device=device))\n",
        "\n",
        "        # Helper for processing code sequences\n",
        "        def process_code_sequence(codes, offsets, emb_layer, max_len, modality_type_idx):\n",
        "            if codes.numel() == 0: # Handle empty codes tensor for a whole batch\n",
        "                padded_seqs = torch.zeros(B, max_len, self.cfg.transformer_d_model, device=device)\n",
        "                padding_mask = torch.ones(B, max_len, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                embedded_codes_flat = emb_layer(codes) # (N_codes, d_model)\n",
        "\n",
        "                batch_padded_sequences = []\n",
        "                batch_padding_masks = []\n",
        "\n",
        "                # Split by offsets to get individual sequences for each batch item\n",
        "                for i in range(B):\n",
        "                    start = offsets[i]\n",
        "                    end = offsets[i+1]\n",
        "\n",
        "                    sequence = embedded_codes_flat[start:end] # (seq_len_i, d_model)\n",
        "\n",
        "                    # Truncate\n",
        "                    if sequence.size(0) > max_len:\n",
        "                        sequence = sequence[:max_len]\n",
        "\n",
        "                    # Pad\n",
        "                    padding_needed = max_len - sequence.size(0)\n",
        "                    if padding_needed > 0:\n",
        "                        padding = torch.zeros(padding_needed, self.cfg.transformer_d_model, device=device)\n",
        "                        sequence = torch.cat([sequence, padding], dim=0)\n",
        "                        mask_row = torch.cat([\n",
        "                            torch.zeros(max_len - padding_needed, dtype=torch.bool, device=device),\n",
        "                            torch.ones(padding_needed, dtype=torch.bool, device=device)\n",
        "                        ])\n",
        "                    else:\n",
        "                        mask_row = torch.zeros(max_len, dtype=torch.bool, device=device)\n",
        "\n",
        "                    batch_padded_sequences.append(sequence.unsqueeze(0)) # (1, max_len, d_model)\n",
        "                    batch_padding_masks.append(mask_row.unsqueeze(0)) # (1, max_len)\n",
        "\n",
        "                # Stack sequences and masks for the batch\n",
        "                padded_seqs = torch.cat(batch_padded_sequences, dim=0) # (B, max_len, d_model)\n",
        "                padding_mask = torch.cat(batch_padding_masks, dim=0) # (B, max_len)\n",
        "\n",
        "            # Add modality type embedding using the helper method\n",
        "            padded_seqs = self._get_modality_emb_with_type(padded_seqs, modality_type_idx)\n",
        "\n",
        "            return padded_seqs, padding_mask\n",
        "\n",
        "        # 4. Process sequence-type code features\n",
        "        # diag_codes (modality type 8)\n",
        "        h_diag_sequence, diag_padding_mask = process_code_sequence(\n",
        "            diag_codes, diag_offsets, self.diag_emb, self.cfg.max_seq_len_diag, 8\n",
        "        )\n",
        "        all_embeddings.append(h_diag_sequence)\n",
        "        src_key_padding_mask_components.append(diag_padding_mask)\n",
        "\n",
        "        # proc_codes (modality type 9)\n",
        "        h_proc_sequence, proc_padding_mask = process_code_sequence(\n",
        "            proc_codes, proc_offsets, self.proc_emb, self.cfg.max_seq_len_proc, 9\n",
        "        )\n",
        "        all_embeddings.append(h_proc_sequence)\n",
        "        src_key_padding_mask_components.append(proc_padding_mask)\n",
        "\n",
        "        # med_codes (modality type 10)\n",
        "        h_med_sequence, med_padding_mask = process_code_sequence(\n",
        "            med_codes, med_offsets, self.med_emb, self.cfg.max_seq_len_med, 10\n",
        "        )\n",
        "        all_embeddings.append(h_med_sequence)\n",
        "        src_key_padding_mask_components.append(med_padding_mask)\n",
        "\n",
        "        # order_codes (modality type 11)\n",
        "        h_order_sequence, order_padding_mask = process_code_sequence(\n",
        "            order_codes, order_offsets, self.order_emb, self.cfg.max_seq_len_order, 11\n",
        "        )\n",
        "        all_embeddings.append(h_order_sequence)\n",
        "        src_key_padding_mask_components.append(order_padding_mask)\n",
        "\n",
        "        # 5. Concatenate all processed tokens\n",
        "        transformer_input = torch.cat(all_embeddings, dim=1) # (B, total_seq_len, d_model)\n",
        "\n",
        "        # 6. Create the src_key_padding_mask\n",
        "        src_key_padding_mask = torch.cat(src_key_padding_mask_components, dim=1) # (B, total_seq_len)\n",
        "\n",
        "        # 7. Add positional embeddings\n",
        "        positions = torch.arange(self.max_total_seq_len, device=device).unsqueeze(0) # (1, total_seq_len)\n",
        "        positional_embeddings = self.positional_emb(positions)\n",
        "        transformer_input = transformer_input + positional_embeddings # (B, total_seq_len, d_model)\n",
        "\n",
        "        # 8. Pass through the Transformer Encoder\n",
        "        transformer_output = self.transformer_encoder(\n",
        "            transformer_input,\n",
        "            src_key_padding_mask=src_key_padding_mask\n",
        "        ) # (B, total_seq_len, d_model)\n",
        "\n",
        "        # 9. Extract the output corresponding to the [CLS] token\n",
        "        cls_output = transformer_output[:, 0, :] # (B, d_model)\n",
        "\n",
        "        # 10. Pass to the regression head\n",
        "        prediction = self.regression_head(cls_output).squeeze(-1) # (B,)\n",
        "\n",
        "        return prediction"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d47e9fca",
        "outputId": "3a36edc7-14e4-4f27-eb2e-5ba092655208"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "# 1. Model / Config Creation\n",
        "\n",
        "cfg = ModelConfig(\n",
        "    num_genders=len(gender_stoi),\n",
        "    num_races=len(race_stoi),\n",
        "    num_services=len(service_stoi),\n",
        "    num_drg_codes=len(drg_code_stoi),\n",
        "    diag_vocab_size=len(diag_stoi),\n",
        "    proc_vocab_size=len(proc_all_stoi),\n",
        "    med_vocab_size=len(med_stoi),\n",
        "    order_vocab_size=len(order_stoi),\n",
        ")\n",
        "\n",
        "model = MultiModalTransformerLOSModel(cfg)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()  # MSE based on log(1+LOS)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_model_path = \"los_multibranch_best.pt\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 2. Training Loop\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # ---------- Train ----------\n",
        "    model.train()\n",
        "    train_loss_sum = 0.0\n",
        "    train_count = 0\n",
        "\n",
        "    print(f\"\\n========== Epoch {epoch}/{NUM_EPOCHS} ==========\")\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        # Move tensors to device\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # log(1+LOS)\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = y_true.size(0)\n",
        "        train_loss_sum += loss.item() * bs\n",
        "        train_count += bs\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            avg_loss = train_loss_sum / train_count\n",
        "            print(f\"  [Epoch {epoch} | Step {batch_idx}/{len(train_loader)}] \"\n",
        "                  f\"AvgTrainLoss={avg_loss:.4f}\")\n",
        "\n",
        "    train_loss = train_loss_sum / train_count\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    model.eval()\n",
        "    val_loss_sum = 0.0\n",
        "    val_count = 0\n",
        "    val_mae_hours_sum = 0.0  # MAE based on actual LOS (hours)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                     for k, v in batch.items()}\n",
        "\n",
        "            y_pred = model(\n",
        "                age=batch[\"age\"],\n",
        "                gender_idx=batch[\"gender_id\"],\n",
        "                race_idx=batch[\"race_id\"],\n",
        "                service_idx=batch[\"service_id\"],\n",
        "                drg_code_idx=batch[\"drg_code_id\"],\n",
        "                drg_severity=batch[\"drg_severity\"],\n",
        "                drg_mortality=batch[\"drg_mortality\"],\n",
        "                diag_codes=batch[\"diag_codes\"],\n",
        "                diag_offsets=batch[\"diag_offsets\"],\n",
        "                proc_codes=batch[\"proc_codes\"],\n",
        "                proc_offsets=batch[\"proc_offsets\"],\n",
        "                med_codes=batch[\"med_codes\"],\n",
        "                med_offsets=batch[\"med_offsets\"],\n",
        "                order_codes=batch[\"order_codes\"],\n",
        "                order_offsets=batch[\"order_offsets\"],\n",
        "            )\n",
        "\n",
        "            y_true = batch[\"target\"]\n",
        "\n",
        "            loss = criterion(y_pred, y_true)\n",
        "\n",
        "            bs = y_true.size(0)\n",
        "            val_loss_sum += loss.item() * bs\n",
        "            val_count += bs\n",
        "\n",
        "            # Convert log(1+LOS) -> actual LOS (hours) and calculate MAE\n",
        "            y_true_hours = torch.expm1(y_true)\n",
        "            y_pred_hours = torch.expm1(y_pred)\n",
        "\n",
        "            mae_hours = torch.abs(y_pred_hours - y_true_hours).sum().item()\n",
        "            val_mae_hours_sum += mae_hours\n",
        "\n",
        "    val_loss = val_loss_sum / val_count\n",
        "    val_mae_hours = val_mae_hours_sum / val_count\n",
        "\n",
        "    print(f\"[Epoch {epoch:03d}] \"\n",
        "          f\"train_loss(log-MSE)={train_loss:.4f} | \"\n",
        "          f\"val_loss(log-MSE)={val_loss:.4f} | \"\n",
        "          f\"val_MAE(hours)={val_mae_hours:.2f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"  â†’ Best model updated, saved to {best_model_path}\")\n",
        "\n",
        "print(\"Training finished. Best val_loss:\", best_val_loss)\n",
        "\n",
        "# 3. Calculate MAE (hours) on Test set\n",
        "best_model = MultiModalTransformerLOSModel(cfg).to(device)\n",
        "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "test_abs_error_sum = 0.0\n",
        "test_count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "                 for k, v in batch.items()}\n",
        "\n",
        "        y_pred = best_model(\n",
        "            age=batch[\"age\"],\n",
        "            gender_idx=batch[\"gender_id\"],\n",
        "            race_idx=batch[\"race_id\"],\n",
        "            service_idx=batch[\"service_id\"],\n",
        "            drg_code_idx=batch[\"drg_code_id\"],\n",
        "            drg_severity=batch[\"drg_severity\"],\n",
        "            drg_mortality=batch[\"drg_mortality\"],\n",
        "            diag_codes=batch[\"diag_codes\"],\n",
        "            diag_offsets=batch[\"diag_offsets\"],\n",
        "            proc_codes=batch[\"proc_codes\"],\n",
        "            proc_offsets=batch[\"proc_offsets\"],\n",
        "            med_codes=batch[\"med_codes\"],\n",
        "            med_offsets=batch[\"med_offsets\"],\n",
        "            order_codes=batch[\"order_codes\"],\n",
        "            order_offsets=batch[\"order_offsets\"],\n",
        "        )\n",
        "\n",
        "        y_true = batch[\"target\"]  # log(1+LOS)\n",
        "\n",
        "        # Convert log(1+LOS) â†’ actual hours\n",
        "        y_true_hours = torch.expm1(y_true)\n",
        "        y_pred_hours = torch.expm1(y_pred)\n",
        "\n",
        "        abs_err = torch.abs(y_pred_hours - y_true_hours)\n",
        "        test_abs_error_sum += abs_err.sum().item()\n",
        "        test_count += y_true.size(0)\n",
        "\n",
        "test_mae_hours = test_abs_error_sum / test_count\n",
        "\n",
        "print(f\"\\n===== Test set MAE =====\")\n",
        "print(f\"Test MAE (hours): {test_mae_hours:.2f}\")\n",
        "print(f\"Test MAE (days) : {test_mae_hours / 24:.2f}\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "========== Epoch 1/10 ==========\n",
            "  [Epoch 1 | Step 0/1162] AvgTrainLoss=17.8877\n",
            "  [Epoch 1 | Step 100/1162] AvgTrainLoss=1.9337\n",
            "  [Epoch 1 | Step 200/1162] AvgTrainLoss=1.2955\n",
            "  [Epoch 1 | Step 300/1162] AvgTrainLoss=1.0749\n",
            "  [Epoch 1 | Step 400/1162] AvgTrainLoss=0.9304\n",
            "  [Epoch 1 | Step 500/1162] AvgTrainLoss=0.8344\n",
            "  [Epoch 1 | Step 600/1162] AvgTrainLoss=0.7665\n",
            "  [Epoch 1 | Step 700/1162] AvgTrainLoss=0.7160\n",
            "  [Epoch 1 | Step 800/1162] AvgTrainLoss=0.6762\n",
            "  [Epoch 1 | Step 900/1162] AvgTrainLoss=0.6439\n",
            "  [Epoch 1 | Step 1000/1162] AvgTrainLoss=0.6161\n",
            "  [Epoch 1 | Step 1100/1162] AvgTrainLoss=0.5940\n",
            "[Epoch 001] train_loss(log-MSE)=0.5817 | val_loss(log-MSE)=0.3852 | val_MAE(hours)=75.70\n",
            "  â†’ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 2/10 ==========\n",
            "  [Epoch 2 | Step 0/1162] AvgTrainLoss=0.3576\n",
            "  [Epoch 2 | Step 100/1162] AvgTrainLoss=0.3432\n",
            "  [Epoch 2 | Step 200/1162] AvgTrainLoss=0.3386\n",
            "  [Epoch 2 | Step 300/1162] AvgTrainLoss=0.3323\n",
            "  [Epoch 2 | Step 400/1162] AvgTrainLoss=0.3290\n",
            "  [Epoch 2 | Step 500/1162] AvgTrainLoss=0.3260\n",
            "  [Epoch 2 | Step 600/1162] AvgTrainLoss=0.3230\n",
            "  [Epoch 2 | Step 700/1162] AvgTrainLoss=0.3194\n",
            "  [Epoch 2 | Step 800/1162] AvgTrainLoss=0.3161\n",
            "  [Epoch 2 | Step 900/1162] AvgTrainLoss=0.3128\n",
            "  [Epoch 2 | Step 1000/1162] AvgTrainLoss=0.3099\n",
            "  [Epoch 2 | Step 1100/1162] AvgTrainLoss=0.3068\n",
            "[Epoch 002] train_loss(log-MSE)=0.3054 | val_loss(log-MSE)=0.3188 | val_MAE(hours)=67.53\n",
            "  â†’ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 3/10 ==========\n",
            "  [Epoch 3 | Step 0/1162] AvgTrainLoss=0.3112\n",
            "  [Epoch 3 | Step 100/1162] AvgTrainLoss=0.2718\n",
            "  [Epoch 3 | Step 200/1162] AvgTrainLoss=0.2721\n",
            "  [Epoch 3 | Step 300/1162] AvgTrainLoss=0.2709\n",
            "  [Epoch 3 | Step 400/1162] AvgTrainLoss=0.2701\n",
            "  [Epoch 3 | Step 500/1162] AvgTrainLoss=0.2692\n",
            "  [Epoch 3 | Step 600/1162] AvgTrainLoss=0.2679\n",
            "  [Epoch 3 | Step 700/1162] AvgTrainLoss=0.2670\n",
            "  [Epoch 3 | Step 800/1162] AvgTrainLoss=0.2674\n",
            "  [Epoch 3 | Step 900/1162] AvgTrainLoss=0.2674\n",
            "  [Epoch 3 | Step 1000/1162] AvgTrainLoss=0.2663\n",
            "  [Epoch 3 | Step 1100/1162] AvgTrainLoss=0.2657\n",
            "[Epoch 003] train_loss(log-MSE)=0.2656 | val_loss(log-MSE)=0.3419 | val_MAE(hours)=74.99\n",
            "\n",
            "========== Epoch 4/10 ==========\n",
            "  [Epoch 4 | Step 0/1162] AvgTrainLoss=0.2914\n",
            "  [Epoch 4 | Step 100/1162] AvgTrainLoss=0.2514\n",
            "  [Epoch 4 | Step 200/1162] AvgTrainLoss=0.2529\n",
            "  [Epoch 4 | Step 300/1162] AvgTrainLoss=0.2537\n",
            "  [Epoch 4 | Step 400/1162] AvgTrainLoss=0.2521\n",
            "  [Epoch 4 | Step 500/1162] AvgTrainLoss=0.2510\n",
            "  [Epoch 4 | Step 600/1162] AvgTrainLoss=0.2517\n",
            "  [Epoch 4 | Step 700/1162] AvgTrainLoss=0.2515\n",
            "  [Epoch 4 | Step 800/1162] AvgTrainLoss=0.2508\n",
            "  [Epoch 4 | Step 900/1162] AvgTrainLoss=0.2510\n",
            "  [Epoch 4 | Step 1000/1162] AvgTrainLoss=0.2502\n",
            "  [Epoch 4 | Step 1100/1162] AvgTrainLoss=0.2506\n",
            "[Epoch 004] train_loss(log-MSE)=0.2506 | val_loss(log-MSE)=0.3715 | val_MAE(hours)=77.83\n",
            "\n",
            "========== Epoch 5/10 ==========\n",
            "  [Epoch 5 | Step 0/1162] AvgTrainLoss=0.2030\n",
            "  [Epoch 5 | Step 100/1162] AvgTrainLoss=0.2421\n",
            "  [Epoch 5 | Step 200/1162] AvgTrainLoss=0.2382\n",
            "  [Epoch 5 | Step 300/1162] AvgTrainLoss=0.2394\n",
            "  [Epoch 5 | Step 400/1162] AvgTrainLoss=0.2401\n",
            "  [Epoch 5 | Step 500/1162] AvgTrainLoss=0.2414\n",
            "  [Epoch 5 | Step 600/1162] AvgTrainLoss=0.2422\n",
            "  [Epoch 5 | Step 700/1162] AvgTrainLoss=0.2433\n",
            "  [Epoch 5 | Step 800/1162] AvgTrainLoss=0.2432\n",
            "  [Epoch 5 | Step 900/1162] AvgTrainLoss=0.2433\n",
            "  [Epoch 5 | Step 1000/1162] AvgTrainLoss=0.2432\n",
            "  [Epoch 5 | Step 1100/1162] AvgTrainLoss=0.2435\n",
            "[Epoch 005] train_loss(log-MSE)=0.2439 | val_loss(log-MSE)=0.2721 | val_MAE(hours)=61.39\n",
            "  â†’ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 6/10 ==========\n",
            "  [Epoch 6 | Step 0/1162] AvgTrainLoss=0.2662\n",
            "  [Epoch 6 | Step 100/1162] AvgTrainLoss=0.2343\n",
            "  [Epoch 6 | Step 200/1162] AvgTrainLoss=0.2366\n",
            "  [Epoch 6 | Step 300/1162] AvgTrainLoss=0.2358\n",
            "  [Epoch 6 | Step 400/1162] AvgTrainLoss=0.2359\n",
            "  [Epoch 6 | Step 500/1162] AvgTrainLoss=0.2365\n",
            "  [Epoch 6 | Step 600/1162] AvgTrainLoss=0.2368\n",
            "  [Epoch 6 | Step 700/1162] AvgTrainLoss=0.2377\n",
            "  [Epoch 6 | Step 800/1162] AvgTrainLoss=0.2379\n",
            "  [Epoch 6 | Step 900/1162] AvgTrainLoss=0.2381\n",
            "  [Epoch 6 | Step 1000/1162] AvgTrainLoss=0.2382\n",
            "  [Epoch 6 | Step 1100/1162] AvgTrainLoss=0.2393\n",
            "[Epoch 006] train_loss(log-MSE)=0.2394 | val_loss(log-MSE)=0.2835 | val_MAE(hours)=63.34\n",
            "\n",
            "========== Epoch 7/10 ==========\n",
            "  [Epoch 7 | Step 0/1162] AvgTrainLoss=0.2111\n",
            "  [Epoch 7 | Step 100/1162] AvgTrainLoss=0.2305\n",
            "  [Epoch 7 | Step 200/1162] AvgTrainLoss=0.2315\n",
            "  [Epoch 7 | Step 300/1162] AvgTrainLoss=0.2308\n",
            "  [Epoch 7 | Step 400/1162] AvgTrainLoss=0.2312\n",
            "  [Epoch 7 | Step 500/1162] AvgTrainLoss=0.2314\n",
            "  [Epoch 7 | Step 600/1162] AvgTrainLoss=0.2315\n",
            "  [Epoch 7 | Step 700/1162] AvgTrainLoss=0.2320\n",
            "  [Epoch 7 | Step 800/1162] AvgTrainLoss=0.2325\n",
            "  [Epoch 7 | Step 900/1162] AvgTrainLoss=0.2326\n",
            "  [Epoch 7 | Step 1000/1162] AvgTrainLoss=0.2332\n",
            "  [Epoch 7 | Step 1100/1162] AvgTrainLoss=0.2331\n",
            "[Epoch 007] train_loss(log-MSE)=0.2334 | val_loss(log-MSE)=0.3080 | val_MAE(hours)=67.81\n",
            "\n",
            "========== Epoch 8/10 ==========\n",
            "  [Epoch 8 | Step 0/1162] AvgTrainLoss=0.2240\n",
            "  [Epoch 8 | Step 100/1162] AvgTrainLoss=0.2253\n",
            "  [Epoch 8 | Step 200/1162] AvgTrainLoss=0.2246\n",
            "  [Epoch 8 | Step 300/1162] AvgTrainLoss=0.2279\n",
            "  [Epoch 8 | Step 400/1162] AvgTrainLoss=0.2279\n",
            "  [Epoch 8 | Step 500/1162] AvgTrainLoss=0.2285\n",
            "  [Epoch 8 | Step 600/1162] AvgTrainLoss=0.2285\n",
            "  [Epoch 8 | Step 700/1162] AvgTrainLoss=0.2287\n",
            "  [Epoch 8 | Step 800/1162] AvgTrainLoss=0.2293\n",
            "  [Epoch 8 | Step 900/1162] AvgTrainLoss=0.2293\n",
            "  [Epoch 8 | Step 1000/1162] AvgTrainLoss=0.2294\n",
            "  [Epoch 8 | Step 1100/1162] AvgTrainLoss=0.2297\n",
            "[Epoch 008] train_loss(log-MSE)=0.2298 | val_loss(log-MSE)=0.2601 | val_MAE(hours)=61.58\n",
            "  â†’ Best model updated, saved to los_multibranch_best.pt\n",
            "\n",
            "========== Epoch 9/10 ==========\n",
            "  [Epoch 9 | Step 0/1162] AvgTrainLoss=0.2260\n",
            "  [Epoch 9 | Step 100/1162] AvgTrainLoss=0.2221\n",
            "  [Epoch 9 | Step 200/1162] AvgTrainLoss=0.2231\n",
            "  [Epoch 9 | Step 300/1162] AvgTrainLoss=0.2240\n",
            "  [Epoch 9 | Step 400/1162] AvgTrainLoss=0.2243\n",
            "  [Epoch 9 | Step 500/1162] AvgTrainLoss=0.2248\n",
            "  [Epoch 9 | Step 600/1162] AvgTrainLoss=0.2250\n",
            "  [Epoch 9 | Step 700/1162] AvgTrainLoss=0.2258\n",
            "  [Epoch 9 | Step 800/1162] AvgTrainLoss=0.2264\n",
            "  [Epoch 9 | Step 900/1162] AvgTrainLoss=0.2264\n",
            "  [Epoch 9 | Step 1000/1162] AvgTrainLoss=0.2267\n",
            "  [Epoch 9 | Step 1100/1162] AvgTrainLoss=0.2271\n",
            "[Epoch 009] train_loss(log-MSE)=0.2274 | val_loss(log-MSE)=0.2642 | val_MAE(hours)=59.26\n",
            "\n",
            "========== Epoch 10/10 ==========\n",
            "  [Epoch 10 | Step 0/1162] AvgTrainLoss=0.2503\n",
            "  [Epoch 10 | Step 100/1162] AvgTrainLoss=0.2215\n",
            "  [Epoch 10 | Step 200/1162] AvgTrainLoss=0.2215\n",
            "  [Epoch 10 | Step 300/1162] AvgTrainLoss=0.2231\n",
            "  [Epoch 10 | Step 400/1162] AvgTrainLoss=0.2219\n",
            "  [Epoch 10 | Step 500/1162] AvgTrainLoss=0.2217\n",
            "  [Epoch 10 | Step 600/1162] AvgTrainLoss=0.2218\n",
            "  [Epoch 10 | Step 700/1162] AvgTrainLoss=0.2223\n",
            "  [Epoch 10 | Step 800/1162] AvgTrainLoss=0.2226\n",
            "  [Epoch 10 | Step 900/1162] AvgTrainLoss=0.2232\n",
            "  [Epoch 10 | Step 1000/1162] AvgTrainLoss=0.2236\n",
            "  [Epoch 10 | Step 1100/1162] AvgTrainLoss=0.2239\n",
            "[Epoch 010] train_loss(log-MSE)=0.2239 | val_loss(log-MSE)=0.2688 | val_MAE(hours)=62.99\n",
            "Training finished. Best val_loss: 0.26013564325247035\n",
            "\n",
            "===== Test set MAE =====\n",
            "Test MAE (hours): 60.83\n",
            "Test MAE (days) : 2.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ndxFSOmYR6Z7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}